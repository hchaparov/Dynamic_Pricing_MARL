{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchaparov/Dynamic_Pricing_MARL/blob/main/2A_Pong_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX6xDBv877gO",
        "outputId": "89bf4ab5-73e4-4eac-cbb7-47cfebf0c0c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "swig is already the newest version (4.0.2-1ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: pettingzoo in /usr/local/lib/python3.10/dist-packages (1.24.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo) (1.25.2)\n",
            "Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo) (0.29.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (4.12.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (0.0.4)\n",
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3) (12.5.40)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: supersuit in /usr/local/lib/python3.10/dist-packages (3.9.2)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from supersuit) (1.25.2)\n",
            "Requirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from supersuit) (0.29.1)\n",
            "Requirement already satisfied: tinyscaler>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from supersuit) (1.2.7)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (4.12.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (0.0.4)\n",
            "Requirement already satisfied: pymunk in /usr/local/lib/python3.10/dist-packages (6.8.1)\n",
            "Requirement already satisfied: cffi>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from pymunk) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.15.0->pymunk) (2.22)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (9.4.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (0.5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg->imageio[ffmpeg]) (67.7.2)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: multi_agent_ale_py in /usr/local/lib/python3.10/dist-packages (0.1.11)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from multi_agent_ale_py) (1.25.2)\n",
            "Requirement already satisfied: autorom in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (2024.6.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install swig\n",
        "!pip install \"pettingzoo\"\n",
        "!pip install \"stable-baselines3\"\n",
        "!pip install \"supersuit\"\n",
        "!pip install pymunk\n",
        "!pip install pyvirtualdisplay imageio[ffmpeg]\n",
        "!apt-get install -y xvfb\n",
        "!pip install tensorboard\n",
        "!pip install pillow\n",
        "!pip install multi_agent_ale_py\n",
        "!pip install autorom\n",
        "!pip install moviepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtZFX4m5Uiwz",
        "outputId": "d57590e3-d559-457d-d617-eaf32c762d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.10/dist-packages/AutoROM/roms\n",
            "\t/usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/et.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/et.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/zaxxon.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/zaxxon.bin\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "!AutoROM --accept-license"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB-s6GRA7-jE",
        "outputId": "cd185331-18c0-4b52-f0e3-3e4b4d872012"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/skimage/util/dtype.py:27: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  np.bool8: (False, True),\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/fx/painting.py:7: DeprecationWarning: Please use `sobel` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import sobel\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "import imageio\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "import supersuit as ss\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo import CnnPolicy\n",
        "from pettingzoo.atari import pong_v3\n",
        "from PIL import Image\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, BaseCallback\n",
        "from stable_baselines3.common.logger import configure\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "log_dir = \"/content/drive/MyDrive/2A_pong_ppo/\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "temp_eval_log_dir = \"/content/drive/My Drive/2A_pong_ppo/tmp\"\n",
        "os.makedirs(temp_eval_log_dir, exist_ok=True)\n",
        "\n",
        "n_training_envs = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHPUvZMr8EEw",
        "outputId": "4caed4dd-d5e6-4027-90db-9eba8341f2ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def train_pong_supersuit(env_fn, steps: int = 200_000, seed: int | None = 0, **env_kwargs):\n",
        "    # Train a single model to play as each agent in a parallel environment\n",
        "    env = env_fn.parallel_env(**env_kwargs)\n",
        "    env = ss.color_reduction_v0(env, mode='full')\n",
        "    env = ss.resize_v1(env, x_size=84, y_size=84)\n",
        "    env = ss.frame_stack_v1(env, 4)\n",
        "\n",
        "    env.reset(seed = seed)\n",
        "\n",
        "    eval_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
        "    eval_env = ss.concat_vec_envs_v1(eval_env, n_training_envs, num_cpus=2, base_class=\"stable_baselines3\")\n",
        "\n",
        "    env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
        "    env = ss.concat_vec_envs_v1(env, n_training_envs, num_cpus=2, base_class=\"stable_baselines3\")\n",
        "\n",
        "\n",
        "    print(f\"Starting training\")\n",
        "\n",
        "    # Create callback that evaluates agent for 10 episodes every 20000 training environment steps.\n",
        "    eval_callback = EvalCallback(eval_env, best_model_save_path=temp_eval_log_dir,\n",
        "                             log_path=temp_eval_log_dir, eval_freq=max(20000 // n_training_envs, 1),\n",
        "                             n_eval_episodes=10, deterministic=True,\n",
        "                             render=False)\n",
        "\n",
        "    if os.path.exists(\"/content/drive/MyDrive/2A_pong_ppo/ppo_model.zip\"):\n",
        "      model = PPO.load(\"/content/drive/MyDrive/2A_pong_ppo/ppo_model_2mil\", env=env)\n",
        "    else:\n",
        "      model = PPO(\n",
        "            CnnPolicy,\n",
        "            env,\n",
        "            learning_rate=3e-4,  # Lower learning rate for stable training\n",
        "            n_steps=2048,        # Increase number of steps per update\n",
        "            batch_size=64,       # Batch size for each update\n",
        "            n_epochs=10,         # Number of epochs to optimize the surrogate loss\n",
        "            gamma=0.99,          # Discount factor\n",
        "            gae_lambda=0.95,     # Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
        "            clip_range=0.2,      # Clipping parameter\n",
        "            ent_coef=0.1,       # Coefficient for entropy\n",
        "            vf_coef=0.5,         # Coefficient for value function loss\n",
        "            max_grad_norm=0.5,   # Maximum norm for gradient clipping\n",
        "            verbose=1,\n",
        "        )\n",
        "\n",
        "    model.learn(total_timesteps=steps, callback=eval_callback)\n",
        "\n",
        "    model.save(\"/content/drive/MyDrive/2A_pong_ppo/ppo_model_2mil\")\n",
        "\n",
        "    print(\"Model has been saved.\")\n",
        "    print(f\"Finished training on {str(env.unwrapped.metadata['name'])}.\")\n",
        "    env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_DhUhiI8Iyj"
      },
      "outputs": [],
      "source": [
        "def resize_frame(frame, macro_block_size=16):\n",
        "    height, width, _ = frame.shape\n",
        "    new_height = (height + macro_block_size - 1) // macro_block_size * macro_block_size\n",
        "    new_width = (width + macro_block_size - 1) // macro_block_size * macro_block_size\n",
        "    resized_frame = np.array(Image.fromarray(frame).resize((new_width, new_height)))\n",
        "    return resized_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rqYXd4ep8LSs"
      },
      "outputs": [],
      "source": [
        "def eval(env_fn, num_games: int = 100, render_mode: str | None = None, **env_kwargs):\n",
        "    # Evaluate a trained agent vs a random agent\n",
        "    env = env_fn.env(render_mode=\"rgb_array\", **env_kwargs)\n",
        "    env = ss.color_reduction_v0(env, mode='full')\n",
        "    env = ss.resize_v1(env, x_size=84, y_size=84)\n",
        "    env = ss.frame_stack_v1(env, 4)\n",
        "\n",
        "    print(f\"\\nStarting evaluation\")\n",
        "\n",
        "    try:\n",
        "        latest_policy = max(glob.glob(\"/content/drive/MyDrive/2A_pong_ppo/ppo_model_2mil.zip\"))\n",
        "    except ValueError:\n",
        "        print(\"Policy not found.\")\n",
        "        exit(0)\n",
        "\n",
        "    model = PPO.load(latest_policy)\n",
        "\n",
        "    rewards = {agent: 0 for agent in env.possible_agents}\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    # train using the Parallel API but evaluate using the AEC API\n",
        "    # using he same SB3 model for every agent\n",
        "    for i in range(num_games):\n",
        "        env.reset(seed=i)\n",
        "\n",
        "        for agent in env.agent_iter():\n",
        "            obs, reward, termination, truncation, info = env.last()\n",
        "\n",
        "            for a in env.agents:\n",
        "                rewards[a] += env.rewards[a]\n",
        "            if termination or truncation:\n",
        "                break\n",
        "            else:\n",
        "                act = model.predict(obs, deterministic=True)[0]\n",
        "\n",
        "            env.step(act)\n",
        "\n",
        "            if render_mode == \"human\":\n",
        "                frame = env.render()\n",
        "                resized_frame = resize_frame(frame)\n",
        "                frames.append(resized_frame)\n",
        "    env.close()\n",
        "\n",
        "    avg_reward = sum(rewards.values()) / len(rewards.values())\n",
        "    print(\"Rewards: \", rewards)\n",
        "    print(f\"Avg reward: {avg_reward}\")\n",
        "    if render_mode == \"human\":\n",
        "      # Create a video from frames using moviepy\n",
        "        clip = ImageSequenceClip(frames, fps=10)\n",
        "        clip.write_videofile('/content/drive/MyDrive/2A_pong_ppo/video_2mil.mp4')\n",
        "\n",
        "        print(\"Evaluation saved as /content/drive/MyDrive/2A_pong_ppo/video_2mil.mp4\")\n",
        "    return avg_reward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6_RgrnYZVge"
      },
      "outputs": [],
      "source": [
        "def plot():\n",
        "    # Load existing evaluation results if they exist\n",
        "    results_file = os.path.join(log_dir, 'evaluations.npz')\n",
        "    if os.path.exists(results_file):\n",
        "        old_results = np.load(results_file)\n",
        "        old_timesteps = old_results['timesteps']\n",
        "        old_results_raw = old_results['results']\n",
        "    else:\n",
        "        old_timesteps = np.array([])\n",
        "        old_results_raw = np.array([]).reshape(0, 5)\n",
        "\n",
        "    # Load new evaluation results\n",
        "    new_results_file = os.path.join(temp_eval_log_dir, 'evaluations.npz')\n",
        "    new_results = np.load(new_results_file)\n",
        "    new_timesteps = new_results['timesteps']\n",
        "    new_results_raw = new_results['results']\n",
        "\n",
        "    # Append new results to old results\n",
        "    if old_timesteps.size > 0:\n",
        "        combined_timesteps = np.concatenate((old_timesteps, new_timesteps + old_timesteps[-1]))\n",
        "        combined_results_raw = np.concatenate((old_results_raw, new_results_raw))\n",
        "    else:\n",
        "        combined_timesteps = new_timesteps\n",
        "        combined_results_raw = new_results_raw\n",
        "\n",
        "    # Save combined results\n",
        "    np.savez(results_file, timesteps=combined_timesteps, results=combined_results_raw)\n",
        "\n",
        "    # Calculate the mean reward for each evaluation point\n",
        "    combined_results_mean = combined_results_raw.mean(axis=1)\n",
        "\n",
        "    # Plot the results\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(combined_timesteps, combined_results_mean)\n",
        "    plt.xlabel('Timesteps')\n",
        "    plt.ylabel('Mean Reward')\n",
        "    plt.title('Evaluation Rewards Over Time')\n",
        "    plt.grid()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0kIhjAHZuaq"
      },
      "outputs": [],
      "source": [
        "def show_video(video_path):\n",
        "    mp4 = open(video_path, 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(f'<video width=\"480\" height=\"320\" controls><source src=\"{data_url}\" type=\"video/mp4\"></video>')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRhyITFbcgnM",
        "outputId": "57c61289-b023-490b-a99a-acbb3d11d660"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training\n",
            "Using cpu device\n",
            "Wrapping the env in a VecTransposeImage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x7b37f6728520> != <supersuit.vector.sb3_vector_wrapper.SB3VecEnvWrapper object at 0x7b38e0a1b190>\n",
            "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 338   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 48    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 70          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 465         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008626994 |\n",
            "|    clip_fraction        | 0.00519     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | -0.00295    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.163      |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00134    |\n",
            "|    value_loss           | 0.0532      |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval num_timesteps=40000, episode_reward=-416.00 +/- 419.00\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+05        |\n",
            "|    mean_reward          | -416         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 40000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054349527 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 4.17e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.158       |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | 0.000156     |\n",
            "|    value_loss           | 0.0453       |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 9     |\n",
            "|    iterations      | 3     |\n",
            "|    time_elapsed    | 5223  |\n",
            "|    total_timesteps | 49152 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 11          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 5682        |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006791824 |\n",
            "|    clip_fraction        | 0.00262     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | -5.04e-05   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.16       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00102    |\n",
            "|    value_loss           | 0.0498      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010788208 |\n",
            "|    clip_fraction        | 0.00773     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | -0.000185   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.139      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00129    |\n",
            "|    value_loss           | 0.0497      |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 13    |\n",
            "|    iterations      | 5     |\n",
            "|    time_elapsed    | 6283  |\n",
            "|    total_timesteps | 81920 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 6729         |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037704175 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.154       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.000476    |\n",
            "|    value_loss           | 0.0527       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 15           |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 7180         |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032259095 |\n",
            "|    clip_fraction        | 0.00123      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -0.000245    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.157       |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | 0.000171     |\n",
            "|    value_loss           | 0.0495       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=-416.00 +/- 419.00\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+05       |\n",
            "|    mean_reward          | -416        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 120000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007724457 |\n",
            "|    clip_fraction        | 0.00072     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | -7.15e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.176      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.000811   |\n",
            "|    value_loss           | 0.0497      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 10     |\n",
            "|    iterations      | 8      |\n",
            "|    time_elapsed    | 12173  |\n",
            "|    total_timesteps | 131072 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 11         |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 12610      |\n",
            "|    total_timesteps      | 147456     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00605705 |\n",
            "|    clip_fraction        | 0.00113    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.79      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.154     |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.00075   |\n",
            "|    value_loss           | 0.054      |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=-416.00 +/- 419.00\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+05        |\n",
            "|    mean_reward          | -416         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 160000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029302475 |\n",
            "|    clip_fraction        | 7.93e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -4.89e-06    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.173       |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.000434    |\n",
            "|    value_loss           | 0.0529       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 9      |\n",
            "|    iterations      | 10     |\n",
            "|    time_elapsed    | 17461  |\n",
            "|    total_timesteps | 163840 |\n",
            "-------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 10           |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 17894        |\n",
            "|    total_timesteps      | 180224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019300076 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.15        |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.000332    |\n",
            "|    value_loss           | 0.0529       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 10           |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 18340        |\n",
            "|    total_timesteps      | 196608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065037594 |\n",
            "|    clip_fraction        | 2.44e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.177       |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    value_loss           | 0.0465       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.91e+03     |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 200000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018209927 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.157       |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.000355    |\n",
            "|    value_loss           | 0.0497       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 11     |\n",
            "|    iterations      | 13     |\n",
            "|    time_elapsed    | 18910  |\n",
            "|    total_timesteps | 212992 |\n",
            "-------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 11           |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 19366        |\n",
            "|    total_timesteps      | 229376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026533783 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.167       |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.000468    |\n",
            "|    value_loss           | 0.0497       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.91e+03     |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 240000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007318849 |\n",
            "|    clip_fraction        | 2.44e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.145       |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.000181    |\n",
            "|    value_loss           | 0.054        |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 12     |\n",
            "|    iterations      | 15     |\n",
            "|    time_elapsed    | 19937  |\n",
            "|    total_timesteps | 245760 |\n",
            "-------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 12           |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 20385        |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077924505 |\n",
            "|    clip_fraction        | 3.66e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.153       |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000387    |\n",
            "|    value_loss           | 0.055        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 13           |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 20845        |\n",
            "|    total_timesteps      | 278528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016274592 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.165       |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.000363    |\n",
            "|    value_loss           | 0.0518       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=280000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 280000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005907929 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.136      |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.000922   |\n",
            "|    value_loss           | 0.0518      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 13     |\n",
            "|    iterations      | 18     |\n",
            "|    time_elapsed    | 21441  |\n",
            "|    total_timesteps | 294912 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 21912       |\n",
            "|    total_timesteps      | 311296      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012064085 |\n",
            "|    clip_fraction        | 0.0169      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.155      |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00293    |\n",
            "|    value_loss           | 0.0522      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=320000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.91e+03     |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 320000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040439023 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.132       |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | 0.000155     |\n",
            "|    value_loss           | 0.0507       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 14     |\n",
            "|    iterations      | 20     |\n",
            "|    time_elapsed    | 22522  |\n",
            "|    total_timesteps | 327680 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 23020       |\n",
            "|    total_timesteps      | 344064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010524539 |\n",
            "|    clip_fraction        | 0.0204      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.141      |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00261    |\n",
            "|    value_loss           | 0.0481      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=360000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 360000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008355562 |\n",
            "|    clip_fraction        | 0.00359     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.162      |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0014     |\n",
            "|    value_loss           | 0.0476      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 15     |\n",
            "|    iterations      | 22     |\n",
            "|    time_elapsed    | 23656  |\n",
            "|    total_timesteps | 360448 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 24160       |\n",
            "|    total_timesteps      | 376832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002108322 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.163      |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.000151   |\n",
            "|    value_loss           | 0.0549      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 24679       |\n",
            "|    total_timesteps      | 393216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010924387 |\n",
            "|    clip_fraction        | 0.00825     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.168      |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.000811   |\n",
            "|    value_loss           | 0.0518      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=400000, episode_reward=-416.00 +/- 419.00\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+05        |\n",
            "|    mean_reward          | -416         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 400000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018995588 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -3.58e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.137       |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.000109    |\n",
            "|    value_loss           | 0.0465       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 13     |\n",
            "|    iterations      | 25     |\n",
            "|    time_elapsed    | 29607  |\n",
            "|    total_timesteps | 409600 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 26          |\n",
            "|    time_elapsed         | 30162       |\n",
            "|    total_timesteps      | 425984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004264217 |\n",
            "|    clip_fraction        | 0.0112      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | -2.86e-06   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.154      |\n",
            "|    n_updates            | 250         |\n",
            "|    policy_gradient_loss | -0.00117    |\n",
            "|    value_loss           | 0.0508      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=440000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 440000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008654948 |\n",
            "|    clip_fraction        | 0.00101     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.157      |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.000498   |\n",
            "|    value_loss           | 0.055       |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 14     |\n",
            "|    iterations      | 27     |\n",
            "|    time_elapsed    | 30865  |\n",
            "|    total_timesteps | 442368 |\n",
            "-------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 14         |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 31454      |\n",
            "|    total_timesteps      | 458752     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00838235 |\n",
            "|    clip_fraction        | 0.00815    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.79      |\n",
            "|    explained_variance   | -4.53e-06  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.149     |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | -0.000993  |\n",
            "|    value_loss           | 0.0497     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 32058        |\n",
            "|    total_timesteps      | 475136       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028611887 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.171       |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | 1.96e-05     |\n",
            "|    value_loss           | 0.0447       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=480000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 480000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005732027 |\n",
            "|    clip_fraction        | 0.000543    |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.131      |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.000515   |\n",
            "|    value_loss           | 0.0483      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 14     |\n",
            "|    iterations      | 30     |\n",
            "|    time_elapsed    | 32809  |\n",
            "|    total_timesteps | 491520 |\n",
            "-------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 15           |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 33427        |\n",
            "|    total_timesteps      | 507904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051719616 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.178       |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.000591    |\n",
            "|    value_loss           | 0.0517       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=520000, episode_reward=-416.00 +/- 419.00\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+05       |\n",
            "|    mean_reward          | -416        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 520000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005129284 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.165      |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.00034    |\n",
            "|    value_loss           | 0.0497      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 13     |\n",
            "|    iterations      | 32     |\n",
            "|    time_elapsed    | 38334  |\n",
            "|    total_timesteps | 524288 |\n",
            "-------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 13           |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 38939        |\n",
            "|    total_timesteps      | 540672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049611134 |\n",
            "|    clip_fraction        | 0.000879     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.144       |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.000556    |\n",
            "|    value_loss           | 0.0476       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 39549        |\n",
            "|    total_timesteps      | 557056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015352337 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.173       |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.000191    |\n",
            "|    value_loss           | 0.051        |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=560000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.91e+03     |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 560000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0062447814 |\n",
            "|    clip_fraction        | 0.00104      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.14        |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00113     |\n",
            "|    value_loss           | 0.0512       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 14     |\n",
            "|    iterations      | 35     |\n",
            "|    time_elapsed    | 40276  |\n",
            "|    total_timesteps | 573440 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 40870       |\n",
            "|    total_timesteps      | 589824      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006236892 |\n",
            "|    clip_fraction        | 0.00349     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | -4.77e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.153      |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.000581   |\n",
            "|    value_loss           | 0.0545      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=600000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.91e+03     |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 600000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018794962 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.157       |\n",
            "|    n_updates            | 360          |\n",
            "|    policy_gradient_loss | -0.000375    |\n",
            "|    value_loss           | 0.0497       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 14     |\n",
            "|    iterations      | 37     |\n",
            "|    time_elapsed    | 41592  |\n",
            "|    total_timesteps | 606208 |\n",
            "-------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 42200        |\n",
            "|    total_timesteps      | 622592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019330493 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.171       |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.000302    |\n",
            "|    value_loss           | 0.0475       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 14           |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 42813        |\n",
            "|    total_timesteps      | 638976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038134402 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.166       |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.000576    |\n",
            "|    value_loss           | 0.0571       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=640000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.91e+03     |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 640000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047794227 |\n",
            "|    clip_fraction        | 0.00884      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.171       |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00133     |\n",
            "|    value_loss           | 0.0497       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 15     |\n",
            "|    iterations      | 40     |\n",
            "|    time_elapsed    | 43565  |\n",
            "|    total_timesteps | 655360 |\n",
            "-------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 15            |\n",
            "|    iterations           | 41            |\n",
            "|    time_elapsed         | 44193         |\n",
            "|    total_timesteps      | 671744        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00091483316 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.79         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.166        |\n",
            "|    n_updates            | 400           |\n",
            "|    policy_gradient_loss | -0.000207     |\n",
            "|    value_loss           | 0.0538        |\n",
            "-------------------------------------------\n",
            "Eval num_timesteps=680000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.91e+03     |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 680000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036135276 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.13        |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00067     |\n",
            "|    value_loss           | 0.0487       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 15     |\n",
            "|    iterations      | 42     |\n",
            "|    time_elapsed    | 44962  |\n",
            "|    total_timesteps | 688128 |\n",
            "-------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 15           |\n",
            "|    iterations           | 43           |\n",
            "|    time_elapsed         | 45604        |\n",
            "|    total_timesteps      | 704512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016240822 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.148       |\n",
            "|    n_updates            | 420          |\n",
            "|    policy_gradient_loss | -0.000169    |\n",
            "|    value_loss           | 0.0474       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=720000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | 0           |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 720000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003662737 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.133      |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.000879   |\n",
            "|    value_loss           | 0.0507      |\n",
            "-----------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 15     |\n",
            "|    iterations      | 44     |\n",
            "|    time_elapsed    | 46364  |\n",
            "|    total_timesteps | 720896 |\n",
            "-------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 15           |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 47002        |\n",
            "|    total_timesteps      | 737280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022376536 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.151       |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000537    |\n",
            "|    value_loss           | 0.0476       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 15           |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 47637        |\n",
            "|    total_timesteps      | 753664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006483764 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.134       |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | 0.000216     |\n",
            "|    value_loss           | 0.0497       |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=760000, episode_reward=0.00 +/- 21.00\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 2.91e+03     |\n",
            "|    mean_reward          | 0            |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 760000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048599592 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.154       |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.000656    |\n",
            "|    value_loss           | 0.0518       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 15     |\n",
            "|    iterations      | 47     |\n",
            "|    time_elapsed    | 48408  |\n",
            "|    total_timesteps | 770048 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 16          |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 49056       |\n",
            "|    total_timesteps      | 786432      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004639115 |\n",
            "|    clip_fraction        | 0.00369     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.145      |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.00129    |\n",
            "|    value_loss           | 0.0539      |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=800000, episode_reward=-416.00 +/- 419.00\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+05        |\n",
            "|    mean_reward          | -416         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 800000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046976507 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.142       |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -0.000265    |\n",
            "|    value_loss           | 0.0507       |\n",
            "------------------------------------------\n",
            "-------------------------------\n",
            "| time/              |        |\n",
            "|    fps             | 14     |\n",
            "|    iterations      | 49     |\n",
            "|    time_elapsed    | 54036  |\n",
            "|    total_timesteps | 802816 |\n",
            "-------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 14          |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 54700       |\n",
            "|    total_timesteps      | 819200      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002054158 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.183      |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.000371   |\n",
            "|    value_loss           | 0.0508      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 51          |\n",
            "|    time_elapsed         | 55359       |\n",
            "|    total_timesteps      | 835584      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001636786 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.79       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.149      |\n",
            "|    n_updates            | 500         |\n",
            "|    policy_gradient_loss | -0.000147   |\n",
            "|    value_loss           | 0.0507      |\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    display = Display(visible=0, size=(1400, 900))\n",
        "    display.start()\n",
        "\n",
        "    env_fn = pong_v3\n",
        "    env_kwargs = {}\n",
        "\n",
        "    # Train a model (takes ~3 minutes on GPU)\n",
        "    train_pong_supersuit(env_fn, steps=2000000, seed = 0, **env_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msULzJuaEHZj"
      },
      "outputs": [],
      "source": [
        "    plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlFaJ5YTZ0CV"
      },
      "outputs": [],
      "source": [
        "    # Evaluate 10 games (average reward should be positive but can vary significantly)\n",
        "    eval(env_fn, num_games=10, render_mode=None, **env_kwargs)\n",
        "    # Watch 2 games\n",
        "    eval(env_fn, num_games=2, render_mode=\"human\", **env_kwargs)\n",
        "    # Display the video after evaluation\n",
        "    video_path = \"/content/drive/MyDrive/2A_pong_ppo/video_2mil.mp4\"\n",
        "    display.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSrN2WWN8Uk-"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# Convert mp4 to base64\n",
        "video_path = \"/content/drive/MyDrive/2A_pong_ppo/video_2mil.mp4\"\n",
        "video = open(video_path, \"rb\").read()\n",
        "video_encoded = b64encode(video).decode()\n",
        "\n",
        "# Display video\n",
        "HTML(f\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "      <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMD1cwBrSBC31M9EtLhULey",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}