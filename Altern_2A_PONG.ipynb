{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPDAoW13Z2zVfns/wfY5NOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchaparov/Dynamic_Pricing_MARL/blob/main/Altern_2A_PONG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install swig\n",
        "!pip install \"pettingzoo\"\n",
        "!pip install \"stable-baselines3\"\n",
        "!pip install \"supersuit\"\n",
        "!pip install pymunk\n",
        "!pip install pyvirtualdisplay imageio[ffmpeg]\n",
        "!apt-get install -y xvfb\n",
        "!pip install tensorboard\n",
        "!pip install pillow\n",
        "!pip install multi_agent_ale_py\n",
        "!pip install autorom\n",
        "!pip install moviepy\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83L9ueMe0NSA",
        "outputId": "2a3fac95-4667-4fa7-8b18-8d5b5433fe35"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 2s (524 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 121913 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pettingzoo\n",
            "  Downloading pettingzoo-1.24.3-py3-none-any.whl (847 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m847.8/847.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pettingzoo) (1.25.2)\n",
            "Collecting gymnasium>=0.28.0 (from pettingzoo)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->pettingzoo) (4.12.1)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.28.0->pettingzoo)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, pettingzoo\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 pettingzoo-1.24.3\n",
            "Collecting stable-baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.3.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 stable-baselines3-2.3.2\n",
            "Collecting supersuit\n",
            "  Downloading SuperSuit-3.9.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from supersuit) (1.25.2)\n",
            "Requirement already satisfied: gymnasium>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from supersuit) (0.29.1)\n",
            "Collecting tinyscaler>=1.2.6 (from supersuit)\n",
            "  Downloading tinyscaler-1.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.1/517.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (4.12.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.1->supersuit) (0.0.4)\n",
            "Installing collected packages: tinyscaler, supersuit\n",
            "Successfully installed supersuit-3.9.2 tinyscaler-1.2.7\n",
            "Collecting pymunk\n",
            "  Downloading pymunk-6.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from pymunk) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.15.0->pymunk) (2.22)\n",
            "Installing collected packages: pymunk\n",
            "Successfully installed pymunk-6.8.1\n",
            "Collecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (9.4.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (0.5.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg->imageio[ffmpeg]) (67.7.2)\n",
            "Installing collected packages: pyvirtualdisplay\n",
            "Successfully installed pyvirtualdisplay-3.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 7,813 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.10 [863 kB]\n",
            "Fetched 7,813 kB in 3s (2,897 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 122666 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.64.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting multi_agent_ale_py\n",
            "  Downloading multi-agent-ale-py-0.1.11.tar.gz (551 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from multi_agent_ale_py) (1.25.2)\n",
            "Building wheels for collected packages: multi_agent_ale_py\n",
            "  Building wheel for multi_agent_ale_py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multi_agent_ale_py: filename=multi_agent_ale_py-0.1.11-cp310-cp310-linux_x86_64.whl size=721821 sha256=b2b4a9242670e15ad24de4a923a8dfebd2a89b3441d65febfcc776549ec07965\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/75/64/8ad68adb0da26405c4b18c291b9c322c44d3e99c16b0f3b890\n",
            "Successfully built multi_agent_ale_py\n",
            "Installing collected packages: multi_agent_ale_py\n",
            "Successfully installed multi_agent_ale_py-0.1.11\n",
            "Collecting autorom\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (2024.6.2)\n",
            "Installing collected packages: autorom\n",
            "Successfully installed autorom-0.6.1\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.6.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5xv1sQy0NpM",
        "outputId": "6f5fb74c-02bd-4247-d25f-66d1e2cb81ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.10/dist-packages/AutoROM/roms\n",
            "\t/usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/adventure.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/air_raid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/alien.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/amidar.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/assault.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/asterix.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/asteroids.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/atlantis.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/atlantis2.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/backgammon.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/bank_heist.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/basic_math.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/battle_zone.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/beam_rider.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/berzerk.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/blackjack.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/bowling.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/boxing.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/breakout.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/carnival.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/casino.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/centipede.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/chopper_command.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/combat.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/crazy_climber.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/crossbow.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/darkchambers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/defender.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/demon_attack.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/donkey_kong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/double_dunk.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/earthworld.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/elevator_action.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/enduro.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/entombed.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/et.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/et.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/fishing_derby.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/flag_capture.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/freeway.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/frogger.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/frostbite.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/galaxian.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/gopher.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/gravitar.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/hangman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/haunted_house.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/hero.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/human_cannonball.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/ice_hockey.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/jamesbond.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/journey_escape.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/joust.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/kaboom.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/kangaroo.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/keystone_kapers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/king_kong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/klax.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/koolaid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/krull.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/kung_fu_master.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/laser_gates.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/lost_luggage.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/mario_bros.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/maze_craze.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/miniature_golf.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/montezuma_revenge.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/mr_do.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/ms_pacman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/name_this_game.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/othello.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pacman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/phoenix.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pitfall.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pitfall2.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pong.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/pooyan.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/private_eye.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/qbert.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/riverraid.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/road_runner.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/robotank.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/seaquest.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/sir_lancelot.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/skiing.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/solaris.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/space_invaders.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/space_war.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/star_gunner.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/superman.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/surround.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/tennis.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/tetris.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/tic_tac_toe_3d.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/time_pilot.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/trondead.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/turmoil.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/tutankham.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/up_n_down.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/venture.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/video_checkers.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/video_chess.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/video_cube.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/video_pinball.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/warlords.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/wizard_of_wor.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/word_zapper.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/yars_revenge.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/AutoROM/roms/zaxxon.bin\n",
            "Installed /usr/local/lib/python3.10/dist-packages/multi_agent_ale_py/roms/zaxxon.bin\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "import imageio\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import time\n",
        "import supersuit as ss\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo import CnnPolicy\n",
        "from pettingzoo.atari import pong_v3\n",
        "from PIL import Image\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback, BaseCallback\n",
        "from stable_baselines3.common.logger import configure\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "log_dir = \"/content/drive/MyDrive/2A_PONG_ppo/\"\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "\n",
        "tensorboard_log_dir = \"/content/drive/MyDrive/2A_PONG_ppo/tensorboard/\"\n",
        "os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
        "\n",
        "n_training_envs = 4\n",
        "\n",
        "# Define paths for saving models and evaluation results\n",
        "left_model_path = \"/content/drive/MyDrive/2A_PONG_ppo/left_ppo_10x20k\"\n",
        "right_model_path = \"/content/drive/MyDrive/2A_PONG_ppo/right_ppo_10x20k\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUi5jI-k0NvM",
        "outputId": "4bef5b70-b9ed-4aca-cb9e-ceba8826471d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/skimage/util/dtype.py:27: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  np.bool8: (False, True),\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/fx/painting.py:7: DeprecationWarning: Please use `sobel` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import sobel\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TensorboardCallback(BaseCallback):\n",
        "    def __init__(self, verbose=0):\n",
        "        super(TensorboardCallback, self).__init__(verbose)\n",
        "        self.rewards = []\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        reward = self.locals['rewards'][0]  # assuming single environment (not vectorized)\n",
        "        self.rewards.append(reward)\n",
        "\n",
        "        if len(self.rewards) >= 100:\n",
        "            mean_reward = np.mean(self.rewards[-100:])\n",
        "            self.logger.record('mean_reward', mean_reward)\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "id": "LiZvE9olCon3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_PONG_supersuit(env_fn, steps: int = 20000, seed: int | None = 0, **env_kwargs):\n",
        "    # Train a single model to play as each agent in a cooperative Parallel environment\n",
        "    env = env_fn.parallel_env(**env_kwargs)\n",
        "    env = ss.color_reduction_v0(env, mode='full')\n",
        "    env = ss.resize_v1(env, x_size=84, y_size=84)\n",
        "    env = ss.frame_stack_v1(env, 4)\n",
        "\n",
        "    env.reset(seed = seed)\n",
        "\n",
        "    eval_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
        "    eval_env = ss.concat_vec_envs_v1(eval_env, n_training_envs, num_cpus=2, base_class=\"stable_baselines3\")\n",
        "\n",
        "    env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
        "    env = ss.concat_vec_envs_v1(env, n_training_envs, num_cpus=2, base_class=\"stable_baselines3\")\n",
        "\n",
        "\n",
        "    print(f\"Starting training\")\n",
        "\n",
        "    # Load or create models for both agents\n",
        "    if os.path.exists(left_model_path + \".zip\") and os.path.exists(right_model_path + \".zip\"):\n",
        "        model_left = PPO.load(left_model_path, env=env)\n",
        "        model_right = PPO.load(right_model_path, env=env)\n",
        "    else:\n",
        "        model_left = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=tensorboard_log_dir)\n",
        "        model_right = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=tensorboard_log_dir)\n",
        "\n",
        "    # Callback for saving models and logging to TensorBoard\n",
        "    eval_callback_left = EvalCallback(eval_env, best_model_save_path=left_model_path,\n",
        "                                      log_path=tensorboard_log_dir, eval_freq=5000,\n",
        "                                      deterministic=True, render=False)\n",
        "\n",
        "    eval_callback_right = EvalCallback(eval_env, best_model_save_path=right_model_path,\n",
        "                                       log_path=tensorboard_log_dir, eval_freq=5000,\n",
        "                                       deterministic=True, render=False)\n",
        "\n",
        "    tensorboard_callback = TensorboardCallback()\n",
        "\n",
        "    for i in range(10):  # 30 iterations of self-play training\n",
        "        print(f\"Self-play iteration {i+1}\")\n",
        "\n",
        "        # Train the left agent\n",
        "        model_left.learn(total_timesteps=steps, callback=[eval_callback_left, tensorboard_callback])\n",
        "        model_left.save(left_model_path)  # Save the left agent\n",
        "\n",
        "        # Train the right agent\n",
        "        model_right.learn(total_timesteps=steps, callback=[eval_callback_right, tensorboard_callback])\n",
        "        model_right.save(right_model_path)  # Save the right agent\n",
        "\n",
        "    print(\"Model has been saved.\")\n",
        "    print(f\"Finished training on {str(env.unwrapped.metadata['name'])}.\")\n",
        "    env.close()\n"
      ],
      "metadata": {
        "id": "cZl7wErO0Nzm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_frame(frame, macro_block_size=16):\n",
        "    height, width, _ = frame.shape\n",
        "    new_height = (height + macro_block_size - 1) // macro_block_size * macro_block_size\n",
        "    new_width = (width + macro_block_size - 1) // macro_block_size * macro_block_size\n",
        "    resized_frame = np.array(Image.fromarray(frame).resize((new_width, new_height)))\n",
        "    return resized_frame"
      ],
      "metadata": {
        "id": "gWXdetcS0N3o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_timesteps(env_fn, num_timesteps: int = 1000, render_mode: str | None = None, **env_kwargs):\n",
        "    # Evaluate trained agents for a fixed number of timesteps\n",
        "    env = env_fn.env(render_mode=\"rgb_array\", **env_kwargs)\n",
        "    env = ss.color_reduction_v0(env, mode='full')\n",
        "    env = ss.resize_v1(env, x_size=84, y_size=84)\n",
        "    env = ss.frame_stack_v1(env, 4)\n",
        "\n",
        "    print(f\"\\nStarting evaluation\")\n",
        "\n",
        "    # Load the latest policies for both agents\n",
        "    try:\n",
        "        latest_policy_left = max(glob.glob(\"/content/drive/MyDrive/2A_PONG_ppo/left_ppo_10x20k.zip\"))\n",
        "    except ValueError:\n",
        "        print(\"Policy agent 1 not found.\")\n",
        "        exit(0)\n",
        "\n",
        "    try:\n",
        "        latest_policy_right = max(glob.glob(\"/content/drive/MyDrive/2A_PONG_ppo/right_ppo_10x20k.zip\"))\n",
        "    except ValueError:\n",
        "        print(\"Policy agent 2 not found.\")\n",
        "        exit(0)\n",
        "\n",
        "    model_left = PPO.load(latest_policy_left)\n",
        "    model_right = PPO.load(latest_policy_right)\n",
        "\n",
        "    rewards = {agent: 0 for agent in env.possible_agents}\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    # Run evaluation for a fixed number of timesteps\n",
        "    env.reset()\n",
        "    timestep = 0\n",
        "    while timestep < num_timesteps:\n",
        "        for agent in env.agent_iter():\n",
        "            obs, reward, termination, truncation, info = env.last()\n",
        "            rewards[agent] += reward\n",
        "\n",
        "            if termination or truncation:\n",
        "                env.step(None)\n",
        "            else:\n",
        "                if agent == \"first_0\":  # Assuming the first agent's identifier\n",
        "                    act = model_left.predict(obs, deterministic=True)[0]\n",
        "                else:  # Assuming the second agent's identifier\n",
        "                    act = model_right.predict(obs, deterministic=True)[0]\n",
        "                env.step(act)\n",
        "\n",
        "            if render_mode == \"human\":\n",
        "                frame = env.render()\n",
        "                resized_frame = resize_frame(frame)\n",
        "                frames.append(resized_frame)\n",
        "\n",
        "            timestep += 1\n",
        "            if timestep >= num_timesteps:\n",
        "                break\n",
        "        if timestep >= num_timesteps:\n",
        "            break\n",
        "\n",
        "    env.close()\n",
        "\n",
        "    avg_reward = sum(rewards.values()) / len(rewards.values())\n",
        "    print(\"Rewards: \", rewards)\n",
        "    print(f\"Avg reward: {avg_reward}\")\n",
        "\n",
        "    if render_mode == \"human\":\n",
        "        # Create a video from frames using moviepy\n",
        "        clip = ImageSequenceClip(frames, fps=10)\n",
        "        clip.write_videofile('/content/drive/MyDrive/2A_PONG_ppo/video_10x20k.mp4')\n",
        "\n",
        "        print(\"Evaluation saved as /content/drive/MyDrive/2A_PONG_ppo/video_10x20k.mp4\")\n",
        "    return avg_reward\n"
      ],
      "metadata": {
        "id": "DgpWMw1p0N8C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_video(video_path):\n",
        "    mp4 = open(video_path, 'rb').read()\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "    return HTML(f'<video width=\"480\" height=\"320\" controls><source src=\"{data_url}\" type=\"video/mp4\"></video>')\n"
      ],
      "metadata": {
        "id": "jUAnvpDv0OAE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    display = Display(visible=0, size=(1400, 900))\n",
        "    display.start()\n",
        "\n",
        "    env_fn = pong_v3\n",
        "    env_kwargs = {}\n",
        "\n",
        "    # Train a model\n",
        "    train_PONG_supersuit(env_fn, steps=20000, seed = 0, **env_kwargs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwZ1Beco0OCk",
        "outputId": "bbc93d9b-65cd-4f0c-8eaa-099cb11296eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training\n",
            "Using cpu device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Using cpu device\n",
            "Wrapping the env in a VecTransposeImage.\n",
            "Self-play iteration 1\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x78edc8fe61a0> != <supersuit.vector.sb3_vector_wrapper.SB3VecEnvWrapper object at 0x78edc8fe75e0>\n",
            "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 302   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 54    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-------------------------------------------\n",
            "| mean_reward             | 0.0           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 59            |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 551           |\n",
            "|    total_timesteps      | 32768         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 9.8806464e-05 |\n",
            "|    clip_fraction        | 0.000757      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.79         |\n",
            "|    explained_variance   | -0.0024       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.028         |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | 6.95e-05      |\n",
            "|    value_loss           | 0.0559        |\n",
            "-------------------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/callbacks.py:414: UserWarning: Training and eval env are not of the same type<stable_baselines3.common.vec_env.vec_transpose.VecTransposeImage object at 0x78eeaeeab670> != <supersuit.vector.sb3_vector_wrapper.SB3VecEnvWrapper object at 0x78edc8fe75e0>\n",
            "  warnings.warn(\"Training and eval env are not of the same type\" f\"{self.training_env} != {self.eval_env}\")\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 254   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 64    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| mean_reward             | 0.0          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 58           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 560          |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073927836 |\n",
            "|    clip_fraction        | 0.0136       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.79        |\n",
            "|    explained_variance   | -0.00316     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0344       |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.000524    |\n",
            "|    value_loss           | 0.0544       |\n",
            "------------------------------------------\n",
            "Self-play iteration 2\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=7232, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 2.91e+03 |\n",
            "|    mean_reward     | -4.2     |\n",
            "| mean_reward        | 0.01     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 7232     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 121   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 135   |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| mean_reward             | 0.0         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 51          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 637         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011887406 |\n",
            "|    clip_fraction        | 0.0373      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | -2.5e-06    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0287      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00242    |\n",
            "|    value_loss           | 0.054       |\n",
            "-----------------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_5\n",
            "Eval num_timesteps=7232, episode_reward=-332.20 +/- 410.53\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+05    |\n",
            "|    mean_reward     | -332     |\n",
            "| mean_reward        | -0.01    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 7232     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 6     |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 2579  |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| mean_reward             | 0.0         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 10          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 3081        |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009730499 |\n",
            "|    clip_fraction        | 0.0147      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | -0.00135    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0514      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0008     |\n",
            "|    value_loss           | 0.0509      |\n",
            "-----------------------------------------\n",
            "Self-play iteration 3\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_6\n",
            "Eval num_timesteps=14464, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 2.91e+03 |\n",
            "|    mean_reward     | -4.2     |\n",
            "| mean_reward        | 0.0      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 14464    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.01  |\n",
            "| time/              |       |\n",
            "|    fps             | 122   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 133   |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| mean_reward             | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 51           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 640          |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036897128 |\n",
            "|    clip_fraction        | 0.00293      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0208       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -9.59e-05    |\n",
            "|    value_loss           | 0.0508       |\n",
            "------------------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_7\n",
            "Eval num_timesteps=14464, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 2.91e+03 |\n",
            "|    mean_reward     | -4.2     |\n",
            "| mean_reward        | -0.01    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 14464    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "------------------------------\n",
            "| mean_reward        | 0.01  |\n",
            "| time/              |       |\n",
            "|    fps             | 124   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 131   |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| mean_reward             | -0.01        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 51           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 637          |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0094868895 |\n",
            "|    clip_fraction        | 0.0331       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.78        |\n",
            "|    explained_variance   | -3.54e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0488       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    value_loss           | 0.0466       |\n",
            "------------------------------------------\n",
            "Self-play iteration 4\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_8\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 305   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 53    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "Eval num_timesteps=21696, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | -4.2        |\n",
            "| mean_reward             | -0.01       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 21696       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011601768 |\n",
            "|    clip_fraction        | 0.0113      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.78       |\n",
            "|    explained_variance   | -1.67e-06   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0153      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.000882   |\n",
            "|    value_loss           | 0.0508      |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 51    |\n",
            "|    iterations      | 2     |\n",
            "|    time_elapsed    | 633   |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_9\n",
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 282   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 57    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "Eval num_timesteps=21696, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | -4.2        |\n",
            "| mean_reward             | 0.0         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 21696       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012551583 |\n",
            "|    clip_fraction        | 0.0195      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.74       |\n",
            "|    explained_variance   | -1.3e-05    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00447    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00109    |\n",
            "|    value_loss           | 0.0455      |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 49    |\n",
            "|    iterations      | 2     |\n",
            "|    time_elapsed    | 661   |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "Self-play iteration 5\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_10\n",
            "------------------------------\n",
            "| mean_reward        | 0.01  |\n",
            "| time/              |       |\n",
            "|    fps             | 311   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 52    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "Eval num_timesteps=28928, episode_reward=-332.20 +/- 410.53\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+05       |\n",
            "|    mean_reward          | -332        |\n",
            "| mean_reward             | -0.01       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 28928       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012764597 |\n",
            "|    clip_fraction        | 0.0301      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.74       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0172      |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00185    |\n",
            "|    value_loss           | 0.0487      |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 10    |\n",
            "|    iterations      | 2     |\n",
            "|    time_elapsed    | 3127  |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_11\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 302   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 54    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "Eval num_timesteps=28928, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | -4.2        |\n",
            "| mean_reward             | -0.01       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 28928       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012617688 |\n",
            "|    clip_fraction        | 0.0241      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.68       |\n",
            "|    explained_variance   | -1.91e-06   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00571     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00134    |\n",
            "|    value_loss           | 0.055       |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.01  |\n",
            "| time/              |       |\n",
            "|    fps             | 50    |\n",
            "|    iterations      | 2     |\n",
            "|    time_elapsed    | 643   |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "Self-play iteration 6\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_12\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 285   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 57    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| mean_reward             | -0.01       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 57          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 567         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011640886 |\n",
            "|    clip_fraction        | 0.00988     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00825     |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.000749   |\n",
            "|    value_loss           | 0.0381      |\n",
            "-----------------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_13\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 299   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 54    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| mean_reward             | -0.01       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 55          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 590         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014977146 |\n",
            "|    clip_fraction        | 0.0383      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.64       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0327      |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00191    |\n",
            "|    value_loss           | 0.054       |\n",
            "-----------------------------------------\n",
            "Self-play iteration 7\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_14\n",
            "Eval num_timesteps=3392, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 2.91e+03 |\n",
            "|    mean_reward     | -4.2     |\n",
            "| mean_reward        | 0.01     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 3392     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.01  |\n",
            "| time/              |       |\n",
            "|    fps             | 122   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 133   |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| mean_reward             | 0.0         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 49          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 660         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010733681 |\n",
            "|    clip_fraction        | 0.0137      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.74       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0363      |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.000839   |\n",
            "|    value_loss           | 0.0487      |\n",
            "-----------------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_15\n",
            "Eval num_timesteps=3392, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 2.91e+03 |\n",
            "|    mean_reward     | -4.2     |\n",
            "| mean_reward        | 0.01     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 3392     |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.01  |\n",
            "| time/              |       |\n",
            "|    fps             | 124   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 131   |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| mean_reward             | 0.01        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 50          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 647         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013572232 |\n",
            "|    clip_fraction        | 0.0281      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.45       |\n",
            "|    explained_variance   | -1.19e-06   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0161     |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0012     |\n",
            "|    value_loss           | 0.0572      |\n",
            "-----------------------------------------\n",
            "Self-play iteration 8\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_16\n",
            "Eval num_timesteps=10624, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 2.91e+03 |\n",
            "|    mean_reward     | -4.2     |\n",
            "| mean_reward        | -0.01    |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10624    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 119   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 137   |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "-----------------------------------------\n",
            "| mean_reward             | 0.0         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 49          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 658         |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010216144 |\n",
            "|    clip_fraction        | 0.014       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.71       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0357      |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00081    |\n",
            "|    value_loss           | 0.0529      |\n",
            "-----------------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_17\n",
            "Eval num_timesteps=10624, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 2.91e+03 |\n",
            "|    mean_reward     | -4.2     |\n",
            "| mean_reward        | 0.01     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10624    |\n",
            "---------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.01  |\n",
            "| time/              |       |\n",
            "|    fps             | 122   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 133   |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| mean_reward             | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 49           |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 655          |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037686129 |\n",
            "|    clip_fraction        | 0.0211       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | -1.67e-06    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0572       |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.000812    |\n",
            "|    value_loss           | 0.0593       |\n",
            "------------------------------------------\n",
            "Self-play iteration 9\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_18\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 296   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 55    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "Eval num_timesteps=17856, episode_reward=-332.20 +/- 410.53\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 1e+05        |\n",
            "|    mean_reward          | -332         |\n",
            "| mean_reward             | -0.01        |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 17856        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054077366 |\n",
            "|    clip_fraction        | 0.0281       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0463       |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00115     |\n",
            "|    value_loss           | 0.036        |\n",
            "------------------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 10    |\n",
            "|    iterations      | 2     |\n",
            "|    time_elapsed    | 3170  |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_19\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 277   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 58    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "Eval num_timesteps=17856, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 2.91e+03    |\n",
            "|    mean_reward          | -4.2        |\n",
            "| mean_reward             | 0.01        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 17856       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009651526 |\n",
            "|    clip_fraction        | 0.0358      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.49       |\n",
            "|    explained_variance   | -5.96e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0177      |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.00164    |\n",
            "|    value_loss           | 0.0582      |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 47    |\n",
            "|    iterations      | 2     |\n",
            "|    time_elapsed    | 687   |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "Self-play iteration 10\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_20\n",
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 309   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 52    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "Eval num_timesteps=25088, episode_reward=-332.20 +/- 410.53\n",
            "Episode length: 100000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+05       |\n",
            "|    mean_reward          | -332        |\n",
            "| mean_reward             | 0.0         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 25088       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009717349 |\n",
            "|    clip_fraction        | 0.0263      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00687     |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0013     |\n",
            "|    value_loss           | 0.0413      |\n",
            "-----------------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | -0.01 |\n",
            "| time/              |       |\n",
            "|    fps             | 10    |\n",
            "|    iterations      | 2     |\n",
            "|    time_elapsed    | 3178  |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "Logging to /content/drive/MyDrive/2A_PONG_ppo/tensorboard/PPO_21\n",
            "------------------------------\n",
            "| mean_reward        | 0.0   |\n",
            "| time/              |       |\n",
            "|    fps             | 275   |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 59    |\n",
            "|    total_timesteps | 16384 |\n",
            "------------------------------\n",
            "Eval num_timesteps=25088, episode_reward=-4.20 +/- 20.58\n",
            "Episode length: 2913.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 2.91e+03   |\n",
            "|    mean_reward          | -4.2       |\n",
            "| mean_reward             | 0.01       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 25088      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01118005 |\n",
            "|    clip_fraction        | 0.0131     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.43      |\n",
            "|    explained_variance   | -5.13e-06  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0517     |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.000324  |\n",
            "|    value_loss           | 0.0582     |\n",
            "----------------------------------------\n",
            "------------------------------\n",
            "| mean_reward        | 0.01  |\n",
            "| time/              |       |\n",
            "|    fps             | 47    |\n",
            "|    iterations      | 2     |\n",
            "|    time_elapsed    | 686   |\n",
            "|    total_timesteps | 32768 |\n",
            "------------------------------\n",
            "Model has been saved.\n",
            "Finished training on pong_v3.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  display = Display(visible=0, size=(1400, 900))\n",
        "  display.start()\n",
        "\n",
        "  env_fn = pong_v3\n",
        "  env_kwargs = {}\n",
        "    # Evaluate 10 games (average reward should be positive but can vary significantly)\n",
        "    #eval(env_fn, num_games=10, render_mode=None, **env_kwargs)\n",
        "    # Watch 2 games\n",
        "  eval_timesteps(env_fn, num_timesteps=1000, render_mode=\"human\", **env_kwargs)\n",
        "    # Display the video after evaluation\n",
        "  video_path = \"/content/drive/MyDrive/2A_PONG_ppo/video_10x20k.mp4\"\n",
        "  display.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOmEuITf0OF2",
        "outputId": "abe03b36-c5ae-4375-ce6a-a6d64017e686"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting evaluation\n",
            "Rewards:  {'first_0': -2, 'second_0': -1}\n",
            "Avg reward: -1.5\n",
            "Moviepy - Building video /content/drive/MyDrive/2A_PONG_ppo/video_10x20k.mp4.\n",
            "Moviepy - Writing video /content/drive/MyDrive/2A_PONG_ppo/video_10x20k.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/drive/MyDrive/2A_PONG_ppo/video_10x20k.mp4\n",
            "Evaluation saved as /content/drive/MyDrive/2A_PONG_ppo/video_10x20k.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# Convert mp4 to base64\n",
        "video_path = \"/content/drive/MyDrive/2A_PONG_ppo/video_10x20k.mp4\"\n",
        "video = open(video_path, \"rb\").read()\n",
        "video_encoded = b64encode(video).decode()\n",
        "\n",
        "# Display video\n",
        "HTML(f\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "      <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "alCBUZ_g0OIh",
        "outputId": "8e86382e-fb53-48b9-f61d-098f6a12b469"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=\"640\" height=\"480\" controls>\n",
              "      <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAS+ZtZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1OSByMjk5MSAxNzcxYjU1IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxOSAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTcgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAB4mWIhAB/k3mVxva1Wrx2BYgRok7ehbEfwSVACeO2ZeVyzte0B6NW2D38w1qGRcFgiY5Xf6vCfouPw1b8BZPoORAhRr+aKFIglZDQD4vR5zWKzCqnxnWEV72P6hX2Zur3cjbUu7Quq5uUc4/ctfA3uaEYp2LszdPYUP1q2/DUJFa51kN1way83Y1KlyScne5QjGK6fk35BADvRExj7zQxqSlHHUYHcdjkuHTW8HHyP/OXkWnAMz7fJz0XnGCBfkIgDhp/Gbec/Hb5Ewkfjy4+MhY+Uja+q6B1U6T62S1KhQ3VwJRoRGf0PksMOyQMGz/J2Ks5DFvZnJbF31SRFQEr7yigE5Dzt107nGxi5RDxKT93SAY2RpQjqt/aneHIs/+Fj77De1Js7lpcRo4ASnXeaWG1PhX5VjM0HtIfRKcA+k9FMeJQ5WDJ4OYuNUGJsDDX0nF+CX6dnGCfggBEWOAyIYsbnskAIXkJKAJDOC/QBQDsGGD+AHclTBfNMUsUM18LfLahr5BrPKwD9NYqoMhwdZ47WR/3Dhyd7knpromHcUF9V6Inegth86SO6PEs1J3lUTzWMqzeMJDSCuoyMAE5XOBwu4UUoFs1+iatqQXF9YDywazMn7r6GuO1toe/wMz5l6ppAAAAE0GaJGxH//yEFHDdqhuY3sKsungAAAAKQZ5CeK8K+unS0QAAAAgBnmF0Tf8CHgAAAAsBnmNqTf8NWD4hwQAAAC5BmmhJqEFomUwI//yEFHvl2O+q3ogwCRDToIkWflVwzyJcC4i1SlztQKuObU6TAAAADUGehkURLX8N/eFDI7EAAAAKAZ6ldE3/DRy8EQAAAAwBnqdqTf8ROQOB8kcAAAA3QZqsSahBbJlMCP/8hAKyIzAdc/TmGwEO3vBwkHY2ODGUOq/5jGVaHtMkl3IalWe6LQ2GQJEp6AAAABJBnspFFS1/Df0709TloV19GsEAAAAMAZ7pdE3/D7DKhRgMAAAADQGe62pN/xE604DFVXgAAAA1QZrwSahBbJlMCP/8hBR75dBWcfFpvnP8pQo5P5E2eza54rmx9vqSqHaclbMDzFxzE4T3HPEAAAARQZ8ORRUtfxIpyNhQKLwJvNEAAAAOAZ8tdE3/ECxtXJ+tL/cAAAAOAZ8vak3/FozA984DprwAAAA7QZs0SahBbJlMCP/8hAZHQRVgAO57yZ09JhfKO8aooY1Wxz/v8JirM8keJHD4nySIOX+rCMm1ugustGAAAAARQZ9SRRUtfxeQk90bjVToDLEAAAANAZ9xdE3/EC2V8DZV4AAAABYBn3NqTf8cwve1C/x8S1ADvSnCqmvgAAAAMkGbeEmoQWyZTAj//IQYaoeAUjblmt5JQTDYPHhcAe9ajupZzGyWd50hT/thOLIro/ZjAAAAEkGflkUVLX8fASZF+T1pDHRIpwAAAA0Bn7V0Tf8QLeCVINUPAAAADQGft2pN/yXZbeoEWY0AAABAQZu8SahBbJlMCP/8hBmXpadgqJv1lANd8ZzeUA3fGLdrsBCIM615MB1TdmVNzP1EAmsBf4IRH7IUVNiq+CdrIAAAABFBn9pFFS1/HwEpROSoD8ZsMQAAABgBn/l0Tf8cfgIACY3CTDntkFzcrx8WobgAAAAOAZ/7ak3/Jdl3TYlSSVkAAAA5QZvgSahBbJlMCP/8hBhqh4pNuXI0C+an4oLG9GrQbiJ5utAIp27YFlpt9we/jVCCIt1qo1TCJVxhAAAAFEGeHkUVLX8fASlE5J4IIYv9RMFZAAAADwGePXRN/xAtzOSg1Wn3MAAAAA4Bnj9qTf8l2XdNiMk/yQAAACFBmiRJqEFsmUwI//yEGWj0mYhLtqvuw7Gv7WBHJ8mNYyAAAAATQZ5CRRUtfx8Bv2KZAyMkxmSYQQAAAA4BnmF0Tf8QLch4exh3QAAAAA0BnmNqTf8l3BQibJZXAAAAKUGaaEmoQWyZTAj//IQZaAwMqaRoUdZ5y/bWRjf1IZ+4Yhk3eJX8EJdnAAAAD0GehkUVLX8NYSd2ToZEgQAAAA0BnqV0Tf8QLcf6Ja6dAAAACgGep2pN/xBRTkYAAAArQZqsSahBbJlMCP/8hBlox4wJ6/O3fEP5eT02DD++Xlax74Ig8d/nx9nf+AAAAA9BnspFFS1/HwG/YpZJ/9UAAAANAZ7pdE3/EC3EsuI3gAAAAAwBnutqTf8l3BQh/GAAAAAUQZrwSahBbJlMCP/8hABNlkzZ9vEAAAANQZ8ORRUtfw1hJu+4HQAAAAwBny10Tf8QLcH1w5EAAAAKAZ8vak3/EFFORgAAABRBmzRJqEFsmUwI//yEAE2Wlmxc4AAAAA1Bn1JFFS1/DWEm77gdAAAADAGfcXRN/xAtwfXDkAAAAAoBn3NqTf8QUU5GAAAAIEGbeEmoQWyZTAj//IQATZaWsuIiClYAUxvmy5uRC2vhAAAADUGflkUVLX8NYSbvuBwAAAAMAZ+1dE3/EC3B9cORAAAACgGft2pN/xBRTkcAAAAQQZu8SahBbJlMCP/8hAAwIAAAAAxBn9pFFS1/DWEmosEAAAAKAZ/5dE3/EC2+bAAAAAoBn/tqTf8QUU5HAAAAEEGb4EmoQWyZTAj//IQAMCEAAAAMQZ4eRRUtfw1hJqLAAAAACgGePXRN/xAtvmwAAAAKAZ4/ak3/EFFORwAAABBBmiRJqEFsmUwI//yEADAgAAAADEGeQkUVLX8NYSaiwQAAAAoBnmF0Tf8QLb5sAAAACgGeY2pN/xBRTkcAAAAQQZpoSahBbJlMCP/8hAAwIQAAAAxBnoZFFS1/DWEmosEAAAAKAZ6ldE3/EC2+bQAAAAoBnqdqTf8QUU5GAAAAEEGarEmoQWyZTAj//IQAMCAAAAAMQZ7KRRUtfw1hJqLBAAAACgGe6XRN/xAtvmwAAAAKAZ7rak3/EFFORgAAABBBmvBJqEFsmUwI//yEADAhAAAADEGfDkUVLX8NYSaiwQAAAAoBny10Tf8QLb5tAAAACgGfL2pN/xBRTkYAAAAQQZs0SahBbJlMCP/8hAAwIAAAAAxBn1JFFS1/DWEmosEAAAAKAZ9xdE3/EC2+bAAAAAoBn3NqTf8QUU5GAAAAEEGbeEmoQWyZTAj//IQAMCEAAAAMQZ+WRRUtfw1hJqLAAAAACgGftXRN/xAtvm0AAAAKAZ+3ak3/EFFORwAAABBBm7xJqEFsmUwI//yEADAgAAAADEGf2kUVLX8NYSaiwQAAAAoBn/l0Tf8QLb5sAAAACgGf+2pN/xBRTkcAAAAQQZvgSahBbJlMCP/8hAAwIQAAAAxBnh5FFS1/DWEmosAAAAAKAZ49dE3/EC2+bAAAAAoBnj9qTf8QUU5HAAAAEEGaJEmoQWyZTAj//IQAMCAAAAAMQZ5CRRUtfw1hJqLBAAAACgGeYXRN/xAtvmwAAAAKAZ5jak3/EFFORwAAABBBmmhJqEFsmUwI//yEADAhAAAADEGehkUVLX8NYSaiwQAAAAoBnqV0Tf8QLb5tAAAACgGep2pN/xBRTkYAAAAQQZqsSahBbJlMCP/8hAAwIAAAAAxBnspFFS1/DWEmosEAAAAKAZ7pdE3/EC2+bAAAAAoBnutqTf8QUU5GAAAAEEGa8EmoQWyZTAj//IQAMCEAAAAMQZ8ORRUtfw1hJqLBAAAACgGfLXRN/xAtvm0AAAAKAZ8vak3/EFFORgAAADtBmzRJqEFsmUwI//yEAPxeh4KFCO7b7HlwizBYECoGD3ZBGX0ojcleBs983QGgPmeE2UWQs/DXFH2X3QAAABhBn1JFFS1/DWEpDgbi/u7YnzDf4stHzoMAAAAMAZ9xdE3/EC3bbqdAAAAADAGfc2pN/xBRXuv5ywAAAB5Bm3hJqEFsmUwI//yEAP3v+K/4WXXIdEk+8I+LHEEAAAAdQZ+WRRUtfw1hKQlCLDMgfGvPA4GxYiEgiFfOMeAAAAAMAZ+1dE3/EC3ba/NrAAAADQGft2pN/xBRWNI8dKEAAAAbQZu8SahBbJlMCP/8hADHgdlzaMOhxixP5feAAAAAEUGf2kUVLX8NYSgrWm+QSeshAAAADAGf+XRN/xAt0PBUpQAAAAwBn/tqTf8QUVjU5yEAAAAfQZvgSahBbJlMCP/8iFJ72eJFNbcGZujPP/HW6/zs7wAAABlBnh5FFS1/DWEoKf0npLS5quXU43uncNuYAAAADAGePXRN/xAt0PdBwAAAAA0Bnj9qTf8QUVjUGzmBAAAAL0GaJEmoQWyZTAj//Ihjsam2C0hgpp88ikYKPrV42+dxfdfITQ5gCKEeMK4sP+ayAAAAHUGeQkUVLX8NYSgwjluYKt3Htqw7m0+2RhELReIpAAAADAGeYXRN/xAt0PXDswAAAAwBnmNqTf8QUVjTsvMAAAAXQZpoSahBbJlMCP/8hADI7/irnsuTWdEAAAARQZ6GRRUtfw1hKCX2lJrsLSEAAAAOAZ6ldE3/EC3RbsG/jsEAAAANAZ6nak3/EFFY3VG7IAAAABtBmqxJqEFsmUwI//yEAJqatsGKewGwRYuvMegAAAAYQZ7KRRUtfw1hJ7qOk9JevTkta4RXhmKBAAAADAGe6XRN/xAty1QcoAAAAAwBnutqTf8QUVXDzmAAAAAfQZrwSahBbJlMCP/8hACeXWzLm7ZwK6AQplADCBD8QQAAABlBnw5FFS1/DWEnw9Km44ZNi/MPA2XDqyKdAAAADQGfLXRN/xAty/gu3YEAAAAOAZ8vak3/EFFWCC7TReAAAAArQZs0SahBbJlMCP/8hACfdLxAmZQe2k3+ZhEOy63SMC4UZV9KdilCdrkmiAAAAB5Bn1JFFS1/DWEnwsxCYbU66jxGBqJDRB0IjjRMv4EAAAAOAZ9xdE3/EC3L0CYAa8AAAAANAZ9zak3/EFFWCvT9DAAAAB9Bm3hJqEFsmUwI//yEAJ9zrFXPZcm43X4VCrOEZXyJAAAAEkGflkUVLX8NYSfBZBsxvpBZgAAAAA4Bn7V0Tf8QLcvrOuO+1QAAAAwBn7dqTf8QUVYLAhUAAAAdQZu8SahBbJlMCP/8hAB5HyZJ1EONbwK3RRglKLwAAAAQQZ/aRRUtfw1hJ2etN8wYQQAAAAwBn/l0Tf8QLcdK26AAAAAMAZ/7ak3/EFFTaz0hAAAAH0Gb4EmoQWyZTAj//IQAeR8mSN1IDqyBu54vijxwZi0AAAAXQZ4eRRUtfw1hJ2oU4B5+0c9hCkKp+sAAAAAMAZ49dE3/EC3HStugAAAADAGeP2pN/xBRU2pmcwAAAC1BmiRJqEFsmUwI//yEAHn/oyABjyuH96E/gOTwctNGSydYnWoSmkyVsiMWUMAAAAASQZ5CRRUtfw1hJ2WBt8i2GIO9AAAADQGeYXRN/xAtx0on4YAAAAAMAZ5jak3/EFFTamZzAAAAGEGaaEmoQWyZTAj//IQAX0DsuPjokXw5bwAAABlBnoZFFS1/DWEnH+62T22aWbPqt4BZctt1AAAADAGepXRN/xAtxBsQoQAAAA0BnqdqTf8QUVG8j39AAAAAKEGarEmoQWyZTAj//IQAX8zp7Tsbd+wGfHmOtOuMR5tC2K2f6aMV23gAAAAaQZ7KRRUtfw1hJyC1YJPbZEGyrhd7ANqOtIEAAAAMAZ7pdE3/EC3EYCejAAAADQGe62pN/xBRUbyPf0AAAAAkQZrwSahBbJlMCP/8hABhwOy4szFwz8VAz1sGbDTc3te0RPOBAAAAGkGfDkUVLX8NYScgss3mlyeGvVRJkRek/sYJAAAADgGfLXRN/xAtxJITdbehAAAADgGfL2pN/xBRUbATrdSAAAAANEGbNEmoQWyZTAj//IQAYnf8PGHxJa8iIjAIFVV+hoIazScwu9Dn+mbvcjOWZYipLpbR4vAAAAAaQZ9SRRUtfw1hJx6CSmIA99kv+WldvBt+IkEAAAAOAZ9xdE3/EC3EYBtkB+AAAAAMAZ9zak3/EFFQMf/gAAAAREGbd0moQWyZTAj//IQAS7gDVcuvHLAZkOAPW0Z9d4Ka+o0HrDn4KRSFy3KlKreZQw7xVjBlYQhIMHcm3bt57h2h5je5AAAAJUGflUUVLJ8OiBog1xtyo9+rNuu0laJeOz3uoYh94jUHSyMrUygAAAAMAZ+2ak3/EFFQPITxAAAAMUGbu0moQWyZTAj//IQAS0bSfZcCCNVRTwyj5Fo1sAbfh3oUU/DgVBqq9YdfXU5DltEAAAArQZ/ZRRUtfw1hJu3ALgGuR1CSuQUHeHAS3jUK81zYQtiznpb10pGYuhnUCAAAABMBn/h0Tf8QLcHR9AjNGx092eknAAAADAGf+mpN/xBRUDyE8AAAADhBm/9JqEFsmUwI//yEAEsu7nABkUQX8QTrTKKXjZ0WSYSg20ouppTqqrsZgVwX+0pXwQQ9ZbV7gQAAAB1Bnh1FFS1/DWEm7iR0ekWvmCaOn2RF8ILBCBHc9wAAAAwBnjx0Tf8QLcG+XMAAAAAMAZ4+ak3/EFFQPITwAAAAMEGaI0moQWyZTAj//IQAS372xIqUA/uP2mL7oy7L6Bl0rUHyMcr39MS2ZxaNnERu+wAAACRBnkFFFS1/DWEm7h4MNrJblWN38xa7DUSxLLv7990rThLkJMAAAAAMAZ5gdE3/EC3BvlzBAAAADAGeYmpN/xBRUDyE8AAAAFJBmmdJqEFsmUwI//yEAGJ/oyABjw7rMV6cbDORBTIcOpKTlQYVXaY6oadTRrHedbixpGwTnODBOVPDvzSB0Li8gjEmkQRajZLXEtyS7YnPlMK1AAAAGUGehUUVLX8NYSbuAZSYUTtubgsgxR8jIRkAAAAMAZ6kdE3/EC3BvlzBAAAADAGepmpN/xBRUDyE8QAAACRBmqtJqEFsmUwI//yEAGIB1lvItfDhJcEY/u376jY1cumfFOAAAAAaQZ7JRRUtfw1hJyBlLzAFUchjtubW0lHeSygAAAANAZ7odE3/EC3EzNPIbQAAAA0BnupqTf8QUVHYqWv2AAAAGEGa70moQWyZTAj//IQAZEDstOMxU7V6QQAAABpBnw1FFS1/DWEnJhdEaw/j6Mnhr1USTU9vcwAAAA0Bnyx0Tf8QLcTM08htAAAADQGfLmpN/xBRUe1wbYkAAAAfQZszSahBbJlMCP/8hABkkn6r8yvoS46zd0mQPByFuAAAABBBn1FFFS1/DWEnJzfh+qj/AAAADQGfcHRN/xAtxMzV2IEAAAANAZ9yak3/EFFR5SHfgAAAAC1Bm3dJqEFsmUwI//yEAH98CygEIznILyP95txHXH5AwA4uhoYf2MqVBp+oC9gAAAAaQZ+VRRUtfw1hJ3hfleq3K7N0/31z41x8fzsAAAANAZ+0dE3/EC3EzNXYgAAAAA4Bn7ZqTf8QUVQEsaEkEQAAACtBm7tJqEFsmUwI//yEAH70mYit3LOyM7ov5d7SRlAOHhBOyZA83xfb5WNRAAAAJkGf2UUVLX8NYSd7qArFGzyPcbgOJBU+xC4lwTsTvO1EePQ0OV3wAAAADQGf+HRN/xAtyBfJNEUAAAANAZ/6ak3/EFFT+yYjbgAAABdBm/9JqEFsmUwI//yEAH6fJkRSVrK/sQAAABBBnh1FFS1/DWEnea03vprrAAAADAGePHRN/xAtyBhJIAAAAAwBnj5qTf8QUVP7dVAAAAAdQZojSahBbJlMCP/8hAB+nyZHf9iVmXWhDKxPTyEAAAARQZ5BRRUtfw1hJ9fx/uL3ocAAAAAMAZ5gdE3/EC3IGEkhAAAADQGeYmpN/xBRVrCqCMAAAAAqQZpnSahBbJlMCP/8hACnJ9ls9FtmUb/MUZT2xHRmj15jfmvoILYWtq8HAAAAHkGehUUVLX8NYSfY/y8M0bZVU2HU+zwpmFmJCw/WkwAAAAwBnqR0Tf8QLcgYSSEAAAAOAZ6mak3/EFFWsNIKTYEAAAAjQZqrSahBbJlMCP/8hACoE8stnoRPTsWNEX+0pBjSAE6hNmsAAAASQZ7JRRUtfw1hJ9k9N75vRH2cAAAADAGe6HRN/xAtzRaugwAAAA0BnupqTf8QUVawqgjAAAAAG0Ga70moQWyZTAj//IQAq6fZbtwHYZanH2cWIAAAABhBnw1FFS1/DWEn4cvr1UZPDVdTqM+uvOEAAAANAZ8sdE3/EC3No8IFwQAAAA0Bny5qTf8QUVcHOnhdAAAAIkGbM0moQWyZTAj//IQArMSVOWb95KEgTGb4I2YGx4iro2IAAAAaQZ9RRRUtfw1hKHO1gtACt1FPtsrisrsDlYAAAAANAZ9wdE3/EC3No8IFwQAAAA0Bn3JqTf8QUVb5DJvAAAAAHkGbd0moQWyZTAj//IQA24HZbvjWCywB/zFgJ28hsAAAABxBn5VFFS1/DWEocsxkzdaaWWVtofW64EQ9HXCtAAAADgGftHRN/xAt1MFb8kk4AAAADgGftmpN/xBRWsOMxl0xAAAAGEGbuUmoQWyZTBRNfwAC1uEje76TC6p4qQAAAA0Bn9hqTf8QW4Ub/CLYAAACUmWIggAK/6i+B6LLLfwDABLmwqLyDd4bCLQf0zdv4JP0DqPma/JjYzK4gMSH8fkW4veNTaG23w7Y8Z5iS/jWQ4LtJMcn28nJO0MG8LEED+cYB6Bnc+3npGCxetbjFQp9CludSSnT+B0kX02WReyelwsvzv6jkEZJ9LXprrleKIUVqheISOoWdjuIZ99XUVa/CjDN2xsPMWUUWk8G/qVWe3W4GtY0+2kqbrpzoCEysDJa7xMX371upB01h7r0gC1u70JjQMBy0Nr1GNsnb/TMq38lJCI69hgOemrfnn8MCseesgM9UJ1zsGDtxP/aYtJpM4mwYjoPJBcsdgnhatGaFvpl1Da5Vm+2PUVTYCjgntBPFBy9V1kk0JhBhdvi/fISZEy+RKilu+PioQ44DVVEhYDAw6ewHEgmixGDwyK+jXr32QuoBfjzszKlepdnEK99bj0B8h/EYuOw7V+37z3JLiS6bBCH98YjtkhxWvKeh9NN+aAsX9mhM72TzkJJOv38F5TJq/WwZC2AMs9tWth5T4wO+0oTkPfAACZbOjzq82tNMVaEJ0w4xHQFYwAAAwABmtt3InAk9yWfib2peeHmYwmPWdmkUSweZwsfVcqhmUztbwQoDoMsHKtMe5+0d+vmWRIkpKks8hyO0L26yQUC4h3m9ELbr+4pZBa5atFfaySRBplogPLJ2CZD9/KTRvhiCkd9W7lb7nqj1ghxhHly61FtpsO9J/BsCpGUn5Qa/d1xnWr2kRdlTrunKcLvh0SKioGA1ITfWCjH76R4WzMrSgADfwAAABNBmiRsR//8hADcQNZk9Xuf2VdQAAAAJ0GeQnivB+ykwcK+Q9skWZRl6p1LyxDFcNtoQlbVlm3wcdq19B6PwQAAAAsBnmF0Tf8J0MXByQAAAAoBnmNqTf8J1GJYAAAAGkGaaEmoQWiZTAj//IQA24HZbY7gKM0S3pt4AAAADkGehkURLX8KZ8QAiCzJAAAACgGepXRN/wnQ75QAAAALAZ6nak3/DMi8TE0AAAAgQZqsSahBbJlMCP/8hAEbutmTMcFBeGfGVX7DgU8FU2oAAAASQZ7KRRUtfwps5Z8t5FFnv+dlAAAADAGe6XRN/wy4L37BLQAAAAsBnutqTf8Mtf7ImQAAABdBmvBJqEFsmUwI//yEARvBGRhPuWHowQAAAAxBnw5FFS1/ClrCoOQAAAALAZ8tdE3/DLIWv0wAAAAIAZ8vak3/Ah8AAABcQZs0SahBbJlMCP/9LFxuMS5fpcU8zf6iivSFDoyHrWX8wehrXgCmPKKg1OhAm2oBk51TJD36vjpbM3rMju4Q7AIBPVrwr6iaeJ8Wm/Syt3Xw8LMuRrngV/mf/CAAAAAOQZ9SRRUtf2hDEYwvDrwAAAAOAZ9xdE3/cUvO7kh8ooEAAAAIAZ9zak3/Ah8AAAAQQZt4SahBbJlMCP/8hAAwIQAAAAlBn5ZFFS1/Ab0AAAAIAZ+1dE3/Ah4AAAAIAZ+3ak3/Ah8AAAAQQZu8SahBbJlMCP/8hAAwIAAAAAlBn9pFFS1/Ab0AAAAIAZ/5dE3/Ah8AAAAIAZ/7ak3/Ah4AAAAQQZvgSahBbJlMCP/8hAAwIQAAAAlBnh5FFS1/Ab0AAAAIAZ49dE3/Ah4AAAAIAZ4/ak3/Ah8AAAAQQZokSahBbJlMCP/8hAAwIAAAAAlBnkJFFS1/Ab0AAAAIAZ5hdE3/Ah8AAAAIAZ5jak3/Ah4AAAAQQZpoSahBbJlMCP/8hAAwIAAAAAlBnoZFFS1/Ab0AAAAIAZ6ldE3/Ah4AAAAIAZ6nak3/Ah8AAAAQQZqsSahBbJlMCP/8hAAwIAAAAAlBnspFFS1/Ab0AAAAIAZ7pdE3/Ah8AAAAIAZ7rak3/Ah8AAAAQQZrwSahBbJlMCP/8hAAwIQAAAAlBnw5FFS1/Ab0AAAAIAZ8tdE3/Ah4AAAAIAZ8vak3/Ah8AAAAQQZs0SahBbJlMCP/8hAAwIAAAAAlBn1JFFS1/Ab0AAAAIAZ9xdE3/Ah8AAAAIAZ9zak3/Ah8AAAAQQZt4SahBbJlMCP/8hAAwIQAAAAlBn5ZFFS1/Ab0AAAAIAZ+1dE3/Ah4AAAAIAZ+3ak3/Ah8AAAAQQZu8SahBbJlMCP/8hAAwIAAAAAlBn9pFFS1/Ab0AAAAIAZ/5dE3/Ah8AAAAIAZ/7ak3/Ah4AAAAQQZvgSahBbJlMCP/8hAAwIQAAAAlBnh5FFS1/Ab0AAAAIAZ49dE3/Ah4AAAAIAZ4/ak3/Ah8AAAAQQZokSahBbJlMCP/8hAAwIAAAAAlBnkJFFS1/Ab0AAAAIAZ5hdE3/Ah8AAAAIAZ5jak3/Ah4AAAAQQZpoSahBbJlMCP/8hAAwIAAAAAlBnoZFFS1/Ab0AAAAIAZ6ldE3/Ah4AAAAIAZ6nak3/Ah8AAAAQQZqsSahBbJlMCP/8hAAwIAAAAAlBnspFFS1/Ab0AAAAIAZ7pdE3/Ah8AAAAIAZ7rak3/Ah8AAAAQQZrwSahBbJlMCP/8hAAwIQAAAAlBnw5FFS1/Ab0AAAAIAZ8tdE3/Ah4AAAAIAZ8vak3/Ah8AAAAQQZs0SahBbJlMCP/8hAAwIAAAAAlBn1JFFS1/Ab0AAAAIAZ9xdE3/Ah8AAAAIAZ9zak3/Ah8AAAAQQZt4SahBbJlMCP/8hAAwIQAAAAlBn5ZFFS1/Ab0AAAAIAZ+1dE3/Ah4AAAAIAZ+3ak3/Ah8AAAAQQZu8SahBbJlMCP/8hAAwIAAAAAlBn9pFFS1/Ab0AAAAIAZ/5dE3/Ah8AAAAIAZ/7ak3/Ah4AAAAQQZvgSahBbJlMCP/8hAAwIQAAAAlBnh5FFS1/Ab0AAAAIAZ49dE3/Ah4AAAAIAZ4/ak3/Ah8AAAAQQZokSahBbJlMCP/8hAAwIAAAAAlBnkJFFS1/Ab0AAAAIAZ5hdE3/Ah8AAAAIAZ5jak3/Ah4AAAAQQZpoSahBbJlMCP/8hAAwIAAAAAlBnoZFFS1/Ab0AAAAIAZ6ldE3/Ah4AAAAIAZ6nak3/Ah8AAAAQQZqsSahBbJlMCP/8hAAwIAAAAAlBnspFFS1/Ab0AAAAIAZ7pdE3/Ah8AAAAIAZ7rak3/Ah8AAAAQQZrwSahBbJlMCP/8hAAwIQAAAAlBnw5FFS1/Ab0AAAAIAZ8tdE3/Ah4AAAAIAZ8vak3/Ah8AAAAQQZs0SahBbJlMCP/8hAAwIAAAAAlBn1JFFS1/Ab0AAAAIAZ9xdE3/Ah8AAAAIAZ9zak3/Ah8AAAAQQZt4SahBbJlMCP/8hAAwIQAAAAlBn5ZFFS1/Ab0AAAAIAZ+1dE3/Ah4AAAAIAZ+3ak3/Ah8AAAAQQZu8SahBbJlMCP/8hAAwIAAAAAlBn9pFFS1/Ab0AAAAIAZ/5dE3/Ah8AAAAIAZ/7ak3/Ah4AAAAQQZvgSahBbJlMCP/8hAAwIQAAAAlBnh5FFS1/Ab0AAAAIAZ49dE3/Ah4AAAAIAZ4/ak3/Ah8AAAAQQZokSahBbJlMCP/8hAAwIAAAAAlBnkJFFS1/Ab0AAAAIAZ5hdE3/Ah8AAAAIAZ5jak3/Ah4AAAAQQZpoSahBbJlMCP/8hAAwIAAAAAlBnoZFFS1/Ab0AAAAIAZ6ldE3/Ah4AAAAIAZ6nak3/Ah8AAAAQQZqsSahBbJlMCP/8hAAwIAAAAAlBnspFFS1/Ab0AAAAIAZ7pdE3/Ah8AAAAIAZ7rak3/Ah8AAAAQQZrwSahBbJlMCP/8hAAwIQAAAAlBnw5FFS1/Ab0AAAAIAZ8tdE3/Ah4AAAAIAZ8vak3/Ah8AAAAQQZs0SahBbJlMCP/8hAAwIAAAAAlBn1JFFS1/Ab0AAAAIAZ9xdE3/Ah8AAAAIAZ9zak3/Ah8AAAAQQZt4SahBbJlMCP/8hAAwIQAAAAlBn5ZFFS1/Ab0AAAAIAZ+1dE3/Ah4AAAAIAZ+3ak3/Ah8AAAAQQZu8SahBbJlMCP/8hAAwIAAAAAlBn9pFFS1/Ab0AAAAIAZ/5dE3/Ah8AAAAIAZ/7ak3/Ah4AAAAQQZvgSahBbJlMCP/8hAAwIQAAAAlBnh5FFS1/Ab0AAAAIAZ49dE3/Ah4AAAAIAZ4/ak3/Ah8AAAAQQZokSahBbJlMCP/8hAAwIAAAAAlBnkJFFS1/Ab0AAAAIAZ5hdE3/Ah8AAAAIAZ5jak3/Ah4AAAAQQZpoSahBbJlMCP/8hAAwIAAAAAlBnoZFFS1/Ab0AAAAIAZ6ldE3/Ah4AAAAIAZ6nak3/Ah8AAAAQQZqsSahBbJlMCP/8hAAwIAAAAAlBnspFFS1/Ab0AAAAIAZ7pdE3/Ah8AAAAIAZ7rak3/Ah8AAAAQQZrwSahBbJlMCP/8hAAwIQAAAAlBnw5FFS1/Ab0AAAAIAZ8tdE3/Ah4AAAAIAZ8vak3/Ah8AAAAQQZs0SahBbJlMCP/8hAAwIAAAAAlBn1JFFS1/Ab0AAAAIAZ9xdE3/Ah8AAAAIAZ9zak3/Ah8AAAAQQZt4SahBbJlMCP/8hAAwIQAAAAlBn5ZFFS1/Ab0AAAAIAZ+1dE3/Ah4AAAAIAZ+3ak3/Ah8AAAAQQZu8SahBbJlMCP/8hAAwIAAAAAlBn9pFFS1/Ab0AAAAIAZ/5dE3/Ah8AAAAIAZ/7ak3/Ah4AAAAQQZvgSahBbJlMCP/8hAAwIQAAAAlBnh5FFS1/Ab0AAAAIAZ49dE3/Ah4AAAAIAZ4/ak3/Ah8AAAAQQZokSahBbJlMCP/8hAAwIAAAAAlBnkJFFS1/Ab0AAAAIAZ5hdE3/Ah8AAAAIAZ5jak3/Ah4AAAAQQZpoSahBbJlMCP/8hAAwIAAAAAlBnoZFFS1/Ab0AAAAIAZ6ldE3/Ah4AAAAIAZ6nak3/Ah8AAAAQQZqsSahBbJlMCP/8hAAwIAAAAAlBnspFFS1/Ab0AAAAIAZ7pdE3/Ah8AAAAIAZ7rak3/Ah8AAAAQQZrwSahBbJlMCP/8hAAwIQAAAAlBnw5FFS1/Ab0AAAAIAZ8tdE3/Ah4AAAAIAZ8vak3/Ah8AAAAQQZs0SahBbJlMCP/8hAAwIAAAAAlBn1JFFS1/Ab0AAAAIAZ9xdE3/Ah8AAAAIAZ9zak3/Ah8AAAAQQZt4SahBbJlMCP/8hAAwIQAAAAlBn5ZFFS1/Ab0AAAAIAZ+1dE3/Ah4AAAAIAZ+3ak3/Ah8AAAAQQZu8SahBbJlMCP/8hAAwIAAAAAlBn9pFFS1/Ab0AAAAIAZ/5dE3/Ah8AAAAIAZ/7ak3/Ah4AAAAQQZvgSahBbJlMCP/8hAAwIQAAAAlBnh5FFS1/Ab0AAAAIAZ49dE3/Ah4AAAAIAZ4/ak3/Ah8AAAAQQZokSahBbJlMCP/8hAAwIAAAAAlBnkJFFS1/Ab0AAAAIAZ5hdE3/Ah8AAAAIAZ5jak3/Ah4AAAAQQZpoSahBbJlMCP/8hAAwIAAAAAlBnoZFFS1/Ab0AAAAIAZ6ldE3/Ah4AAAAIAZ6nak3/Ah8AAAAQQZqsSahBbJlMCP/8hAAwIAAAAAlBnspFFS1/Ab0AAAAIAZ7pdE3/Ah8AAAAIAZ7rak3/Ah8AAAAQQZrwSahBbJlMCP/8hAAwIQAAAAlBnw5FFS1/Ab0AAAAIAZ8tdE3/Ah4AAAAIAZ8vak3/Ah8AAAAQQZs0SahBbJlMCP/8hAAwIAAAAAlBn1JFFS1/Ab0AAAAIAZ9xdE3/Ah8AAAAIAZ9zak3/Ah8AAAAQQZt4SahBbJlMCP/8hAAwIQAAAAlBn5ZFFS1/Ab0AAAAIAZ+1dE3/Ah4AAAAIAZ+3ak3/Ah8AAAAOQZu5SahBbJlMCb8AAj4AAAHHZYiEACv/qL4Hosst/AMAEubCovIN3hsItB/TN2/gk/QOo+Zr8mNjMriAxIfx+Rbi941NobbfDtjxnmJL+NZDgu0kxyfbyck7QwbwsQQP5xgHoGdz7eekYLF61uMVAUZEN/Th8S6Vn/34/EGvQrx2pJb79XVRYD37W0JXo0iKOSDhWIxhMSBQCsdR5sc6wLL9nTph7rfgAJNcDT5HjeIFqdgy6F+PlW0AYDloeHdnSF5nlXJ5sd/DD+vWSgKrUEcgRGDWb7Bq4Z8vQCM4vOkX/7TFpNJkIRxSE1Y7zsRMAG7sFyYL1cqULVlGNGArCP4PYNPUM6cMHTV4oz7cYz1658t2fNyYv9w2pltgc8Q496cKsFmRLo+8o+VmKoK4PfgUeyn4zi3naTstst+xyB74ztmTmC/Gz40Ob2baPyar7RQDXJKAKzN/4xM1uc/ND0fpiJ/oHHUxa0RV/hx4apd0dCWpT0FaV8A4TTgAAAMAAAMAAP/k9bUmvsefm1d/e1Zc0fmfO9vpr66KQt4g5OfAlTd9mj3kAZhiivYNgVL6s/sRRtq0B8Wh45U+al/Ij7NQrxkAZGjgmEexp62Xm1UcaO30rFAALiAAAAALQZokbEf//IQAMCEAAAAHQZ5CeK8BvQAAAAgBnmF0Tf8CHwAAAAgBnmNqTf8CHwAAABBBmmhJqEFomUwI//yEADAgAAAACUGehkURLX8BvQAAAAgBnqV0Tf8CHgAAAAgBnqdqTf8CHwAAABBBmqxJqEFsmUwI//yEADAhAAAACUGeykUVLX8BvQAAAAgBnul0Tf8CHgAAAAgBnutqTf8CHwAAABBBmvBJqEFsmUwI//yEADAgAAAACUGfDkUVLX8BvQAAAAgBny10Tf8CHgAAAAgBny9qTf8CHwAAABBBmzRJqEFsmUwI//yEADAhAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHwAAAAgBn3NqTf8CHgAAABBBm3hJqEFsmUwI//yEADAgAAAACUGflkUVLX8BvQAAAAgBn7V0Tf8CHgAAAAgBn7dqTf8CHgAAABBBm7xJqEFsmUwI//yEADAhAAAACUGf2kUVLX8BvQAAAAgBn/l0Tf8CHwAAAAgBn/tqTf8CHgAAABBBm+BJqEFsmUwI//yEADAgAAAACUGeHkUVLX8BvQAAAAgBnj10Tf8CHgAAAAgBnj9qTf8CHgAAABBBmiRJqEFsmUwI//yEADAhAAAACUGeQkUVLX8BvQAAAAgBnmF0Tf8CHwAAAAgBnmNqTf8CHwAAABBBmmhJqEFsmUwI//yEADAgAAAACUGehkUVLX8BvQAAAAgBnqV0Tf8CHgAAAAgBnqdqTf8CHwAAABBBmqxJqEFsmUwI//yEADAhAAAACUGeykUVLX8BvQAAAAgBnul0Tf8CHgAAAAgBnutqTf8CHwAAABBBmvBJqEFsmUwI//yEADAgAAAACUGfDkUVLX8BvQAAAAgBny10Tf8CHgAAAAgBny9qTf8CHwAAABBBmzRJqEFsmUwI//yEADAhAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHwAAAAgBn3NqTf8CHgAAABBBm3hJqEFsmUwI//yEADAgAAAACUGflkUVLX8BvQAAAAgBn7V0Tf8CHgAAAAgBn7dqTf8CHgAAABBBm7xJqEFsmUwI//yEADAhAAAACUGf2kUVLX8BvQAAAAgBn/l0Tf8CHwAAAAgBn/tqTf8CHgAAABBBm+BJqEFsmUwI//yEADAgAAAACUGeHkUVLX8BvQAAAAgBnj10Tf8CHgAAAAgBnj9qTf8CHgAAABBBmiRJqEFsmUwI//yEADAhAAAACUGeQkUVLX8BvQAAAAgBnmF0Tf8CHwAAAAgBnmNqTf8CHwAAABBBmmhJqEFsmUwI//yEADAgAAAACUGehkUVLX8BvQAAAAgBnqV0Tf8CHgAAAAgBnqdqTf8CHwAAABBBmqxJqEFsmUwI//yEADAhAAAACUGeykUVLX8BvQAAAAgBnul0Tf8CHgAAAAgBnutqTf8CHwAAABBBmvBJqEFsmUwI//yEADAgAAAACUGfDkUVLX8BvQAAAAgBny10Tf8CHgAAAAgBny9qTf8CHwAAABBBmzRJqEFsmUwI//yEADAhAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHwAAAAgBn3NqTf8CHgAAABBBm3hJqEFsmUwI//yEADAgAAAACUGflkUVLX8BvQAAAAgBn7V0Tf8CHgAAAAgBn7dqTf8CHgAAABBBm7xJqEFsmUwI//yEADAhAAAACUGf2kUVLX8BvQAAAAgBn/l0Tf8CHwAAAAgBn/tqTf8CHgAAABBBm+BJqEFsmUwI//yEADAgAAAACUGeHkUVLX8BvQAAAAgBnj10Tf8CHgAAAAgBnj9qTf8CHgAAABBBmiRJqEFsmUwI//yEADAhAAAACUGeQkUVLX8BvQAAAAgBnmF0Tf8CHwAAAAgBnmNqTf8CHwAAABBBmmhJqEFsmUwI//yEADAgAAAACUGehkUVLX8BvQAAAAgBnqV0Tf8CHgAAAAgBnqdqTf8CHwAAABBBmqxJqEFsmUwI//yEADAhAAAACUGeykUVLX8BvQAAAAgBnul0Tf8CHgAAAAgBnutqTf8CHwAAABBBmvBJqEFsmUwI//yEADAgAAAACUGfDkUVLX8BvQAAAAgBny10Tf8CHgAAAAgBny9qTf8CHwAAABBBmzRJqEFsmUwI//yEADAhAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHwAAAAgBn3NqTf8CHgAAABBBm3hJqEFsmUwI//yEADAgAAAACUGflkUVLX8BvQAAAAgBn7V0Tf8CHgAAAAgBn7dqTf8CHgAAABBBm7xJqEFsmUwI//yEADAhAAAACUGf2kUVLX8BvQAAAAgBn/l0Tf8CHwAAAAgBn/tqTf8CHgAAABBBm+BJqEFsmUwI//yEADAgAAAACUGeHkUVLX8BvQAAAAgBnj10Tf8CHgAAAAgBnj9qTf8CHgAAABBBmiRJqEFsmUwI//yEADAhAAAACUGeQkUVLX8BvQAAAAgBnmF0Tf8CHwAAAAgBnmNqTf8CHwAAABBBmmhJqEFsmUwI//yEADAgAAAACUGehkUVLX8BvQAAAAgBnqV0Tf8CHgAAAAgBnqdqTf8CHwAAABBBmqxJqEFsmUwI//yEADAhAAAACUGeykUVLX8BvQAAAAgBnul0Tf8CHgAAAAgBnutqTf8CHwAAABBBmvBJqEFsmUwI//yEADAgAAAACUGfDkUVLX8BvQAAAAgBny10Tf8CHgAAAAgBny9qTf8CHwAAABBBmzRJqEFsmUwI//yEADAhAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHwAAAAgBn3NqTf8CHgAAABBBm3hJqEFsmUwI//yEADAgAAAACUGflkUVLX8BvQAAAAgBn7V0Tf8CHgAAAAgBn7dqTf8CHgAAABBBm7xJqEFsmUwI//yEADAhAAAACUGf2kUVLX8BvQAAAAgBn/l0Tf8CHwAAAAgBn/tqTf8CHgAAABBBm+BJqEFsmUwI//yEADAgAAAACUGeHkUVLX8BvQAAAAgBnj10Tf8CHgAAAAgBnj9qTf8CHgAAABBBmiRJqEFsmUwI//yEADAhAAAACUGeQkUVLX8BvQAAAAgBnmF0Tf8CHwAAAAgBnmNqTf8CHwAAABBBmmhJqEFsmUwI//yEADAgAAAACUGehkUVLX8BvQAAAAgBnqV0Tf8CHgAAAAgBnqdqTf8CHwAAABBBmqxJqEFsmUwI//yEADAhAAAACUGeykUVLX8BvQAAAAgBnul0Tf8CHgAAAAgBnutqTf8CHwAAABBBmvBJqEFsmUwI//yEADAgAAAACUGfDkUVLX8BvQAAAAgBny10Tf8CHgAAAAgBny9qTf8CHwAAABBBmzRJqEFsmUwI//yEADAhAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHwAAAAgBn3NqTf8CHgAAABBBm3hJqEFsmUwI//yEADAgAAAACUGflkUVLX8BvQAAAAgBn7V0Tf8CHgAAAAgBn7dqTf8CHgAAABBBm7xJqEFsmUwI//yEADAhAAAACUGf2kUVLX8BvQAAAAgBn/l0Tf8CHwAAAAgBn/tqTf8CHgAAABBBm+BJqEFsmUwI//yEADAgAAAACUGeHkUVLX8BvQAAAAgBnj10Tf8CHgAAAAgBnj9qTf8CHgAAABBBmiRJqEFsmUwI//yEADAhAAAACUGeQkUVLX8BvQAAAAgBnmF0Tf8CHwAAAAgBnmNqTf8CHwAAABBBmmhJqEFsmUwI//yEADAgAAAACUGehkUVLX8BvQAAAAgBnqV0Tf8CHgAAAAgBnqdqTf8CHwAAABBBmqxJqEFsmUwI//yEADAhAAAACUGeykUVLX8BvQAAAAgBnul0Tf8CHgAAAAgBnutqTf8CHwAAABBBmvBJqEFsmUwI//yEADAgAAAACUGfDkUVLX8BvQAAAAgBny10Tf8CHgAAAAgBny9qTf8CHwAAABBBmzRJqEFsmUwI//yEADAhAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHwAAAAgBn3NqTf8CHgAAABBBm3hJqEFsmUwI//yEADAgAAAACUGflkUVLX8BvQAAAAgBn7V0Tf8CHgAAAAgBn7dqTf8CHgAAABBBm7xJqEFsmUwI//yEADAhAAAACUGf2kUVLX8BvQAAAAgBn/l0Tf8CHwAAAAgBn/tqTf8CHgAAABBBm+BJqEFsmUwI//yEADAgAAAACUGeHkUVLX8BvQAAAAgBnj10Tf8CHgAAAAgBnj9qTf8CHgAAABBBmiRJqEFsmUwI//yEADAhAAAACUGeQkUVLX8BvQAAAAgBnmF0Tf8CHwAAAAgBnmNqTf8CHwAAABBBmmhJqEFsmUwI//yEADAgAAAACUGehkUVLX8BvQAAAAgBnqV0Tf8CHgAAAAgBnqdqTf8CHwAAABBBmqxJqEFsmUwI//yEADAhAAAACUGeykUVLX8BvQAAAAgBnul0Tf8CHgAAAAgBnutqTf8CHwAAABBBmvBJqEFsmUwI//yEADAgAAAACUGfDkUVLX8BvQAAAAgBny10Tf8CHgAAAAgBny9qTf8CHwAAABBBmzRJqEFsmUwI//yEADAhAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHwAAAAgBn3NqTf8CHgAAABBBm3hJqEFsmUwI//yEADAgAAAACUGflkUVLX8BvQAAAAgBn7V0Tf8CHgAAAAgBn7dqTf8CHgAAAA5Bm7lJqEFsmUwJvwACPwAAAcdliIIACv+ovgeiyy38AwAS5sKi8g3eGwi0H9M3b+CT9A6j5mvyY2MyuIDEh/H5FuL3jU2htt8O2PGeYkv41kOC7STHJ9vJyTtDBvCxBA/nGAegZ3Pt56RgsXrW4xUBRkQ39OHxLpWf/fj8Qa9CvHaklvv1dVFgPftbQlejSIo5IOFYjGExIFAKx1HmxzrAsv2dOmHut+AAk1wNPkeN4gWp2DLoX4+VbQBgOWh4d2dIXmeVcnmx38MP69ZKAqtQRyBEYNZvsGrhny9AIzi86Rf/tMWk0mQhHFITVjvOxEwAbuwXJgvVypQtWUY0YCsI/g9g09QzpwwdNXijPtxjPXrny3Z83Ji/3DamW2BzxDj3pwqwWZEuj7yj5WYqgrg9+BR7KfjOLedpOy2y37HIHvjO2ZOYL8bPjQ5vZto/JqvtFANckoArM3/jEzW5z80PR+mIn+gcdTFrRFX+HHhql3R0JalPQVpXwDhNOAAAAwAAAwAA/+T1tSa+x5+bV397VlzR+Z872+mvropC3iDk58CVN32aPeQBmGKK9g2BUvqz+xFG2rQHxaHjlT5qX8iPs1CvGQBkaOCYR7GnrZebVRxo7fSsUAAuIQAAAAtBmiRsR//8hAAwIQAAAAdBnkJ4rwG9AAAACAGeYXRN/wIeAAAACAGeY2pN/wIfAAAAEEGaaEmoQWiZTAj//IQAMCAAAAAJQZ6GRREtfwG9AAAACAGepXRN/wIfAAAACAGep2pN/wIeAAAAEEGarEmoQWyZTAj//IQAMCEAAAAJQZ7KRRUtfwG9AAAACAGe6XRN/wIeAAAACAGe62pN/wIfAAAAEEGa8EmoQWyZTAj//IQAMCAAAAAJQZ8ORRUtfwG9AAAACAGfLXRN/wIfAAAACAGfL2pN/wIeAAAAEEGbNEmoQWyZTAj//IQAMCAAAAAJQZ9SRRUtfwG9AAAACAGfcXRN/wIeAAAACAGfc2pN/wIfAAAAEEGbeEmoQWyZTAj//IQAMCAAAAAJQZ+WRRUtfwG9AAAACAGftXRN/wIfAAAACAGft2pN/wIfAAAAEEGbvEmoQWyZTAj//IQAMCEAAAAJQZ/aRRUtfwG9AAAACAGf+XRN/wIeAAAACAGf+2pN/wIfAAAAEEGb4EmoQWyZTAj//IQAMCAAAAAJQZ4eRRUtfwG9AAAACAGePXRN/wIfAAAACAGeP2pN/wIfAAAAEEGaJEmoQWyZTAj//IQAMCEAAAAJQZ5CRRUtfwG9AAAACAGeYXRN/wIeAAAACAGeY2pN/wIfAAAAEEGaaEmoQWyZTAj//IQAMCAAAAAJQZ6GRRUtfwG9AAAACAGepXRN/wIfAAAACAGep2pN/wIeAAAAEEGarEmoQWyZTAj//IQAMCEAAAAJQZ7KRRUtfwG9AAAACAGe6XRN/wIeAAAACAGe62pN/wIfAAAAEEGa8EmoQWyZTAj//IQAMCAAAAAJQZ8ORRUtfwG9AAAACAGfLXRN/wIfAAAACAGfL2pN/wIeAAAAEEGbNEmoQWyZTAj//IQAMCAAAAAJQZ9SRRUtfwG9AAAACAGfcXRN/wIeAAAACAGfc2pN/wIfAAAAEEGbeEmoQWyZTAj//IQAMCAAAAAJQZ+WRRUtfwG9AAAACAGftXRN/wIfAAAACAGft2pN/wIfAAAAEEGbvEmoQWyZTAj//IQAMCEAAAAJQZ/aRRUtfwG9AAAACAGf+XRN/wIeAAAACAGf+2pN/wIfAAAAEEGb4EmoQWyZTAj//IQAMCAAAAAJQZ4eRRUtfwG9AAAACAGePXRN/wIfAAAACAGeP2pN/wIfAAAAEEGaJEmoQWyZTAj//IQAMCEAAAAJQZ5CRRUtfwG9AAAACAGeYXRN/wIeAAAACAGeY2pN/wIfAAAAEEGaaEmoQWyZTAj//IQAMCAAAAAJQZ6GRRUtfwG9AAAACAGepXRN/wIfAAAACAGep2pN/wIeAAAAEEGarEmoQWyZTAj//IQAMCEAAAAJQZ7KRRUtfwG9AAAACAGe6XRN/wIeAAAACAGe62pN/wIfAAAAEEGa8EmoQWyZTAj//IQAMCAAAAAJQZ8ORRUtfwG9AAAACAGfLXRN/wIfAAAACAGfL2pN/wIeAAAAEEGbNEmoQWyZTAj//IQAMCAAAAAJQZ9SRRUtfwG9AAAACAGfcXRN/wIeAAAACAGfc2pN/wIfAAAAEEGbeEmoQWyZTAj//IQAMCAAAAAJQZ+WRRUtfwG9AAAACAGftXRN/wIfAAAACAGft2pN/wIfAAAAEEGbvEmoQWyZTAj//IQAMCEAAAAJQZ/aRRUtfwG9AAAACAGf+XRN/wIeAAAACAGf+2pN/wIfAAAAEEGb4EmoQWyZTAj//IQAMCAAAAAJQZ4eRRUtfwG9AAAACAGePXRN/wIfAAAACAGeP2pN/wIfAAAAEEGaJEmoQWyZTAj//IQAMCEAAAAJQZ5CRRUtfwG9AAAACAGeYXRN/wIeAAAACAGeY2pN/wIfAAAAEEGaaEmoQWyZTAj//IQAMCAAAAAJQZ6GRRUtfwG9AAAACAGepXRN/wIfAAAACAGep2pN/wIeAAAAEEGarEmoQWyZTAj//IQAMCEAAAAJQZ7KRRUtfwG9AAAACAGe6XRN/wIeAAAACAGe62pN/wIfAAAAEEGa8EmoQWyZTAj//IQAMCAAAAAJQZ8ORRUtfwG9AAAACAGfLXRN/wIfAAAACAGfL2pN/wIeAAAAEEGbNEmoQWyZTAj//IQAMCAAAAAJQZ9SRRUtfwG9AAAACAGfcXRN/wIeAAAACAGfc2pN/wIfAAAAEEGbeEmoQWyZTAj//IQAMCAAAAAJQZ+WRRUtfwG9AAAACAGftXRN/wIfAAAACAGft2pN/wIfAAAAEEGbvEmoQWyZTAj//IQAMCEAAAAJQZ/aRRUtfwG9AAAACAGf+XRN/wIeAAAACAGf+2pN/wIfAAAAEEGb4EmoQWyZTAj//IQAMCAAAAAJQZ4eRRUtfwG9AAAACAGePXRN/wIfAAAACAGeP2pN/wIfAAAAEEGaJEmoQWyZTAj//IQAMCEAAAAJQZ5CRRUtfwG9AAAACAGeYXRN/wIeAAAACAGeY2pN/wIfAAAAEEGaaEmoQWyZTAj//IQAMCAAAAAJQZ6GRRUtfwG9AAAACAGepXRN/wIfAAAACAGep2pN/wIeAAAAEEGarEmoQWyZTAj//IQAMCEAAAAJQZ7KRRUtfwG9AAAACAGe6XRN/wIeAAAACAGe62pN/wIfAAAAEEGa8EmoQWyZTAj//IQAMCAAAAAJQZ8ORRUtfwG9AAAACAGfLXRN/wIfAAAACAGfL2pN/wIeAAAAEEGbNEmoQWyZTAj//IQAMCAAAAAJQZ9SRRUtfwG9AAAACAGfcXRN/wIeAAAACAGfc2pN/wIfAAAAEEGbeEmoQWyZTAj//IQAMCAAAAAJQZ+WRRUtfwG9AAAACAGftXRN/wIfAAAACAGft2pN/wIfAAAAEEGbvEmoQWyZTAj//IQAMCEAAAAJQZ/aRRUtfwG9AAAACAGf+XRN/wIeAAAACAGf+2pN/wIfAAAAEEGb4EmoQWyZTAj//IQAMCAAAAAJQZ4eRRUtfwG9AAAACAGePXRN/wIfAAAACAGeP2pN/wIfAAAAEEGaJEmoQWyZTAj//IQAMCEAAAAJQZ5CRRUtfwG9AAAACAGeYXRN/wIeAAAACAGeY2pN/wIfAAAAEEGaaEmoQWyZTAj//IQAMCAAAAAJQZ6GRRUtfwG9AAAACAGepXRN/wIfAAAACAGep2pN/wIeAAAAEEGarEmoQWyZTAj//IQAMCEAAAAJQZ7KRRUtfwG9AAAACAGe6XRN/wIeAAAACAGe62pN/wIfAAAAEEGa8EmoQWyZTAj//IQAMCAAAAAJQZ8ORRUtfwG9AAAACAGfLXRN/wIfAAAACAGfL2pN/wIeAAAAEEGbNEmoQWyZTAj//IQAMCAAAAAJQZ9SRRUtfwG9AAAACAGfcXRN/wIeAAAACAGfc2pN/wIfAAAAEEGbeEmoQWyZTAj//IQAMCAAAAAJQZ+WRRUtfwG9AAAACAGftXRN/wIfAAAACAGft2pN/wIfAAAAEEGbvEmoQWyZTAj//IQAMCEAAAAJQZ/aRRUtfwG9AAAACAGf+XRN/wIeAAAACAGf+2pN/wIfAAAAEEGb4EmoQWyZTAj//IQAMCAAAAAJQZ4eRRUtfwG9AAAACAGePXRN/wIfAAAACAGeP2pN/wIfAAAAEEGaJEmoQWyZTAj//IQAMCEAAAAJQZ5CRRUtfwG9AAAACAGeYXRN/wIeAAAACAGeY2pN/wIfAAAAEEGaaEmoQWyZTAj//IQAMCAAAAAJQZ6GRRUtfwG9AAAACAGepXRN/wIfAAAACAGep2pN/wIeAAAAEEGarEmoQWyZTAj//IQAMCEAAAAJQZ7KRRUtfwG9AAAACAGe6XRN/wIeAAAACAGe62pN/wIfAAAAEEGa8EmoQWyZTAj//IQAMCAAAAAJQZ8ORRUtfwG9AAAACAGfLXRN/wIfAAAACAGfL2pN/wIeAAAAEEGbNEmoQWyZTAj//IQAMCAAAAAJQZ9SRRUtfwG9AAAACAGfcXRN/wIeAAAACAGfc2pN/wIfAAAAEEGbeEmoQWyZTAj//IQAMCAAAAAJQZ+WRRUtfwG9AAAACAGftXRN/wIfAAAACAGft2pN/wIfAAAAEEGbvEmoQWyZTAjf+lgAXkEAAAAJQZ/aRRUtfwG9AAAACAGf+XRN/wIeAAAACAGf+2pN/wIfAAAAEEGb4EmoQWyZTAjf+lgAXkAAAAAJQZ4eRRUtfwG9AAAACAGePXRN/wIfAAAACAGeP2pN/wIfAAAAEEGaJEmoQWyZTAi/+lgAXkEAAAAJQZ5CRRUtfwG9AAAACAGeYXRN/wIeAAAACAGeY2pN/wIfAAAAEEGaaEmoQWyZTAi/+lgAXkAAAAAJQZ6GRRUtfwG9AAAACAGepXRN/wIfAAAACAGep2pN/wIeAAAAEEGarEmoQWyZTAif8yAA44EAAAAJQZ7KRRUtfwG9AAAACAGe6XRN/wIeAAAACAGe62pN/wIfAAAAD0Ga8EmoQWyZTAn/5EACygAAAAlBnw5FFS1/Ab0AAAAIAZ8tdE3/Ah8AAAAIAZ8vak3/Ah4AAAAPQZs0SahBbJlMCX+HAAqoAAAACUGfUkUVLX8BvQAAAAgBn3F0Tf8CHgAAAAgBn3NqTf8CHwAAAA9Bm3hJqEFsmUwK/wAAm4AAAAAJQZ+WRRUtfwG9AAAACAGftXRN/wIfAAAACAGft2pN/wIfAAAADkGbuUmoQWyZTAm/AAI/AAAx5W1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAYagAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAADEPdHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAYagAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAACgAAAA4AAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAGGoAAACAAAAQAAAAAwh21kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAKAAAD6AAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAAMDJtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAC/yc3RibAAAAJZzdHNkAAAAAAAAAAEAAACGYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAACgAOAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAADBhdmNDAWQAC//hABdnZAALrNlCh2hAAAADAEAAAAUDxQplgAEABmjr48siwAAAABhzdHRzAAAAAAAAAAEAAAPoAAAEAAAAACBzdHNzAAAAAAAAAAQAAAABAAAA+wAAAfUAAALvAAAfOGN0dHMAAAAAAAAD5QAAAAEAAAgAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAEAAAAAACAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAADAAAAAABAAAEAAAAAAEAAAgAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAIAAAgAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAIAAAgAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAAAgAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAPoAAAAAQAAD7RzdHN6AAAAAAAAAAAAAAPoAAAEmAAAABcAAAAOAAAADAAAAA8AAAAyAAAAEQAAAA4AAAAQAAAAOwAAABYAAAAQAAAAEQAAADkAAAAVAAAAEgAAABIAAAA/AAAAFQAAABEAAAAaAAAANgAAABYAAAARAAAAEQAAAEQAAAAVAAAAHAAAABIAAAA9AAAAGAAAABMAAAASAAAAJQAAABcAAAASAAAAEQAAAC0AAAATAAAAEQAAAA4AAAAvAAAAEwAAABEAAAAQAAAAGAAAABEAAAAQAAAADgAAABgAAAARAAAAEAAAAA4AAAAkAAAAEQAAABAAAAAOAAAAFAAAABAAAAAOAAAADgAAABQAAAAQAAAADgAAAA4AAAAUAAAAEAAAAA4AAAAOAAAAFAAAABAAAAAOAAAADgAAABQAAAAQAAAADgAAAA4AAAAUAAAAEAAAAA4AAAAOAAAAFAAAABAAAAAOAAAADgAAABQAAAAQAAAADgAAAA4AAAAUAAAAEAAAAA4AAAAOAAAAFAAAABAAAAAOAAAADgAAABQAAAAQAAAADgAAAA4AAAAUAAAAEAAAAA4AAAAOAAAAFAAAABAAAAAOAAAADgAAABQAAAAQAAAADgAAAA4AAAA/AAAAHAAAABAAAAAQAAAAIgAAACEAAAAQAAAAEQAAAB8AAAAVAAAAEAAAABAAAAAjAAAAHQAAABAAAAARAAAAMwAAACEAAAAQAAAAEAAAABsAAAAVAAAAEgAAABEAAAAfAAAAHAAAABAAAAAQAAAAIwAAAB0AAAARAAAAEgAAAC8AAAAiAAAAEgAAABEAAAAjAAAAFgAAABIAAAAQAAAAIQAAABQAAAAQAAAAEAAAACMAAAAbAAAAEAAAABAAAAAxAAAAFgAAABEAAAAQAAAAHAAAAB0AAAAQAAAAEQAAACwAAAAeAAAAEAAAABEAAAAoAAAAHgAAABIAAAASAAAAOAAAAB4AAAASAAAAEAAAAEgAAAApAAAAEAAAADUAAAAvAAAAFwAAABAAAAA8AAAAIQAAABAAAAAQAAAANAAAACgAAAAQAAAAEAAAAFYAAAAdAAAAEAAAABAAAAAoAAAAHgAAABEAAAARAAAAHAAAAB4AAAARAAAAEQAAACMAAAAUAAAAEQAAABEAAAAxAAAAHgAAABEAAAASAAAALwAAACoAAAARAAAAEQAAABsAAAAUAAAAEAAAABAAAAAhAAAAFQAAABAAAAARAAAALgAAACIAAAAQAAAAEgAAACcAAAAWAAAAEAAAABEAAAAfAAAAHAAAABEAAAARAAAAJgAAAB4AAAARAAAAEQAAACIAAAAgAAAAEgAAABIAAAAcAAAAEQAAAlYAAAAXAAAAKwAAAA8AAAAOAAAAHgAAABIAAAAOAAAADwAAACQAAAAWAAAAEAAAAA8AAAAbAAAAEAAAAA8AAAAMAAAAYAAAABIAAAASAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABIAAAHLAAAADwAAAAsAAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAASAAABywAAAA8AAAALAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAFAAAAA0AAAAMAAAADAAAABQAAAANAAAADAAAAAwAAAAUAAAADQAAAAwAAAAMAAAAEwAAAA0AAAAMAAAADAAAABMAAAANAAAADAAAAAwAAAATAAAADQAAAAwAAAAMAAAAEgAAABRzdGNvAAAAAAAAAAEAAAAwAAAAYnVkdGEAAABabWV0YQAAAAAAAAAhaGRscgAAAAAAAAAAbWRpcmFwcGwAAAAAAAAAAAAAAAAtaWxzdAAAACWpdG9vAAAAHWRhdGEAAAABAAAAAExhdmY1OC4yOS4xMDA=\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}