{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchaparov/Dynamic_Pricing_MARL/blob/main/Bachelor_thesis_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uOcAEbJytPt"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHBieuNL8xwf"
      },
      "source": [
        "**Stationary Demand market:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XURsofIJaoBc",
        "outputId": "e3e003bf-9b16-41e3-937f-7f2132fb62f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Installing collected packages: stable_baselines3\n",
            "Successfully installed stable_baselines3-2.3.2\n",
            "Collecting huggingface_sb3\n",
            "  Downloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (0.20.3)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (6.0.1)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (1.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.6 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (2024.2.2)\n",
            "Installing collected packages: huggingface_sb3\n",
            "Successfully installed huggingface_sb3-3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install stable_baselines3 #\"stable-baselines3[extra]>=2.0.0a4\"\n",
        "!pip install huggingface_sb3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RRL2G5fym8ap"
      },
      "outputs": [],
      "source": [
        "from pickle import TRUE\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "class OligopolyMarketEnv(gym.Env):\n",
        "\n",
        "   # Because of google colab, we cannot implement the GUI ('human' render mode)\n",
        "    metadata = {\"render_modes\": [\"console\"]}\n",
        "\n",
        "    def __init__(self, a, b, beta_G, beta_L, reference_price, c, a_phi, before, max_steps, render_mode=\"console\"):\n",
        "        super(OligopolyMarketEnv, self).__init__()\n",
        "        self.render_mode = render_mode\n",
        "        self.reference_price = reference_price\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        self.beta_G = beta_G\n",
        "        self.beta_L = beta_L\n",
        "        self.c = c  # costs (Lower boundary for prices)\n",
        "        self.a_phi = a_phi\n",
        "        self.before = before\n",
        "        self.max_steps = max_steps # change of the price |max_steps| per year\n",
        "        self.last_action = None\n",
        "        self.last_profit = None\n",
        "        self.uv_buffer = []\n",
        "        self.revenue_buffer = []\n",
        "        self.t = 0\n",
        "        self.upper_bound = None\n",
        "        action = 0\n",
        "        self.count = max_steps\n",
        "\n",
        "\n",
        "\n",
        "         # Determine the upper bound of the action space\n",
        "        if self.reference_price <= self.a / self.b:\n",
        "            self.upper_bound = min((self.a + self.beta_G * self.reference_price) / (self.b + self.beta_G), (self.a - self.b * self.reference_price + self.beta_G * self.reference_price)/(self.beta_G))\n",
        "        else:\n",
        "            self.upper_bound = min((self.a + self.beta_L * self.reference_price) / (self.b + self.beta_L), (self.a - self.b * self.reference_price + self.beta_L * self.reference_price)/(self.beta_L))\n",
        "\n",
        "        # Ensure the upper bound is at least greater than the lower bound c\n",
        "        if self.upper_bound < self.c:\n",
        "           print(\"Watch out: upper_bound < costs\")\n",
        "\n",
        "        # Action space (price set by the firm) is bounded\n",
        "        # self.action_space = spaces.Box(low=np.array([c], dtype=np.float32), high=np.array([upper_bound], dtype=np.float32), dtype=np.float32)\n",
        "        # Normalize action [-1, 1]\n",
        "        self.action_space = spaces.Box(low=np.array([-1], dtype=np.float32), high=np.array([1], dtype=np.float32), dtype=np.float32)\n",
        "\n",
        "        # State space is the reference price\n",
        "        self.observation_space = spaces.Box(low=np.array([0], dtype=np.float32), high=np.array([np.inf], dtype=np.float32), shape=(1,), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        # rescale the action space [c, upper_bound]\n",
        "        # action = action\n",
        "        rescaled_action = self.c + ((action + 1.01) / 2 )* (self.upper_bound - self.c)\n",
        "        price = rescaled_action\n",
        "        done = False\n",
        "        # average_price = price  # Simplified for single agent\n",
        "        # b_phi = 1\n",
        "\n",
        "\n",
        "        # Implementing demand function\n",
        "        if self.reference_price > price:\n",
        "            demand = self.a - self.b * self.reference_price + self.beta_G * (self.reference_price - price)\n",
        "        else:\n",
        "            demand = self.a - self.b * self.reference_price + self.beta_L * (self.reference_price - price)\n",
        "\n",
        "        demand = np.array(demand).item()\n",
        "        demand = int(np.floor(demand))\n",
        "\n",
        "        # Ensuring float type inside the environment\n",
        "        # Converting from array to scalar if needed\n",
        "        if isinstance(price, np.ndarray):\n",
        "          price = price.item()\n",
        "\n",
        "        if isinstance(demand, np.ndarray):\n",
        "          demand = demand.item()\n",
        "\n",
        "        revenue = price * demand\n",
        "        self.revenue_buffer.append(revenue)\n",
        "        self.uv_buffer.append(np.random.randint(demand + 1, 1000))\n",
        "\n",
        "        # immediate reward function\n",
        "        if self.t == 0 or self.before >= self.t:\n",
        "           reward = self.revenue_buffer[self.t] / self.uv_buffer[self.t]\n",
        "        else:\n",
        "           reward = (self.revenue_buffer[self.t] / self.uv_buffer[self.t]) - (self.revenue_buffer[self.t - self.before] / self.uv_buffer[self.t - self.before])\n",
        "\n",
        "\n",
        "        # Store the last action and last profit for render()\n",
        "        self.last_action = rescaled_action\n",
        "        self.last_profit = revenue\n",
        "\n",
        "        next_state = np.array([self.reference_price]).astype(np.float32)  # State is constant\n",
        "        self.t += 1\n",
        "\n",
        "        if self.t == self.max_steps:\n",
        "          done = True\n",
        "          self.max_steps += self.count\n",
        "\n",
        "\n",
        "        return next_state, reward, done, False, {} #, action, price, demand, self.t, rescaled_action, self.revenue_buffer, self.uv_buffer\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed, options=options)\n",
        "       # we convert to float32 to make it more general, because we want to use continuous actions\n",
        "        return np.array([self.reference_price]).astype(np.float32), {}\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "      if self.render_mode == \"console\":\n",
        "          if self.last_action is not None and self.last_profit is not None:\n",
        "              # Ensure last_action and last_profit are scalars for formatting\n",
        "              if isinstance(self.last_action, np.ndarray):\n",
        "                  if self.last_action.size == 1:\n",
        "                      last_action = self.last_action.item()  # Convert single element array to scalar\n",
        "                  else:\n",
        "                      last_action = self.last_action\n",
        "                      print(\"Error: last_action is not a single element array\")\n",
        "              else:\n",
        "                  last_action = self.last_action  # if already scalar\n",
        "\n",
        "              if isinstance(self.last_profit, np.ndarray):\n",
        "                  if self.last_profit.size == 1:\n",
        "                      last_profit = self.last_profit.item()\n",
        "                  else:\n",
        "                      last_profit = self.last_profit\n",
        "                      print(\"Error: last_profit is not a single element array\")\n",
        "              else:\n",
        "                  last_profit = self.last_profit\n",
        "\n",
        "              print(f\"Reference Price: {self.reference_price:.3f}\")\n",
        "              print(f\"Last Action (Price Set by Firm): {last_action:.3f}\")\n",
        "              print(f\"Last Profit: {last_profit:.3f}\")\n",
        "\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST OF A NON-TRAINED ENV:"
      ],
      "metadata": {
        "id": "DBE3jJAQsMmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Test for compatability with the algorithms of stable_baselines3\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = OligopolyMarketEnv(a = 10, b = 1, beta_G = 2, beta_L = 2, reference_price = 1.0, c = 0, a_phi = 1, before = 2, max_steps = 3)\n",
        "# If the environment doesn't follow the interface, an error will be thrown\n",
        "check_env(env, warn=True)"
      ],
      "metadata": {
        "id": "LGtmZ_jIGmZr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "env = OligopolyMarketEnv(a = 10, b = 1, beta_G = 2, beta_L = 2, reference_price = 1.0, c = 0, a_phi = 1, before = 2, max_steps = 3)\n",
        "\n",
        "obs, _ = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "\n",
        "# Test:\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "    price = random.uniform(-1, 1)\n",
        "    print(f\"Step {step + 1}\")\n",
        "    obs, reward, done, false, info, action, price, demand, t, rescaled_action, revenue_buffer, uv_buffer = env.step(price)\n",
        "    print( \"reward=\", reward, \"action=\", action, \"done =\", done, \",price=\", price, \",demand=\", demand,\",t = \", t, \",rescaled_action=\", rescaled_action, \",revenue_buffer=\", revenue_buffer, \",uv_buffer=\", uv_buffer)\n",
        "    env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOvz1ebnD1N7",
        "outputId": "35de9ecd-3611-4fde-8c17-20e3ce84c0a6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box(0.0, inf, (1,), float32)\n",
            "Box(-1.0, 1.0, (1,), float32)\n",
            "[-0.50006974]\n",
            "Step 1\n",
            "reward= 0.0008989268667747776 action= -0.9683347397249891 done = False ,price= 0.08333052055002188 ,demand= 10 ,t =  1 ,rescaled_action= 0.08333052055002188 ,revenue_buffer= [0.8333052055002188] ,uv_buffer= [927]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.083\n",
            "Last Profit: 0.833\n",
            "Step 2\n",
            "reward= 0.06958028688963223 action= 0.7208096363796019 done = False ,price= 3.461619272759204 ,demand= 4 ,t =  2 ,rescaled_action= 3.461619272759204 ,revenue_buffer= [0.8333052055002188, 13.846477091036816] ,uv_buffer= [927, 199]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.462\n",
            "Last Profit: 13.846\n",
            "Step 3\n",
            "reward= 0.015302518936511543 action= 0.5145134490499625 done = True ,price= 3.049026898099925 ,demand= 4 ,t =  3 ,rescaled_action= 3.049026898099925 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997] ,uv_buffer= [927, 199, 797]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.049\n",
            "Last Profit: 12.196\n",
            "Step 4\n",
            "reward= 0.11207376443299193 action= 0.5794729490729613 done = False ,price= 3.1789458981459227 ,demand= 4 ,t =  4 ,rescaled_action= 3.1789458981459227 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369] ,uv_buffer= [927, 199, 797, 70]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.179\n",
            "Last Profit: 12.716\n",
            "Step 5\n",
            "reward= 0.02310318093418484 action= 0.9742944933193132 done = False ,price= 3.9685889866386264 ,demand= 3 ,t =  5 ,rescaled_action= 3.9685889866386264 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588] ,uv_buffer= [927, 199, 797, 70, 310]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.969\n",
            "Last Profit: 11.906\n",
            "Step 6\n",
            "reward= -0.16687276029447853 action= -0.22870318851230254 done = True ,price= 1.562593622975395 ,demand= 7 ,t =  6 ,rescaled_action= 1.562593622975395 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764] ,uv_buffer= [927, 199, 797, 70, 310, 740]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.563\n",
            "Last Profit: 10.938\n",
            "Step 7\n",
            "reward= -0.0074923147261674455 action= 0.15955640463467824 done = False ,price= 2.3391128092693565 ,demand= 6 ,t =  7 ,rescaled_action= 2.3391128092693565 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.339\n",
            "Last Profit: 14.035\n",
            "Step 8\n",
            "reward= 0.18639030644984364 action= 0.9681873752002277 done = False ,price= 3.9563747504004554 ,demand= 3 ,t =  8 ,rescaled_action= 3.9563747504004554 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.956\n",
            "Last Profit: 11.869\n",
            "Step 9\n",
            "reward= 0.014033976678356132 action= 0.4238208421500338 done = True ,price= 2.8676416843000676 ,demand= 5 ,t =  9 ,rescaled_action= 2.8676416843000676 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.868\n",
            "Last Profit: 14.338\n",
            "Step 10\n",
            "reward= -0.16707423651149628 action= 0.1890905273216701 done = False ,price= 2.39818105464334 ,demand= 6 ,t =  10 ,rescaled_action= 2.39818105464334 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.398\n",
            "Last Profit: 14.389\n",
            "Step 11\n",
            "reward= -0.023155301476511018 action= -0.2922240123413047 done = False ,price= 1.4355519753173906 ,demand= 8 ,t =  11 ,rescaled_action= 1.4355519753173906 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.436\n",
            "Last Profit: 11.484\n",
            "Step 12\n",
            "reward= -0.01907728310689217 action= 0.003855255523055323 done = True ,price= 2.0277105110461107 ,demand= 6 ,t =  12 ,rescaled_action= 2.0277105110461107 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.028\n",
            "Last Profit: 12.166\n",
            "Step 13\n",
            "reward= -0.015076002502209213 action= -0.9723900760726769 done = False ,price= 0.0752198478546462 ,demand= 10 ,t =  13 ,rescaled_action= 0.0752198478546462 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663, 0.7521984785464619] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810, 112]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.075\n",
            "Last Profit: 0.752\n",
            "Step 14\n",
            "reward= -0.013390072624630791 action= -0.9327377518624207 done = False ,price= 0.15452449627515863 ,demand= 10 ,t =  14 ,rescaled_action= 0.15452449627515863 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663, 0.7521984785464619, 1.5452449627515863] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810, 112, 948]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.155\n",
            "Last Profit: 1.545\n",
            "Step 15\n",
            "reward= 0.01755723632741924 action= -0.4957095797395623 done = True ,price= 1.0285808405208754 ,demand= 8 ,t =  15 ,rescaled_action= 1.0285808405208754 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663, 0.7521984785464619, 1.5452449627515863, 8.228646724167003] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810, 112, 948, 339]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.029\n",
            "Last Profit: 8.229\n",
            "Step 16\n",
            "reward= 0.018785509554372325 action= 0.14858046429517846 done = False ,price= 2.317160928590357 ,demand= 6 ,t =  16 ,rescaled_action= 2.317160928590357 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663, 0.7521984785464619, 1.5452449627515863, 8.228646724167003, 13.902965571542142] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810, 112, 948, 339, 681]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.317\n",
            "Last Profit: 13.903\n",
            "Step 17\n",
            "reward= 0.04157169866216394 action= 0.8007373029280702 done = False ,price= 3.6214746058561404 ,demand= 3 ,t =  17 ,rescaled_action= 3.6214746058561404 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663, 0.7521984785464619, 1.5452449627515863, 8.228646724167003, 13.902965571542142, 10.864423817568422] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810, 112, 948, 339, 681, 165]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.621\n",
            "Last Profit: 10.864\n",
            "Step 18\n",
            "reward= -0.0034784730381941763 action= -0.35792389258079527 done = True ,price= 1.3041522148384095 ,demand= 8 ,t =  18 ,rescaled_action= 1.3041522148384095 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663, 0.7521984785464619, 1.5452449627515863, 8.228646724167003, 13.902965571542142, 10.864423817568422, 10.433217718707276] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810, 112, 948, 339, 681, 165, 616]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.304\n",
            "Last Profit: 10.433\n",
            "Step 19\n",
            "reward= 0.013816656640077904 action= -0.3976010696699632 done = False ,price= 1.2247978606600736 ,demand= 8 ,t =  19 ,rescaled_action= 1.2247978606600736 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663, 0.7521984785464619, 1.5452449627515863, 8.228646724167003, 13.902965571542142, 10.864423817568422, 10.433217718707276, 9.798382885280589] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810, 112, 948, 339, 681, 165, 616, 123]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.225\n",
            "Last Profit: 9.798\n",
            "Step 20\n",
            "reward= -0.003416636755469703 action= 0.5668172326210017 done = False ,price= 3.1536344652420034 ,demand= 4 ,t =  20 ,rescaled_action= 3.1536344652420034 ,revenue_buffer= [0.8333052055002188, 13.846477091036816, 12.1961075923997, 12.71578359258369, 11.90576695991588, 10.938155360827764, 14.034676855616139, 11.869124251201367, 14.338208421500338, 14.389086327860042, 11.484415802539125, 12.166263066276663, 0.7521984785464619, 1.5452449627515863, 8.228646724167003, 13.902965571542142, 10.864423817568422, 10.433217718707276, 9.798382885280589, 12.614537860968014] ,uv_buffer= [927, 199, 797, 70, 310, 740, 454, 59, 319, 422, 527, 810, 112, 948, 339, 681, 165, 616, 123, 933]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.154\n",
            "Last Profit: 12.615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize the environment:"
      ],
      "metadata": {
        "id": "RlF2NfZcgT1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "vec_env = make_vec_env(OligopolyMarketEnv, n_envs=10, env_kwargs=dict(a = 10, b = 1, beta_G = 2, beta_L = 2, reference_price = 1.0, c = 0, a_phi = 1, before = 2, max_steps = 3))\n"
      ],
      "metadata": {
        "id": "9_vK1aWW2eX4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PPO model**"
      ],
      "metadata": {
        "id": "14o4_AawXfoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO(\n",
        "    policy = 'MlpPolicy',\n",
        "    env = vec_env,\n",
        "    seed = 0,\n",
        "    n_steps = 1024,\n",
        "    batch_size = 64,\n",
        "    n_epochs = 4,\n",
        "    gamma = 0.999,\n",
        "    gae_lambda = 0.98,\n",
        "    ent_coef = 0.01,\n",
        "    verbose=1).learn(100000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEIcpNBkXeNV",
        "outputId": "8a5b2805-1b0b-46b4-83bb-da21bce2ed80"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 3        |\n",
            "|    ep_rew_mean     | -0.00221 |\n",
            "| time/              |          |\n",
            "|    fps             | 6464     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 1        |\n",
            "|    total_timesteps | 10240    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3           |\n",
            "|    ep_rew_mean          | -0.00415    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2758        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011796741 |\n",
            "|    clip_fraction        | 0.12        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.39       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0291     |\n",
            "|    n_updates            | 4           |\n",
            "|    policy_gradient_loss | -0.00721    |\n",
            "|    std                  | 0.963       |\n",
            "|    value_loss           | 0.0485      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3            |\n",
            "|    ep_rew_mean          | 0.0015       |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2626         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071354485 |\n",
            "|    clip_fraction        | 0.0766       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.36        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00913     |\n",
            "|    n_updates            | 8            |\n",
            "|    policy_gradient_loss | -0.00348     |\n",
            "|    std                  | 0.936        |\n",
            "|    value_loss           | 0.062        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3            |\n",
            "|    ep_rew_mean          | -0.00334     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2507         |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 40960        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052567655 |\n",
            "|    clip_fraction        | 0.043        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.33        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0118      |\n",
            "|    n_updates            | 12           |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    std                  | 0.902        |\n",
            "|    value_loss           | 0.0684       |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 3         |\n",
            "|    ep_rew_mean          | -0.00856  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 2463      |\n",
            "|    iterations           | 5         |\n",
            "|    time_elapsed         | 20        |\n",
            "|    total_timesteps      | 51200     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0054056 |\n",
            "|    clip_fraction        | 0.0453    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.3      |\n",
            "|    explained_variance   | 0         |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.0354    |\n",
            "|    n_updates            | 16        |\n",
            "|    policy_gradient_loss | -0.00204  |\n",
            "|    std                  | 0.876     |\n",
            "|    value_loss           | 0.0604    |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3           |\n",
            "|    ep_rew_mean          | -0.00265    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2452        |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 25          |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007064849 |\n",
            "|    clip_fraction        | 0.0688      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.27       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0405      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00355    |\n",
            "|    std                  | 0.85        |\n",
            "|    value_loss           | 0.075       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3            |\n",
            "|    ep_rew_mean          | -0.00541     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 30           |\n",
            "|    total_timesteps      | 71680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035158521 |\n",
            "|    clip_fraction        | 0.0154       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.23        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0343       |\n",
            "|    n_updates            | 24           |\n",
            "|    policy_gradient_loss | -0.00062     |\n",
            "|    std                  | 0.819        |\n",
            "|    value_loss           | 0.0591       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 3           |\n",
            "|    ep_rew_mean          | -0.00134    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2377        |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 34          |\n",
            "|    total_timesteps      | 81920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004773786 |\n",
            "|    clip_fraction        | 0.0221      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0237     |\n",
            "|    n_updates            | 28          |\n",
            "|    policy_gradient_loss | -0.00114    |\n",
            "|    std                  | 0.788       |\n",
            "|    value_loss           | 0.0767      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 3            |\n",
            "|    ep_rew_mean          | 0.00301      |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2374         |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 38           |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028334493 |\n",
            "|    clip_fraction        | 0.0195       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.16        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.000452    |\n",
            "|    n_updates            | 32           |\n",
            "|    policy_gradient_loss | -0.000709    |\n",
            "|    std                  | 0.755        |\n",
            "|    value_loss           | 0.0894       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 3          |\n",
            "|    ep_rew_mean          | 0.0033     |\n",
            "| time/                   |            |\n",
            "|    fps                  | 2350       |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 43         |\n",
            "|    total_timesteps      | 102400     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00489795 |\n",
            "|    clip_fraction        | 0.0402     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.13      |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.02       |\n",
            "|    n_updates            | 36         |\n",
            "|    policy_gradient_loss | -0.000975  |\n",
            "|    std                  | 0.746      |\n",
            "|    value_loss           | 0.0837     |\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(model, vec_env, n_eval_episodes=10, deterministic=False)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUW5R_yxEGMa",
        "outputId": "64f51ef0-53cf-4184-be90-3c35153855e4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward=0.04 +/- 0.06986974285597451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the agent:"
      ],
      "metadata": {
        "id": "_FeVxfFMuUUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the trained agent\n",
        "# using the vec_env\n",
        "obs = vec_env.reset()\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "    action, _ = model.predict(obs, deterministic = False)\n",
        "    print(f\"Step {step + 1}\")\n",
        "    print(\"Action: \", action)\n",
        "    obs, reward, done, info = vec_env.step(action)\n",
        "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
        "    env.render()\n",
        "    if done.all == True:\n",
        "      print(\"End of the year\", \"reward=\", reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIG-OErXSkab",
        "outputId": "0c9130ce-7121-4569-cb81-ff98ebcda476"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1\n",
            "Action:  [[ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.41833025]\n",
            " [ 0.44089496]\n",
            " [-0.16658592]\n",
            " [ 0.52990174]\n",
            " [ 0.31309643]\n",
            " [ 0.32768342]\n",
            " [ 0.69872916]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.00805277 -0.00155923 -0.10269543  0.00106243  0.00030618  0.10648126\n",
            " -0.06882308 -0.00041931 -0.00895544 -0.000251  ] done= [ True  True  True  True  True  True  True  True  True  True]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 2\n",
            "Action:  [[ 0.39660737]\n",
            " [-0.92813253]\n",
            " [ 0.93720657]\n",
            " [ 0.0037632 ]\n",
            " [-0.15293449]\n",
            " [-0.28672224]\n",
            " [ 0.47033527]\n",
            " [-0.09174663]\n",
            " [-0.9309392 ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.01115048 -0.0236358   0.01794027  0.00430864 -0.4165536   0.00470677\n",
            "  0.03245796  0.04247309 -0.02429808 -0.00073038] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 3\n",
            "Action:  [[ 0.5397739 ]\n",
            " [ 1.        ]\n",
            " [ 0.13103005]\n",
            " [ 0.2404122 ]\n",
            " [ 1.        ]\n",
            " [ 0.4622901 ]\n",
            " [-0.5916269 ]\n",
            " [ 1.        ]\n",
            " [ 0.9252521 ]\n",
            " [-0.20850211]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.02782185 -0.00448102  0.0297478   0.00026138 -0.00461879 -0.10342758\n",
            "  0.0060198  -0.00448611  0.01133245  0.0110322 ] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 4\n",
            "Action:  [[0.5891447 ]\n",
            " [0.3725667 ]\n",
            " [0.57514703]\n",
            " [1.        ]\n",
            " [0.60631526]\n",
            " [0.18721315]\n",
            " [0.7088387 ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.06073656  0.09549435 -0.04173012 -0.01249484 -0.0337691   0.14682202\n",
            " -0.01234097 -0.03992051  0.00579529 -0.00038044] done= [ True  True  True  True  True  True  True  True  True  True]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 5\n",
            "Action:  [[ 0.16784522]\n",
            " [ 0.3818521 ]\n",
            " [-0.24214739]\n",
            " [ 0.13632357]\n",
            " [ 0.38562113]\n",
            " [ 0.5865233 ]\n",
            " [ 0.97589695]\n",
            " [ 0.34804165]\n",
            " [ 0.09633005]\n",
            " [ 0.46932214]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.00050507  0.00092077 -0.02656877 -0.00621505  0.05030749  0.01088775\n",
            "  0.00070469  0.04061912 -0.01077862  0.17712563] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 6\n",
            "Action:  [[ 0.98194003]\n",
            " [ 0.5123047 ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.09593484]\n",
            " [ 0.7485311 ]\n",
            " [-0.10483503]\n",
            " [ 1.        ]\n",
            " [ 0.8982723 ]\n",
            " [-0.7754065 ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.01968279 -0.09037327 -0.0020053  -0.00966835  0.02721356  0.0267069\n",
            "  0.07398582 -0.0006847   0.00559797 -0.00456083] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 7\n",
            "Action:  [[ 0.12032396]\n",
            " [ 0.54266655]\n",
            " [ 0.5398742 ]\n",
            " [-0.744956  ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [-0.32665372]\n",
            " [ 0.1559028 ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.02322339  0.02130143  0.44765046 -0.0025273  -0.05266788 -0.01441254\n",
            " -0.01897485  0.0081043  -0.00374368 -0.18790683] done= [ True  True  True  True  True  True  True  True  True  True]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 8\n",
            "Action:  [[ 1.        ]\n",
            " [ 0.96455586]\n",
            " [-0.07774961]\n",
            " [ 1.        ]\n",
            " [ 0.57715446]\n",
            " [ 0.2950699 ]\n",
            " [ 0.09854236]\n",
            " [ 0.5801257 ]\n",
            " [ 0.892859  ]\n",
            " [ 0.7569806 ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-5.7385918e-02 -1.4062035e-03  5.0130527e-02  5.9140532e-04\n",
            " -2.5540233e-02 -1.7327546e-01 -8.9852639e-02 -1.8478443e-04\n",
            "  4.6181956e-01  3.1537491e-01] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 9\n",
            "Action:  [[ 0.12834579]\n",
            " [ 0.799614  ]\n",
            " [-0.01210344]\n",
            " [ 0.0603562 ]\n",
            " [ 0.8862494 ]\n",
            " [-0.39089233]\n",
            " [ 1.        ]\n",
            " [ 0.85877   ]\n",
            " [ 1.        ]\n",
            " [-0.00906092]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.02356225 -0.02240798 -0.19055752  0.08223017  0.00482668  0.01280965\n",
            "  0.01022853 -0.03782688 -0.00777222  0.04566262] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 10\n",
            "Action:  [[ 0.34495205]\n",
            " [ 0.20727876]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 0.38474292]\n",
            " [-0.12957144]\n",
            " [ 0.6423834 ]\n",
            " [ 0.46974275]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.02150273  0.00142438 -0.05104421 -0.01113909  0.0770613  -0.01800874\n",
            "  0.00833708  0.00497434  0.7260186  -0.29994726] done= [ True  True  True  True  True  True  True  True  True  True]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 11\n",
            "Action:  [[1.        ]\n",
            " [1.        ]\n",
            " [0.18461257]\n",
            " [0.28758222]\n",
            " [0.27765176]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [0.91933674]\n",
            " [0.49949375]\n",
            " [0.3504972 ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.1243719   0.00398852 -0.2523743   0.24771516 -0.00047339 -0.00248744\n",
            "  0.          0.03119879  0.00568758 -0.04954387] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 12\n",
            "Action:  [[ 0.7077836 ]\n",
            " [ 0.25085646]\n",
            " [-0.572981  ]\n",
            " [-0.59153175]\n",
            " [ 0.42249358]\n",
            " [-0.32325476]\n",
            " [-0.569376  ]\n",
            " [ 0.4339836 ]\n",
            " [-0.21376812]\n",
            " [ 0.2566541 ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 1.2214748   1.0355293   0.0031742   0.00927334 -0.07282948  0.01498606\n",
            " -0.01872595  0.00399832 -1.0805676   0.02007198] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 13\n",
            "Action:  [[ 0.19257548]\n",
            " [ 1.        ]\n",
            " [ 0.5509509 ]\n",
            " [ 0.730078  ]\n",
            " [-0.5818143 ]\n",
            " [-0.35297006]\n",
            " [ 0.29295346]\n",
            " [ 0.95510733]\n",
            " [ 0.09445938]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-1.2707931e-01  4.0608782e-01 -3.4428381e-03 -2.9979047e-01\n",
            "  2.0390274e-02 -8.1438469e-03  1.6008377e-02 -2.5477566e-02\n",
            "  3.2812692e-02  1.8872984e-04] done= [ True  True  True  True  True  True  True  True  True  True]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 14\n",
            "Action:  [[-0.13274378]\n",
            " [ 0.14411312]\n",
            " [ 0.44329405]\n",
            " [ 1.        ]\n",
            " [ 0.7032619 ]\n",
            " [ 0.8549931 ]\n",
            " [-0.35654074]\n",
            " [ 1.        ]\n",
            " [-0.44019234]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-1.2356205e+00 -9.1881502e-01  5.1751868e-03  8.2467068e-03\n",
            "  3.5870660e-02 -4.1116294e-03  3.8576731e-03 -8.8263821e-04\n",
            " -8.3178543e-02 -2.2520687e-02] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 15\n",
            "Action:  [[ 0.49995717]\n",
            " [ 1.        ]\n",
            " [ 0.13329229]\n",
            " [-0.27284932]\n",
            " [ 1.        ]\n",
            " [ 0.7655194 ]\n",
            " [ 1.        ]\n",
            " [ 0.9742639 ]\n",
            " [-0.82905495]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.10345881 -0.41133437  0.03563149 -0.02874605  0.07756338 -0.0014906\n",
            " -0.00782663 -0.00815797 -0.04075195  0.02653994] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 16\n",
            "Action:  [[-0.34791958]\n",
            " [-0.58315325]\n",
            " [ 0.52190185]\n",
            " [ 0.9681527 ]\n",
            " [ 0.68910605]\n",
            " [-0.08634692]\n",
            " [ 0.8547164 ]\n",
            " [ 1.        ]\n",
            " [ 0.37342805]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.03382693 -0.11572339  0.01269712  0.22435611 -0.04072448  0.03028338\n",
            " -0.00130205 -0.00953154  0.02216187  0.00148119] done= [ True  True  True  True  True  True  True  True  True  True]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 17\n",
            "Action:  [[ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.30286273]\n",
            " [-0.53102934]\n",
            " [ 0.6570336 ]\n",
            " [ 0.6814451 ]\n",
            " [ 0.54200363]\n",
            " [-0.2775839 ]\n",
            " [ 0.96881866]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.13217248  0.00944631 -0.00783292 -0.0041619  -0.09242241  0.00015686\n",
            "  0.02210375 -0.00541689  0.0321759  -0.0314388 ] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 18\n",
            "Action:  [[0.03621197]\n",
            " [0.7102279 ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [0.43488804]\n",
            " [0.19051793]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.02930854  0.00169725 -0.02389904 -0.23175403 -0.00641448 -0.02687689\n",
            "  0.00030025 -0.00494262 -0.04652193 -0.00477304] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 19\n",
            "Action:  [[0.5422752 ]\n",
            " [0.839566  ]\n",
            " [0.2612125 ]\n",
            " [0.43426192]\n",
            " [1.        ]\n",
            " [0.00571358]\n",
            " [0.17764682]\n",
            " [0.5134766 ]\n",
            " [1.        ]\n",
            " [1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.0124429  -0.00430135 -0.02303909  0.03889484  0.00660783 -0.00152285\n",
            " -0.02503542  0.01065471  0.24821527 -0.00068309] done= [ True  True  True  True  True  True  True  True  True  True]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n",
            "Step 20\n",
            "Action:  [[ 0.9801878 ]\n",
            " [ 0.7213868 ]\n",
            " [ 0.87244165]\n",
            " [-0.60921705]\n",
            " [ 0.20539868]\n",
            " [ 1.        ]\n",
            " [ 0.5805476 ]\n",
            " [ 0.7677487 ]\n",
            " [-0.17911404]\n",
            " [-0.4594046 ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.00343464  0.02724507  0.01114688  0.00524823  0.04461224 -0.00265465\n",
            "  0.01604594  0.04790173  0.00507449 -0.00593241] done= [False False False False False False False False False False]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.809\n",
            "Last Profit: 7.282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMTvlhP6IxQQggNuXlpBIro",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}