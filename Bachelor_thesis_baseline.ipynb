{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchaparov/Dynamic_Pricing_MARL/blob/main/Bachelor_thesis_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uOcAEbJytPt"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHBieuNL8xwf"
      },
      "source": [
        "**Stationary Demand market:**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XURsofIJaoBc",
        "outputId": "bbbe12c3-7a05-4d15-aceb-b8f2adf330a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Installing collected packages: stable_baselines3\n",
            "Successfully installed stable_baselines3-2.3.2\n",
            "Collecting huggingface_sb3\n",
            "  Downloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: huggingface-hub~=0.8 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (0.20.3)\n",
            "Requirement already satisfied: pyyaml~=6.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (6.0.1)\n",
            "Requirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (1.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.6 in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub~=0.8->huggingface_sb3) (2024.2.2)\n",
            "Installing collected packages: huggingface_sb3\n",
            "Successfully installed huggingface_sb3-3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium\n",
        "!pip install numpy\n",
        "!pip install torch\n",
        "!pip install stable_baselines3 #\"stable-baselines3[extra]>=2.0.0a4\"\n",
        "!pip install huggingface_sb3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RRL2G5fym8ap"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "class OligopolyMarketEnv(gym.Env):\n",
        "\n",
        "   # Because of google colab, we cannot implement the GUI ('human' render mode)\n",
        "    metadata = {\"render_modes\": [\"console\"]}\n",
        "\n",
        "    def __init__(self, a, b, beta_G, beta_L, reference_price, c, a_phi, before, render_mode=\"console\"):\n",
        "        super(OligopolyMarketEnv, self).__init__()\n",
        "        self.render_mode = render_mode\n",
        "        self.reference_price = reference_price\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        self.beta_G = beta_G\n",
        "        self.beta_L = beta_L\n",
        "        self.c = c  # costs (Lower boundary for prices)\n",
        "        self.a_phi = a_phi\n",
        "        self.before = before\n",
        "        self.last_action = None\n",
        "        self.last_profit = None\n",
        "        self.uv_buffer = []\n",
        "        self.revenue_buffer = []\n",
        "        self.t = 0\n",
        "        self.upper_bound = None\n",
        "        action = 0\n",
        "\n",
        "\n",
        "\n",
        "         # Determine the upper bound of the action space\n",
        "        if self.reference_price <= self.a / self.b:\n",
        "            self.upper_bound = min((self.a + self.beta_G * self.reference_price) / (self.b + self.beta_G), (self.a - self.b * self.reference_price + self.beta_G * self.reference_price)/(self.beta_G))\n",
        "        else:\n",
        "            self.upper_bound = min((self.a + self.beta_L * self.reference_price) / (self.b + self.beta_L), (self.a - self.b * self.reference_price + self.beta_L * self.reference_price)/(self.beta_L))\n",
        "\n",
        "        # Ensure the upper bound is at least greater than the lower bound c\n",
        "        if self.upper_bound < self.c:\n",
        "           print(\"Watch out: upper_bound < costs\")\n",
        "\n",
        "        # Action space (price set by the firm) is bounded\n",
        "        # self.action_space = spaces.Box(low=np.array([c], dtype=np.float32), high=np.array([upper_bound], dtype=np.float32), dtype=np.float32)\n",
        "        # Normalize action [-1, 1]\n",
        "        self.action_space = spaces.Box(low=np.array([-1], dtype=np.float32), high=np.array([1], dtype=np.float32), dtype=np.float32)\n",
        "\n",
        "        # State space is the reference price\n",
        "        self.observation_space = spaces.Box(low=np.array([0], dtype=np.float32), high=np.array([np.inf], dtype=np.float32), shape=(1,), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        # rescale the action space [c, upper_bound]\n",
        "        action = action\n",
        "        rescaled_action = self.c + ((action + 1.01) / 2 )* (self.upper_bound - self.c)\n",
        "        price = rescaled_action\n",
        "        # average_price = price  # Simplified for single agent\n",
        "        b_phi = 1\n",
        "\n",
        "        # Implementing demand function\n",
        "        if self.reference_price > price:\n",
        "            demand = self.a - self.b * self.reference_price + self.beta_G * (self.reference_price - price)\n",
        "        else:\n",
        "            demand = self.a - self.b * self.reference_price + self.beta_L * (self.reference_price - price)\n",
        "\n",
        "        demand = np.array(demand).item()\n",
        "        demand = int(np.floor(demand))\n",
        "\n",
        "        # Ensuring float type inside the environment\n",
        "        # Converting from array to scalar if needed\n",
        "        if isinstance(price, np.ndarray):\n",
        "          price = price.item()\n",
        "\n",
        "        if isinstance(demand, np.ndarray):\n",
        "          demand = demand.item()\n",
        "\n",
        "        revenue = price * demand\n",
        "        self.revenue_buffer.append(revenue)\n",
        "        self.uv_buffer.append(np.random.randint(demand + 1, 1000))\n",
        "\n",
        "        # immediate reward function\n",
        "        if self.t == 0 or self.before >= self.t:\n",
        "           reward = self.revenue_buffer[self.t] / self.uv_buffer[self.t]\n",
        "        else:\n",
        "           reward = (self.revenue_buffer[self.t] / self.uv_buffer[self.t]) - (self.revenue_buffer[self.t - self.before] / self.uv_buffer[self.t - self.before])\n",
        "\n",
        "\n",
        "        # Store the last action and last profit for render()\n",
        "        self.last_action = rescaled_action\n",
        "        self.last_profit = revenue\n",
        "\n",
        "        next_state = np.array([self.reference_price]).astype(np.float32)  # State is constant\n",
        "        self.t += 1\n",
        "\n",
        "        return next_state, reward, False, False, {} #, action, price, demand, self.t, rescaled_action, self.revenue_buffer, self.uv_buffer\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed, options=options)\n",
        "       # we convert to float32 to make it more general, because we want to use continuous actions\n",
        "        return np.array([self.reference_price]).astype(np.float32), {}\n",
        "\n",
        "\n",
        "    def render(self):\n",
        "      if self.render_mode == \"console\":\n",
        "          if self.last_action is not None and self.last_profit is not None:\n",
        "              # Ensure last_action and last_profit are scalars for formatting\n",
        "              if isinstance(self.last_action, np.ndarray):\n",
        "                  if self.last_action.size == 1:\n",
        "                      last_action = self.last_action.item()  # Convert single element array to scalar\n",
        "                  else:\n",
        "                      last_action = self.last_action\n",
        "                      print(\"Error: last_action is not a single element array\")\n",
        "              else:\n",
        "                  last_action = self.last_action  # if already scalar\n",
        "\n",
        "              if isinstance(self.last_profit, np.ndarray):\n",
        "                  if self.last_profit.size == 1:\n",
        "                      last_profit = self.last_profit.item()\n",
        "                  else:\n",
        "                      last_profit = self.last_profit\n",
        "                      print(\"Error: last_profit is not a single element array\")\n",
        "              else:\n",
        "                  last_profit = self.last_profit\n",
        "\n",
        "              print(f\"Reference Price: {self.reference_price:.3f}\")\n",
        "              print(f\"Last Action (Price Set by Firm): {last_action:.3f}\")\n",
        "              print(f\"Last Profit: {last_profit:.3f}\")\n",
        "\n",
        "\n",
        "    def close(self):\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.env_checker import check_env\n",
        "env = OligopolyMarketEnv(a = 10, b = 1, beta_G = 2, beta_L = 2, reference_price = 1.0, c = 0, a_phi = 1, before = 2)\n",
        "# If the environment doesn't follow the interface, an error will be thrown\n",
        "check_env(env, warn=True)"
      ],
      "metadata": {
        "id": "LGtmZ_jIGmZr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST:"
      ],
      "metadata": {
        "id": "DBE3jJAQsMmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "env = OligopolyMarketEnv(a = 10, b = 1, beta_G = 2, beta_L = 2, reference_price = 1.0, c = 0, a_phi = 1, before = 2)\n",
        "\n",
        "obs, _ = env.reset()\n",
        "env.render()\n",
        "\n",
        "print(env.observation_space)\n",
        "print(env.action_space)\n",
        "print(env.action_space.sample())\n",
        "\n",
        "\n",
        "# Test:\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "    price = random.uniform(-1, 1)\n",
        "    print(f\"Step {step + 1}\")\n",
        "    obs, reward, false, false, info, action, price, demand, t, rescaled_action, revenue_buffer, uv_buffer = env.step(price)\n",
        "    print( \",reward=\", reward, \"action=\", action, \",price=\", price, \",demand=\", demand,\",t = \", t, \",rescaled_action=\", rescaled_action, \",revenue_buffer=\", revenue_buffer, \",uv_buffer=\", uv_buffer)\n",
        "    env.render()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOvz1ebnD1N7",
        "outputId": "eb25d9c0-4099-4364-c757-c13e5bcecb33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box(0.0, inf, (1,), float32)\n",
            "Box(-1.0, 1.0, (1,), float32)\n",
            "[0.9117773]\n",
            "Step 1\n",
            ",reward= 0.03791496961115526 action= 0.011065856297473475 ,price= 2.022131712594947 ,demand= 6 ,t =  1 ,rescaled_action= 2.022131712594947 ,revenue_buffer= [12.132790275569683] ,uv_buffer= [320]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 2.02213\n",
            "Last Profit: 12.13279\n",
            "Step 2\n",
            ",reward= 0.0003566514821281404 action= -0.9874637004031959 ,price= 0.02507259919360827 ,demand= 10 ,t =  2 ,rescaled_action= 0.02507259919360827 ,revenue_buffer= [12.132790275569683, 0.2507259919360827] ,uv_buffer= [320, 703]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 0.02507\n",
            "Last Profit: 0.25073\n",
            "Step 3\n",
            ",reward= 0.01830862357788818 action= -0.8352223877990064 ,price= 0.32955522440198726 ,demand= 10 ,t =  3 ,rescaled_action= 0.32955522440198726 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726] ,uv_buffer= [320, 703, 180]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 0.32956\n",
            "Last Profit: 3.29555\n",
            "Step 4\n",
            ",reward= 0.03175879328065287 action= 0.5375269180181408 ,price= 3.0750538360362816 ,demand= 4 ,t =  4 ,rescaled_action= 3.0750538360362816 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126] ,uv_buffer= [320, 703, 180, 383]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 3.07505\n",
            "Last Profit: 12.30022\n",
            "Step 5\n",
            ",reward= -0.01696555017899743 action= -0.9923444816263227 ,price= 0.015311036747354567 ,demand= 10 ,t =  5 ,rescaled_action= 0.015311036747354567 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567] ,uv_buffer= [320, 703, 180, 383, 114]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 0.01531\n",
            "Last Profit: 0.15311\n",
            "Step 6\n",
            ",reward= -0.0160104206879763 action= 0.43012613784265863 ,price= 2.8602522756853173 ,demand= 5 ,t =  6 ,rescaled_action= 2.8602522756853173 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586] ,uv_buffer= [320, 703, 180, 383, 114, 888]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 2.86025\n",
            "Last Profit: 14.30126\n",
            "Step 7\n",
            ",reward= 0.009587343431112396 action= -0.34827389651106233 ,price= 1.3034522069778753 ,demand= 8 ,t =  7 ,rescaled_action= 1.3034522069778753 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 1.30345\n",
            "Last Profit: 10.42762\n",
            "Step 8\n",
            ",reward= 0.007727994337097824 action= -0.036465112775940334 ,price= 1.9270697744481193 ,demand= 7 ,t =  8 ,rescaled_action= 1.9270697744481193 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 1.92707\n",
            "Last Profit: 13.48949\n",
            "Step 9\n",
            ",reward= 0.06045825743692622 action= 0.9036979804514496 ,price= 3.807395960902899 ,demand= 3 ,t =  9 ,rescaled_action= 3.807395960902899 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 3.80740\n",
            "Last Profit: 11.42219\n",
            "Step 10\n",
            ",reward= -0.005181329173847227 action= -0.38799144687631015 ,price= 1.2240171062473797 ,demand= 8 ,t =  10 ,rescaled_action= 1.2240171062473797 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 1.22402\n",
            "Last Profit: 9.79214\n",
            "Step 11\n",
            ",reward= 0.18890078836454566 action= 0.4315920444731127 ,price= 2.8631840889462254 ,demand= 5 ,t =  11 ,rescaled_action= 2.8631840889462254 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 2.86318\n",
            "Last Profit: 14.31592\n",
            "Step 12\n",
            ",reward= 0.13269003123288375 action= 0.9926659862006979 ,price= 3.985331972401396 ,demand= 3 ,t =  12 ,rescaled_action= 3.985331972401396 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 3.98533\n",
            "Last Profit: 11.95600\n",
            "Step 13\n",
            ",reward= -0.15236704397972695 action= -0.06724195308132042 ,price= 1.8655160938373592 ,demand= 7 ,t =  13 ,rescaled_action= 1.8655160938373592 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188, 13.058612656861515] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79, 121]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 1.86552\n",
            "Last Profit: 13.05861\n",
            "Step 14\n",
            ",reward= -0.14403464127251614 action= -0.6135367001722976 ,price= 0.7729265996554049 ,demand= 9 ,t =  14 ,rescaled_action= 0.7729265996554049 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188, 13.058612656861515, 6.956339396898644] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79, 121, 952]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 0.77293\n",
            "Last Profit: 6.95634\n",
            "Step 15\n",
            ",reward= -0.07278015399536238 action= -0.13148403063503977 ,price= 1.7370319387299205 ,demand= 7 ,t =  15 ,rescaled_action= 1.7370319387299205 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188, 13.058612656861515, 6.956339396898644, 12.159223571109443] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79, 121, 952, 346]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 1.73703\n",
            "Last Profit: 12.15922\n",
            "Step 16\n",
            ",reward= 0.02300238981098225 action= -0.18597426089026037 ,price= 1.6280514782194793 ,demand= 7 ,t =  16 ,rescaled_action= 1.6280514782194793 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188, 13.058612656861515, 6.956339396898644, 12.159223571109443, 11.396360347536355] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79, 121, 952, 346, 376]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 1.62805\n",
            "Last Profit: 11.39636\n",
            "Step 17\n",
            ",reward= -0.002456501341436733 action= 0.6669739290623959 ,price= 3.333947858124792 ,demand= 4 ,t =  17 ,rescaled_action= 3.333947858124792 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188, 13.058612656861515, 6.956339396898644, 12.159223571109443, 11.396360347536355, 13.335791432499168] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79, 121, 952, 346, 376, 408]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 3.33395\n",
            "Last Profit: 13.33579\n",
            "Step 18\n",
            ",reward= 0.023998911040498394 action= 0.6428284965095836 ,price= 3.2856569930191672 ,demand= 4 ,t =  18 ,rescaled_action= 3.2856569930191672 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188, 13.058612656861515, 6.956339396898644, 12.159223571109443, 11.396360347536355, 13.335791432499168, 13.142627972076669] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79, 121, 952, 346, 376, 408, 242]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 3.28566\n",
            "Last Profit: 13.14263\n",
            "Step 19\n",
            ",reward= 0.05308923731077767 action= 0.6726125122016688 ,price= 3.3452250244033377 ,demand= 4 ,t =  19 ,rescaled_action= 3.3452250244033377 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188, 13.058612656861515, 6.956339396898644, 12.159223571109443, 11.396360347536355, 13.335791432499168, 13.142627972076669, 13.38090009761335] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79, 121, 952, 346, 376, 408, 242, 156]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 3.34523\n",
            "Last Profit: 13.38090\n",
            "Step 20\n",
            ",reward= 0.12328965039478054 action= 0.5761825201965718 ,price= 3.1523650403931436 ,demand= 4 ,t =  20 ,rescaled_action= 3.1523650403931436 ,revenue_buffer= [12.132790275569683, 0.2507259919360827, 3.2955522440198726, 12.300215344145126, 0.15311036747354567, 14.301261378426586, 10.427617655823003, 13.489488421136835, 11.422187882708698, 9.792136849979038, 14.315920444731127, 11.955995917204188, 13.058612656861515, 6.956339396898644, 12.159223571109443, 11.396360347536355, 13.335791432499168, 13.142627972076669, 13.38090009761335, 12.609460161572574] ,uv_buffer= [320, 703, 180, 383, 114, 888, 954, 566, 160, 525, 55, 79, 121, 952, 346, 376, 408, 242, 156, 71]\n",
            "Reference Price: 1.00000\n",
            "Last Action (Price Set by Firm): 3.15237\n",
            "Last Profit: 12.60946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize the environment:"
      ],
      "metadata": {
        "id": "RlF2NfZcgT1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "\n",
        "# Use make_vec_env to create and vectorize your environment\n",
        "vec_env = make_vec_env(OligopolyMarketEnv, n_envs=10, env_kwargs=dict(a = 10, b = 1, beta_G = 2, beta_L = 2, reference_price = 1.0, c = 0, a_phi = 1, before = 2))\n"
      ],
      "metadata": {
        "id": "9_vK1aWW2eX4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PPO model**"
      ],
      "metadata": {
        "id": "14o4_AawXfoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO(\n",
        "    policy = 'MlpPolicy',\n",
        "    env = vec_env,\n",
        "    seed = 0,\n",
        "    n_steps = 1024,\n",
        "    batch_size = 64,\n",
        "    n_epochs = 4,\n",
        "    gamma = 0.999,\n",
        "    gae_lambda = 0.98,\n",
        "    ent_coef = 0.01,\n",
        "    verbose=1).learn(1000000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEIcpNBkXeNV",
        "outputId": "7e755bc0-9470-4bf0-e69a-26c3cdc5c9d0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "------------------------------\n",
            "| time/              |       |\n",
            "|    fps             | 6913  |\n",
            "|    iterations      | 1     |\n",
            "|    time_elapsed    | 1     |\n",
            "|    total_timesteps | 10240 |\n",
            "------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 3473         |\n",
            "|    iterations           | 2            |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035028562 |\n",
            "|    clip_fraction        | 0.0186       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0127      |\n",
            "|    n_updates            | 4            |\n",
            "|    policy_gradient_loss | -0.000874    |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.031        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2969         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018057786 |\n",
            "|    clip_fraction        | 0.0191       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0048      |\n",
            "|    n_updates            | 8            |\n",
            "|    policy_gradient_loss | -0.000475    |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.0345       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2830          |\n",
            "|    iterations           | 4             |\n",
            "|    time_elapsed         | 14            |\n",
            "|    total_timesteps      | 40960         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020420377 |\n",
            "|    clip_fraction        | 7.32e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.43         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.00465      |\n",
            "|    n_updates            | 12            |\n",
            "|    policy_gradient_loss | 0.000383      |\n",
            "|    std                  | 1.01          |\n",
            "|    value_loss           | 0.0359        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2676         |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020247533 |\n",
            "|    clip_fraction        | 0.00154      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.42        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0164      |\n",
            "|    n_updates            | 16           |\n",
            "|    policy_gradient_loss | 0.000163     |\n",
            "|    std                  | 1            |\n",
            "|    value_loss           | 0.037        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2639        |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 23          |\n",
            "|    total_timesteps      | 61440       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002224608 |\n",
            "|    clip_fraction        | 0.00774     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.43       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0503      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.000284   |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.0412      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2609        |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 27          |\n",
            "|    total_timesteps      | 71680       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001533152 |\n",
            "|    clip_fraction        | 0.0022      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.44       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0184      |\n",
            "|    n_updates            | 24          |\n",
            "|    policy_gradient_loss | -4.29e-05   |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.0271      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2544         |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 81920        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035283011 |\n",
            "|    clip_fraction        | 0.0152       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0293      |\n",
            "|    n_updates            | 28           |\n",
            "|    policy_gradient_loss | -0.00098     |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.034        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2533         |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 36           |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005470179 |\n",
            "|    clip_fraction        | 0.00134      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.44        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00529      |\n",
            "|    n_updates            | 32           |\n",
            "|    policy_gradient_loss | 0.000112     |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0391       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2525         |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 102400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026353467 |\n",
            "|    clip_fraction        | 0.00605      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00834      |\n",
            "|    n_updates            | 36           |\n",
            "|    policy_gradient_loss | -0.00017     |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.043        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2491         |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 45           |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004995279 |\n",
            "|    clip_fraction        | 0.000342     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.46        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0169       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | 0.000269     |\n",
            "|    std                  | 1.05         |\n",
            "|    value_loss           | 0.0341       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2489         |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 49           |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011129004 |\n",
            "|    clip_fraction        | 0.00779      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.48        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00619     |\n",
            "|    n_updates            | 44           |\n",
            "|    policy_gradient_loss | -0.000217    |\n",
            "|    std                  | 1.07         |\n",
            "|    value_loss           | 0.0255       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2477         |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 53           |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011813531 |\n",
            "|    clip_fraction        | 0.00491      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.51        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0162      |\n",
            "|    n_updates            | 48           |\n",
            "|    policy_gradient_loss | -0.000322    |\n",
            "|    std                  | 1.11         |\n",
            "|    value_loss           | 0.0339       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2465         |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 58           |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018337766 |\n",
            "|    clip_fraction        | 0.0114       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.53        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00323     |\n",
            "|    n_updates            | 52           |\n",
            "|    policy_gradient_loss | -0.000532    |\n",
            "|    std                  | 1.12         |\n",
            "|    value_loss           | 0.0378       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2466          |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 62            |\n",
            "|    total_timesteps      | 153600        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00094254146 |\n",
            "|    clip_fraction        | 0.00264       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.53         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.00737       |\n",
            "|    n_updates            | 56            |\n",
            "|    policy_gradient_loss | 6.51e-05      |\n",
            "|    std                  | 1.12          |\n",
            "|    value_loss           | 0.042         |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2445          |\n",
            "|    iterations           | 16            |\n",
            "|    time_elapsed         | 66            |\n",
            "|    total_timesteps      | 163840        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00031601975 |\n",
            "|    clip_fraction        | 9.77e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.54         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.00395      |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | 0.000144      |\n",
            "|    std                  | 1.13          |\n",
            "|    value_loss           | 0.0404        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2446          |\n",
            "|    iterations           | 17            |\n",
            "|    time_elapsed         | 71            |\n",
            "|    total_timesteps      | 174080        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00079535786 |\n",
            "|    clip_fraction        | 0.00139       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.56         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.00881      |\n",
            "|    n_updates            | 64            |\n",
            "|    policy_gradient_loss | 2.35e-05      |\n",
            "|    std                  | 1.16          |\n",
            "|    value_loss           | 0.0341        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2447         |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 75           |\n",
            "|    total_timesteps      | 184320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016602695 |\n",
            "|    clip_fraction        | 0.000732     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0058      |\n",
            "|    n_updates            | 68           |\n",
            "|    policy_gradient_loss | 7.83e-06     |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.0365       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2434         |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 79           |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020154726 |\n",
            "|    clip_fraction        | 0.0175       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.56        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00699     |\n",
            "|    n_updates            | 72           |\n",
            "|    policy_gradient_loss | -0.000733    |\n",
            "|    std                  | 1.15         |\n",
            "|    value_loss           | 0.0411       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2435         |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 84           |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010796366 |\n",
            "|    clip_fraction        | 0.00342      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.57        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0178       |\n",
            "|    n_updates            | 76           |\n",
            "|    policy_gradient_loss | 1.11e-05     |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.0415       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2435         |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 88           |\n",
            "|    total_timesteps      | 215040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020493525 |\n",
            "|    clip_fraction        | 0.00588      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00285      |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | 0.000117     |\n",
            "|    std                  | 1.18         |\n",
            "|    value_loss           | 0.0372       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2425         |\n",
            "|    iterations           | 22           |\n",
            "|    time_elapsed         | 92           |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020303917 |\n",
            "|    clip_fraction        | 0.00542      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.58        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00266     |\n",
            "|    n_updates            | 84           |\n",
            "|    policy_gradient_loss | -7.36e-05    |\n",
            "|    std                  | 1.17         |\n",
            "|    value_loss           | 0.0419       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2427          |\n",
            "|    iterations           | 23            |\n",
            "|    time_elapsed         | 97            |\n",
            "|    total_timesteps      | 235520        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00071225787 |\n",
            "|    clip_fraction        | 0.00605       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.58         |\n",
            "|    explained_variance   | 1.19e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.00278      |\n",
            "|    n_updates            | 88            |\n",
            "|    policy_gradient_loss | 0.000106      |\n",
            "|    std                  | 1.19          |\n",
            "|    value_loss           | 0.0384        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2423         |\n",
            "|    iterations           | 24           |\n",
            "|    time_elapsed         | 101          |\n",
            "|    total_timesteps      | 245760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010592148 |\n",
            "|    clip_fraction        | 0.00374      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.61        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0222       |\n",
            "|    n_updates            | 92           |\n",
            "|    policy_gradient_loss | 0.000112     |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.0309       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2418          |\n",
            "|    iterations           | 25            |\n",
            "|    time_elapsed         | 105           |\n",
            "|    total_timesteps      | 256000        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00023583646 |\n",
            "|    clip_fraction        | 0.00171       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.62         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0385        |\n",
            "|    n_updates            | 96            |\n",
            "|    policy_gradient_loss | 0.000339      |\n",
            "|    std                  | 1.23          |\n",
            "|    value_loss           | 0.0408        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2420         |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 109          |\n",
            "|    total_timesteps      | 266240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013548114 |\n",
            "|    clip_fraction        | 0.0109       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.62        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00871     |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.000207    |\n",
            "|    std                  | 1.22         |\n",
            "|    value_loss           | 0.0368       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2410        |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 114         |\n",
            "|    total_timesteps      | 276480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004425251 |\n",
            "|    clip_fraction        | 0.0201      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.62       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00273     |\n",
            "|    n_updates            | 104         |\n",
            "|    policy_gradient_loss | -0.000882   |\n",
            "|    std                  | 1.23        |\n",
            "|    value_loss           | 0.0327      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2411          |\n",
            "|    iterations           | 28            |\n",
            "|    time_elapsed         | 118           |\n",
            "|    total_timesteps      | 286720        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00063091924 |\n",
            "|    clip_fraction        | 0.00278       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.63         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.0139       |\n",
            "|    n_updates            | 108           |\n",
            "|    policy_gradient_loss | 0.000106      |\n",
            "|    std                  | 1.25          |\n",
            "|    value_loss           | 0.0384        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2413          |\n",
            "|    iterations           | 29            |\n",
            "|    time_elapsed         | 123           |\n",
            "|    total_timesteps      | 296960        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00077996956 |\n",
            "|    clip_fraction        | 0.00115       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.65         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.0139       |\n",
            "|    n_updates            | 112           |\n",
            "|    policy_gradient_loss | 0.00034       |\n",
            "|    std                  | 1.27          |\n",
            "|    value_loss           | 0.037         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2405         |\n",
            "|    iterations           | 30           |\n",
            "|    time_elapsed         | 127          |\n",
            "|    total_timesteps      | 307200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016118068 |\n",
            "|    clip_fraction        | 0.00352      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0136       |\n",
            "|    n_updates            | 116          |\n",
            "|    policy_gradient_loss | 0.000266     |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0359       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2408         |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 131          |\n",
            "|    total_timesteps      | 317440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029623858 |\n",
            "|    clip_fraction        | 0.00464      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0191      |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | 7.05e-05     |\n",
            "|    std                  | 1.27         |\n",
            "|    value_loss           | 0.0404       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2410         |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 135          |\n",
            "|    total_timesteps      | 327680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011710305 |\n",
            "|    clip_fraction        | 0.00352      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.66        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0136      |\n",
            "|    n_updates            | 124          |\n",
            "|    policy_gradient_loss | 0.000489     |\n",
            "|    std                  | 1.28         |\n",
            "|    value_loss           | 0.0417       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2404         |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 140          |\n",
            "|    total_timesteps      | 337920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010966563 |\n",
            "|    clip_fraction        | 0.00149      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.67        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0331       |\n",
            "|    n_updates            | 128          |\n",
            "|    policy_gradient_loss | 0.000437     |\n",
            "|    std                  | 1.29         |\n",
            "|    value_loss           | 0.0485       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2406         |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 144          |\n",
            "|    total_timesteps      | 348160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002730969 |\n",
            "|    clip_fraction        | 0.00146      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.68        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0152      |\n",
            "|    n_updates            | 132          |\n",
            "|    policy_gradient_loss | 0.00038      |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.0431       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2402          |\n",
            "|    iterations           | 35            |\n",
            "|    time_elapsed         | 149           |\n",
            "|    total_timesteps      | 358400        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020728834 |\n",
            "|    clip_fraction        | 0.001         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.69         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.00859      |\n",
            "|    n_updates            | 136           |\n",
            "|    policy_gradient_loss | 0.00038       |\n",
            "|    std                  | 1.31          |\n",
            "|    value_loss           | 0.0393        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2400         |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 153          |\n",
            "|    total_timesteps      | 368640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029732767 |\n",
            "|    clip_fraction        | 0.00723      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.69        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0276      |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.000127    |\n",
            "|    std                  | 1.31         |\n",
            "|    value_loss           | 0.0442       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2403         |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 378880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009626605 |\n",
            "|    clip_fraction        | 0.00115      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.000182    |\n",
            "|    n_updates            | 144          |\n",
            "|    policy_gradient_loss | 0.000163     |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0418       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2396        |\n",
            "|    iterations           | 38          |\n",
            "|    time_elapsed         | 162         |\n",
            "|    total_timesteps      | 389120      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002649869 |\n",
            "|    clip_fraction        | 0.00537     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0483      |\n",
            "|    n_updates            | 148         |\n",
            "|    policy_gradient_loss | 2.99e-05    |\n",
            "|    std                  | 1.33        |\n",
            "|    value_loss           | 0.0464      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2398         |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 166          |\n",
            "|    total_timesteps      | 399360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035887707 |\n",
            "|    clip_fraction        | 0.0187       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00498     |\n",
            "|    n_updates            | 152          |\n",
            "|    policy_gradient_loss | -0.000495    |\n",
            "|    std                  | 1.33         |\n",
            "|    value_loss           | 0.0388       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2400         |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 170          |\n",
            "|    total_timesteps      | 409600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031162116 |\n",
            "|    clip_fraction        | 0.00698      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.7         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0193       |\n",
            "|    n_updates            | 156          |\n",
            "|    policy_gradient_loss | -8.24e-05    |\n",
            "|    std                  | 1.32         |\n",
            "|    value_loss           | 0.041        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2395        |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 175         |\n",
            "|    total_timesteps      | 419840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003513792 |\n",
            "|    clip_fraction        | 0.00989     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.7        |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00554     |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.000254   |\n",
            "|    std                  | 1.32        |\n",
            "|    value_loss           | 0.0433      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2396         |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 179          |\n",
            "|    total_timesteps      | 430080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005371206 |\n",
            "|    clip_fraction        | 0.00281      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.71        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00925     |\n",
            "|    n_updates            | 164          |\n",
            "|    policy_gradient_loss | 0.000214     |\n",
            "|    std                  | 1.35         |\n",
            "|    value_loss           | 0.0438       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2398        |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 183         |\n",
            "|    total_timesteps      | 440320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004603426 |\n",
            "|    clip_fraction        | 0.0243      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0646      |\n",
            "|    n_updates            | 168         |\n",
            "|    policy_gradient_loss | -0.00105    |\n",
            "|    std                  | 1.34        |\n",
            "|    value_loss           | 0.0436      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2393        |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 188         |\n",
            "|    total_timesteps      | 450560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002389457 |\n",
            "|    clip_fraction        | 0.00701     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.72       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0167     |\n",
            "|    n_updates            | 172         |\n",
            "|    policy_gradient_loss | 0.0001      |\n",
            "|    std                  | 1.35        |\n",
            "|    value_loss           | 0.0438      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2395         |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 192          |\n",
            "|    total_timesteps      | 460800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047707083 |\n",
            "|    clip_fraction        | 0.0193       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0427       |\n",
            "|    n_updates            | 176          |\n",
            "|    policy_gradient_loss | -0.000407    |\n",
            "|    std                  | 1.34         |\n",
            "|    value_loss           | 0.0435       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2395         |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 196          |\n",
            "|    total_timesteps      | 471040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014184711 |\n",
            "|    clip_fraction        | 0.00374      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.72        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0174      |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | 0.000282     |\n",
            "|    std                  | 1.36         |\n",
            "|    value_loss           | 0.0466       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2393         |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 201          |\n",
            "|    total_timesteps      | 481280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008895664 |\n",
            "|    clip_fraction        | 0.00171      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.73        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0165      |\n",
            "|    n_updates            | 184          |\n",
            "|    policy_gradient_loss | 0.000146     |\n",
            "|    std                  | 1.37         |\n",
            "|    value_loss           | 0.0442       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2394        |\n",
            "|    iterations           | 48          |\n",
            "|    time_elapsed         | 205         |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002998285 |\n",
            "|    clip_fraction        | 0.0185      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.73       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0364      |\n",
            "|    n_updates            | 188         |\n",
            "|    policy_gradient_loss | -0.00057    |\n",
            "|    std                  | 1.37        |\n",
            "|    value_loss           | 0.0472      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2389          |\n",
            "|    iterations           | 49            |\n",
            "|    time_elapsed         | 210           |\n",
            "|    total_timesteps      | 501760        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00068854477 |\n",
            "|    clip_fraction        | 0.00881       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.75         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0221        |\n",
            "|    n_updates            | 192           |\n",
            "|    policy_gradient_loss | -0.000211     |\n",
            "|    std                  | 1.4           |\n",
            "|    value_loss           | 0.0485        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2390        |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 214         |\n",
            "|    total_timesteps      | 512000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003673296 |\n",
            "|    clip_fraction        | 0.0185      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.75       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0127     |\n",
            "|    n_updates            | 196         |\n",
            "|    policy_gradient_loss | -0.000605   |\n",
            "|    std                  | 1.39        |\n",
            "|    value_loss           | 0.0432      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2392         |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 218          |\n",
            "|    total_timesteps      | 522240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015893165 |\n",
            "|    clip_fraction        | 0.0129       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.76        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00353     |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.000217    |\n",
            "|    std                  | 1.42         |\n",
            "|    value_loss           | 0.045        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2387        |\n",
            "|    iterations           | 52          |\n",
            "|    time_elapsed         | 222         |\n",
            "|    total_timesteps      | 532480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002818477 |\n",
            "|    clip_fraction        | 0.0101      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.77       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0205     |\n",
            "|    n_updates            | 204         |\n",
            "|    policy_gradient_loss | -0.000392   |\n",
            "|    std                  | 1.41        |\n",
            "|    value_loss           | 0.0375      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2389         |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 227          |\n",
            "|    total_timesteps      | 542720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051557636 |\n",
            "|    clip_fraction        | 0.0406       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.77        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0322       |\n",
            "|    n_updates            | 208          |\n",
            "|    policy_gradient_loss | -0.00186     |\n",
            "|    std                  | 1.41         |\n",
            "|    value_loss           | 0.0332       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 2390       |\n",
            "|    iterations           | 54         |\n",
            "|    time_elapsed         | 231        |\n",
            "|    total_timesteps      | 552960     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00376711 |\n",
            "|    clip_fraction        | 0.0219     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.77      |\n",
            "|    explained_variance   | 1.19e-07   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.0517     |\n",
            "|    n_updates            | 212        |\n",
            "|    policy_gradient_loss | -0.000779  |\n",
            "|    std                  | 1.41       |\n",
            "|    value_loss           | 0.0581     |\n",
            "----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2387          |\n",
            "|    iterations           | 55            |\n",
            "|    time_elapsed         | 235           |\n",
            "|    total_timesteps      | 563200        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00078716985 |\n",
            "|    clip_fraction        | 0.00867       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.78         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.013        |\n",
            "|    n_updates            | 216           |\n",
            "|    policy_gradient_loss | 2.96e-05      |\n",
            "|    std                  | 1.44          |\n",
            "|    value_loss           | 0.0526        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2388         |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 240          |\n",
            "|    total_timesteps      | 573440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026381053 |\n",
            "|    clip_fraction        | 0.0115       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.8         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00313      |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -8.16e-06    |\n",
            "|    std                  | 1.46         |\n",
            "|    value_loss           | 0.0419       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2388        |\n",
            "|    iterations           | 57          |\n",
            "|    time_elapsed         | 244         |\n",
            "|    total_timesteps      | 583680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004719538 |\n",
            "|    clip_fraction        | 0.03        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.00408     |\n",
            "|    n_updates            | 224         |\n",
            "|    policy_gradient_loss | -0.00124    |\n",
            "|    std                  | 1.46        |\n",
            "|    value_loss           | 0.0473      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2386        |\n",
            "|    iterations           | 58          |\n",
            "|    time_elapsed         | 248         |\n",
            "|    total_timesteps      | 593920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005143963 |\n",
            "|    clip_fraction        | 0.0354      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.8        |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00411    |\n",
            "|    n_updates            | 228         |\n",
            "|    policy_gradient_loss | -0.00114    |\n",
            "|    std                  | 1.46        |\n",
            "|    value_loss           | 0.0432      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2388         |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 252          |\n",
            "|    total_timesteps      | 604160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012724146 |\n",
            "|    clip_fraction        | 0.00811      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.81        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00883      |\n",
            "|    n_updates            | 232          |\n",
            "|    policy_gradient_loss | -0.000146    |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.0438       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 2384       |\n",
            "|    iterations           | 60         |\n",
            "|    time_elapsed         | 257        |\n",
            "|    total_timesteps      | 614400     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00481285 |\n",
            "|    clip_fraction        | 0.0218     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.83      |\n",
            "|    explained_variance   | 1.79e-07   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.00142    |\n",
            "|    n_updates            | 236        |\n",
            "|    policy_gradient_loss | -0.00103   |\n",
            "|    std                  | 1.51       |\n",
            "|    value_loss           | 0.0427     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2385         |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 261          |\n",
            "|    total_timesteps      | 624640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024211672 |\n",
            "|    clip_fraction        | 0.00686      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.83        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0224      |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | 9.63e-05     |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.0525       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2386         |\n",
            "|    iterations           | 62           |\n",
            "|    time_elapsed         | 265          |\n",
            "|    total_timesteps      | 634880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037250128 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.83        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00904      |\n",
            "|    n_updates            | 244          |\n",
            "|    policy_gradient_loss | -0.000681    |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.0502       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2383          |\n",
            "|    iterations           | 63            |\n",
            "|    time_elapsed         | 270           |\n",
            "|    total_timesteps      | 645120        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00073760835 |\n",
            "|    clip_fraction        | 0.00217       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.84         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0492        |\n",
            "|    n_updates            | 248           |\n",
            "|    policy_gradient_loss | 0.000417      |\n",
            "|    std                  | 1.52          |\n",
            "|    value_loss           | 0.0406        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2385         |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 274          |\n",
            "|    total_timesteps      | 655360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009435845 |\n",
            "|    clip_fraction        | 0.00449      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.84        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0248       |\n",
            "|    n_updates            | 252          |\n",
            "|    policy_gradient_loss | 0.000151     |\n",
            "|    std                  | 1.51         |\n",
            "|    value_loss           | 0.0542       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2386         |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 278          |\n",
            "|    total_timesteps      | 665600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024163513 |\n",
            "|    clip_fraction        | 0.00881      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.84        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0122       |\n",
            "|    n_updates            | 256          |\n",
            "|    policy_gradient_loss | 0.000176     |\n",
            "|    std                  | 1.52         |\n",
            "|    value_loss           | 0.0474       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 66           |\n",
            "|    time_elapsed         | 283          |\n",
            "|    total_timesteps      | 675840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019276388 |\n",
            "|    clip_fraction        | 0.0106       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.84        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00134      |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.000172    |\n",
            "|    std                  | 1.53         |\n",
            "|    value_loss           | 0.0383       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 2384       |\n",
            "|    iterations           | 67         |\n",
            "|    time_elapsed         | 287        |\n",
            "|    total_timesteps      | 686080     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00381158 |\n",
            "|    clip_fraction        | 0.0217     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.85      |\n",
            "|    explained_variance   | 5.96e-08   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0206    |\n",
            "|    n_updates            | 264        |\n",
            "|    policy_gradient_loss | -0.000464  |\n",
            "|    std                  | 1.54       |\n",
            "|    value_loss           | 0.0439     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2385         |\n",
            "|    iterations           | 68           |\n",
            "|    time_elapsed         | 291          |\n",
            "|    total_timesteps      | 696320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008050654 |\n",
            "|    clip_fraction        | 0.004        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.86        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0377       |\n",
            "|    n_updates            | 268          |\n",
            "|    policy_gradient_loss | 0.000371     |\n",
            "|    std                  | 1.56         |\n",
            "|    value_loss           | 0.0435       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 296          |\n",
            "|    total_timesteps      | 706560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027455084 |\n",
            "|    clip_fraction        | 0.0111       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.87        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0122      |\n",
            "|    n_updates            | 272          |\n",
            "|    policy_gradient_loss | -0.000121    |\n",
            "|    std                  | 1.57         |\n",
            "|    value_loss           | 0.0412       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2384          |\n",
            "|    iterations           | 70            |\n",
            "|    time_elapsed         | 300           |\n",
            "|    total_timesteps      | 716800        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00035542395 |\n",
            "|    clip_fraction        | 0.000488      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.88         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.00226      |\n",
            "|    n_updates            | 276           |\n",
            "|    policy_gradient_loss | 0.00025       |\n",
            "|    std                  | 1.59          |\n",
            "|    value_loss           | 0.0378        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2381         |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 305          |\n",
            "|    total_timesteps      | 727040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012013487 |\n",
            "|    clip_fraction        | 0.00188      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.88        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0125      |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | 0.000158     |\n",
            "|    std                  | 1.59         |\n",
            "|    value_loss           | 0.0403       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2382         |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 309          |\n",
            "|    total_timesteps      | 737280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014289861 |\n",
            "|    clip_fraction        | 0.000195     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.89        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0129       |\n",
            "|    n_updates            | 284          |\n",
            "|    policy_gradient_loss | 0.000374     |\n",
            "|    std                  | 1.6          |\n",
            "|    value_loss           | 0.043        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 313          |\n",
            "|    total_timesteps      | 747520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007896087 |\n",
            "|    clip_fraction        | 0.00283      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.9         |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0202      |\n",
            "|    n_updates            | 288          |\n",
            "|    policy_gradient_loss | 0.000227     |\n",
            "|    std                  | 1.64         |\n",
            "|    value_loss           | 0.0447       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2380         |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 318          |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038517308 |\n",
            "|    clip_fraction        | 0.0143       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.92        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00183      |\n",
            "|    n_updates            | 292          |\n",
            "|    policy_gradient_loss | -0.000302    |\n",
            "|    std                  | 1.65         |\n",
            "|    value_loss           | 0.0469       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2382         |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 322          |\n",
            "|    total_timesteps      | 768000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025836192 |\n",
            "|    clip_fraction        | 0.0122       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.93        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0376       |\n",
            "|    n_updates            | 296          |\n",
            "|    policy_gradient_loss | -0.000302    |\n",
            "|    std                  | 1.68         |\n",
            "|    value_loss           | 0.0447       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2383         |\n",
            "|    iterations           | 76           |\n",
            "|    time_elapsed         | 326          |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028047226 |\n",
            "|    clip_fraction        | 0.00857      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.94        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00559      |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.000188    |\n",
            "|    std                  | 1.68         |\n",
            "|    value_loss           | 0.0406       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2380          |\n",
            "|    iterations           | 77            |\n",
            "|    time_elapsed         | 331           |\n",
            "|    total_timesteps      | 788480        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00059068156 |\n",
            "|    clip_fraction        | 0.00498       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.95         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.00408       |\n",
            "|    n_updates            | 304           |\n",
            "|    policy_gradient_loss | 0.000101      |\n",
            "|    std                  | 1.71          |\n",
            "|    value_loss           | 0.0482        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2382        |\n",
            "|    iterations           | 78          |\n",
            "|    time_elapsed         | 335         |\n",
            "|    total_timesteps      | 798720      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004494884 |\n",
            "|    clip_fraction        | 0.027       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.95       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.00561    |\n",
            "|    n_updates            | 308         |\n",
            "|    policy_gradient_loss | -0.00144    |\n",
            "|    std                  | 1.7         |\n",
            "|    value_loss           | 0.0415      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2382         |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 339          |\n",
            "|    total_timesteps      | 808960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005172187 |\n",
            "|    clip_fraction        | 0.000269     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.95        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00752      |\n",
            "|    n_updates            | 312          |\n",
            "|    policy_gradient_loss | 0.000302     |\n",
            "|    std                  | 1.72         |\n",
            "|    value_loss           | 0.0422       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2379         |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 344          |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031201825 |\n",
            "|    clip_fraction        | 0.00967      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.96        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0194      |\n",
            "|    n_updates            | 316          |\n",
            "|    policy_gradient_loss | -0.000205    |\n",
            "|    std                  | 1.71         |\n",
            "|    value_loss           | 0.0426       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2380         |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 348          |\n",
            "|    total_timesteps      | 829440       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013786255 |\n",
            "|    clip_fraction        | 0.00376      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.96        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00517     |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -5.86e-05    |\n",
            "|    std                  | 1.73         |\n",
            "|    value_loss           | 0.0373       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2378         |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 352          |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009534644 |\n",
            "|    clip_fraction        | 0.00339      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.98        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0201      |\n",
            "|    n_updates            | 324          |\n",
            "|    policy_gradient_loss | 0.000174     |\n",
            "|    std                  | 1.76         |\n",
            "|    value_loss           | 0.0324       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2379        |\n",
            "|    iterations           | 83          |\n",
            "|    time_elapsed         | 357         |\n",
            "|    total_timesteps      | 849920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005428196 |\n",
            "|    clip_fraction        | 0.0267      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.98       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | -0.0242     |\n",
            "|    n_updates            | 328         |\n",
            "|    policy_gradient_loss | -0.0012     |\n",
            "|    std                  | 1.74        |\n",
            "|    value_loss           | 0.0451      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 2379          |\n",
            "|    iterations           | 84            |\n",
            "|    time_elapsed         | 361           |\n",
            "|    total_timesteps      | 860160        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00088637846 |\n",
            "|    clip_fraction        | 0.000952      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.98         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | -0.0262       |\n",
            "|    n_updates            | 332           |\n",
            "|    policy_gradient_loss | 0.000256      |\n",
            "|    std                  | 1.76          |\n",
            "|    value_loss           | 0.0396        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2376         |\n",
            "|    iterations           | 85           |\n",
            "|    time_elapsed         | 366          |\n",
            "|    total_timesteps      | 870400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019292769 |\n",
            "|    clip_fraction        | 0.00591      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2           |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0506       |\n",
            "|    n_updates            | 336          |\n",
            "|    policy_gradient_loss | -8.99e-05    |\n",
            "|    std                  | 1.81         |\n",
            "|    value_loss           | 0.0445       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2376         |\n",
            "|    iterations           | 86           |\n",
            "|    time_elapsed         | 370          |\n",
            "|    total_timesteps      | 880640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028811663 |\n",
            "|    clip_fraction        | 0.00366      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.012       |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | 3.1e-06      |\n",
            "|    std                  | 1.81         |\n",
            "|    value_loss           | 0.0413       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2376         |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 374          |\n",
            "|    total_timesteps      | 890880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025546842 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.01        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0162      |\n",
            "|    n_updates            | 344          |\n",
            "|    policy_gradient_loss | -0.000739    |\n",
            "|    std                  | 1.79         |\n",
            "|    value_loss           | 0.0485       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2374         |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 379          |\n",
            "|    total_timesteps      | 901120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035433143 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2           |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0245       |\n",
            "|    n_updates            | 348          |\n",
            "|    policy_gradient_loss | -0.000389    |\n",
            "|    std                  | 1.79         |\n",
            "|    value_loss           | 0.0438       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2375         |\n",
            "|    iterations           | 89           |\n",
            "|    time_elapsed         | 383          |\n",
            "|    total_timesteps      | 911360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024571072 |\n",
            "|    clip_fraction        | 0.0149       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.01        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0301       |\n",
            "|    n_updates            | 352          |\n",
            "|    policy_gradient_loss | -0.000511    |\n",
            "|    std                  | 1.82         |\n",
            "|    value_loss           | 0.06         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2373         |\n",
            "|    iterations           | 90           |\n",
            "|    time_elapsed         | 388          |\n",
            "|    total_timesteps      | 921600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012143679 |\n",
            "|    clip_fraction        | 0.0116       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.00605     |\n",
            "|    n_updates            | 356          |\n",
            "|    policy_gradient_loss | -0.0002      |\n",
            "|    std                  | 1.82         |\n",
            "|    value_loss           | 0.0398       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 2373       |\n",
            "|    iterations           | 91         |\n",
            "|    time_elapsed         | 392        |\n",
            "|    total_timesteps      | 931840     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00219706 |\n",
            "|    clip_fraction        | 0.0173     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.02      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0163    |\n",
            "|    n_updates            | 360        |\n",
            "|    policy_gradient_loss | -0.000433  |\n",
            "|    std                  | 1.82       |\n",
            "|    value_loss           | 0.0404     |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2374         |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 396          |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032979771 |\n",
            "|    clip_fraction        | 0.0115       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0174      |\n",
            "|    n_updates            | 364          |\n",
            "|    policy_gradient_loss | 5.54e-06     |\n",
            "|    std                  | 1.82         |\n",
            "|    value_loss           | 0.0482       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2371         |\n",
            "|    iterations           | 93           |\n",
            "|    time_elapsed         | 401          |\n",
            "|    total_timesteps      | 952320       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027498591 |\n",
            "|    clip_fraction        | 0.0103       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.03        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.00759      |\n",
            "|    n_updates            | 368          |\n",
            "|    policy_gradient_loss | 3.12e-05     |\n",
            "|    std                  | 1.83         |\n",
            "|    value_loss           | 0.0389       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2372         |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 405          |\n",
            "|    total_timesteps      | 962560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033426187 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | -0.0199      |\n",
            "|    n_updates            | 372          |\n",
            "|    policy_gradient_loss | -0.000328    |\n",
            "|    std                  | 1.82         |\n",
            "|    value_loss           | 0.0387       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 2373        |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 409         |\n",
            "|    total_timesteps      | 972800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004092892 |\n",
            "|    clip_fraction        | 0.0229      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.02       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0529      |\n",
            "|    n_updates            | 376         |\n",
            "|    policy_gradient_loss | -0.000992   |\n",
            "|    std                  | 1.81        |\n",
            "|    value_loss           | 0.0495      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2371         |\n",
            "|    iterations           | 96           |\n",
            "|    time_elapsed         | 414          |\n",
            "|    total_timesteps      | 983040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038033382 |\n",
            "|    clip_fraction        | 0.0148       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0429       |\n",
            "|    n_updates            | 380          |\n",
            "|    policy_gradient_loss | -0.000584    |\n",
            "|    std                  | 1.82         |\n",
            "|    value_loss           | 0.0432       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2372         |\n",
            "|    iterations           | 97           |\n",
            "|    time_elapsed         | 418          |\n",
            "|    total_timesteps      | 993280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032957338 |\n",
            "|    clip_fraction        | 0.0184       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.02        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0142       |\n",
            "|    n_updates            | 384          |\n",
            "|    policy_gradient_loss | -0.000928    |\n",
            "|    std                  | 1.84         |\n",
            "|    value_loss           | 0.0357       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 2373         |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 422          |\n",
            "|    total_timesteps      | 1003520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011809979 |\n",
            "|    clip_fraction        | 0.00576      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -2.05        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.0593       |\n",
            "|    n_updates            | 388          |\n",
            "|    policy_gradient_loss | -0.000188    |\n",
            "|    std                  | 1.89         |\n",
            "|    value_loss           | 0.0514       |\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the agent:"
      ],
      "metadata": {
        "id": "_FeVxfFMuUUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the trained agent\n",
        "# using the vecenv\n",
        "obs = vec_env.reset()\n",
        "n_steps = 20\n",
        "for step in range(n_steps):\n",
        "    action, _ = model.predict(obs, deterministic = False)\n",
        "    print(f\"Step {step + 1}\")\n",
        "    print(\"Action: \", action)\n",
        "    obs, reward, done, info = vec_env.step(action)\n",
        "    print(\"obs=\", obs, \"reward=\", reward)\n",
        "    vec_env.render()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIG-OErXSkab",
        "outputId": "02b8c33b-9ae6-4ef6-f9b1-7fb53144727b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1\n",
            "Action:  [[ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.56757253]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [-0.722242  ]\n",
            " [ 1.        ]\n",
            " [ 0.06750298]\n",
            " [ 1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.00358075  0.0301524   0.01621884 -0.01479498  0.02483997 -0.01055197\n",
            "  0.16385403  0.1289105   0.01060945  0.01158481]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.155\n",
            "Last Profit: 12.621\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.576\n",
            "Last Profit: 5.180\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.155\n",
            "Last Profit: 12.930\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 2\n",
            "Action:  [[ 1.        ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.20092082]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 1.8575467e-03  1.7271896e-03 -8.0694677e-03  3.9504426e-05\n",
            "  1.0897984e-02 -3.2029290e-02 -2.5568354e-01  1.4079795e-02\n",
            " -3.4716170e-02  3.8418274e-02]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.422\n",
            "Last Profit: 14.531\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 3\n",
            "Action:  [[ 0.09726107]\n",
            " [ 0.95734626]\n",
            " [ 0.13743734]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [-0.53504384]\n",
            " [ 0.38861632]\n",
            " [ 1.        ]\n",
            " [ 0.4625939 ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.02248445 -0.02963687  0.02783292  0.02471357 -0.03705046  0.00424554\n",
            " -0.16653559 -0.02334457  0.0126538  -0.01456703]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.215\n",
            "Last Profit: 13.287\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.935\n",
            "Last Profit: 11.804\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.295\n",
            "Last Profit: 13.769\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.950\n",
            "Last Profit: 8.549\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.797\n",
            "Last Profit: 13.986\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.945\n",
            "Last Profit: 14.726\n",
            "Step 4\n",
            "Action:  [[ 1.        ]\n",
            " [ 0.6686743 ]\n",
            " [ 0.35824966]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.79828006]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.00855635  0.01703602  0.01985244  0.00060202  0.04215308  0.00277089\n",
            " -0.0330095  -0.01581363 -0.00748136 -0.0047298 ]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.357\n",
            "Last Profit: 13.429\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.736\n",
            "Last Profit: 13.682\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.617\n",
            "Last Profit: 10.850\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 5\n",
            "Action:  [[ 1.        ]\n",
            " [ 0.25234008]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.1764952 ]\n",
            " [ 0.45612514]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.02751761  0.00136268 -0.02816214 -0.00317636  0.44351727  0.02548576\n",
            " -0.00658595 -0.10557771 -0.01294279 -0.01263301]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.525\n",
            "Last Profit: 12.623\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.373\n",
            "Last Profit: 14.238\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.932\n",
            "Last Profit: 14.661\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 6\n",
            "Action:  [[ 1.        ]\n",
            " [ 1.        ]\n",
            " [-0.7395147 ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [-0.99928534]\n",
            " [ 1.        ]\n",
            " [ 0.8352086 ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.00193752  0.00116687 -0.01294082 -0.00302064 -0.04875238  0.00608312\n",
            "  0.10915055 -0.01196661  0.00923392 -0.01234266]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.541\n",
            "Last Profit: 4.869\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.021\n",
            "Last Profit: 0.214\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.690\n",
            "Last Profit: 11.071\n",
            "Step 7\n",
            "Action:  [[ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.41850853]\n",
            " [ 1.        ]\n",
            " [ 0.9603209 ]\n",
            " [ 0.8281823 ]\n",
            " [-1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 2.2937987e-02 -5.9935544e-03  5.4841875e-03  7.7868305e-02\n",
            " -4.3555412e-01  2.5725950e-02  3.8139258e-02 -7.9118094e-05\n",
            " -1.0409949e-02  3.1217920e-02]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.857\n",
            "Last Profit: 14.285\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.941\n",
            "Last Profit: 11.822\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.676\n",
            "Last Profit: 11.029\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 8\n",
            "Action:  [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.00405022 -0.02007769  0.00839167  0.00165536 -0.00042136  0.13321535\n",
            " -0.0970774   0.01182028 -0.00178937  0.03425195]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 9\n",
            "Action:  [[ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [ 1.]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.01180333  0.02348136 -0.01159938 -0.0910992   0.00510492  0.02131407\n",
            " -0.03884134  0.00041279  0.07562409 -0.02396187]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 10\n",
            "Action:  [[ 0.91023755]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [-0.2669556 ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 0.5115242 ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.00098112  0.00788388  0.00359267  0.01053714  0.00308081 -0.11748534\n",
            " -0.02087259  0.00754698  0.05492502 -0.04535094]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.840\n",
            "Last Profit: 11.521\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.486\n",
            "Last Profit: 11.889\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.043\n",
            "Last Profit: 12.172\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 11\n",
            "Action:  [[ 1.        ]\n",
            " [ 0.7621078 ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.09791875]\n",
            " [ 1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.01796867 -0.02008415  0.0009119  -0.00761307  0.00760143 -0.07159446\n",
            "  0.00032711  0.02315724 -0.06138862 -0.00900502]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.544\n",
            "Last Profit: 10.633\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.216\n",
            "Last Profit: 13.295\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 12\n",
            "Action:  [[ 1.        ]\n",
            " [ 0.7170095 ]\n",
            " [ 0.642217  ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [-0.49490917]\n",
            " [ 1.        ]\n",
            " [ 0.14528763]\n",
            " [-1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.03567395  0.00067164 -0.00213522 -0.00936475 -0.0034052  -0.02216386\n",
            "  0.00781137  0.00109076 -0.06418724  0.00321436]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.454\n",
            "Last Profit: 13.816\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.304\n",
            "Last Profit: 13.218\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.030\n",
            "Last Profit: 8.241\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.311\n",
            "Last Profit: 13.863\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 13\n",
            "Action:  [[1.        ]\n",
            " [0.5015787 ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [1.        ]\n",
            " [0.19844842]\n",
            " [0.36604548]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.03711152  0.02261848  0.01280423  0.00974048 -0.01290983  0.03465072\n",
            "  0.04133527 -0.00225608  0.00177852  0.00589941]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.023\n",
            "Last Profit: 12.093\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.417\n",
            "Last Profit: 14.501\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.752\n",
            "Last Profit: 13.760\n",
            "Step 14\n",
            "Action:  [[ 1.       ]\n",
            " [ 0.8178403]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [-1.       ]\n",
            " [ 1.       ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.01593797 -0.00555993  0.03444202  0.029285    0.02434029  0.19953004\n",
            "  0.02747854  0.00601924  0.00127161 -0.00462227]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.656\n",
            "Last Profit: 10.967\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 15\n",
            "Action:  [[ 0.25293517]\n",
            " [ 1.        ]\n",
            " [ 0.26779425]\n",
            " [ 0.0083456 ]\n",
            " [-1.        ]\n",
            " [ 0.58994687]\n",
            " [ 1.        ]\n",
            " [-0.17968833]\n",
            " [ 1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.04440724 -0.0234848  -0.00581137  0.16617967 -0.00892428 -0.03252611\n",
            " -0.03597439 -0.0099769   0.01110799  0.01393165]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.526\n",
            "Last Profit: 12.629\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.556\n",
            "Last Profit: 12.778\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.037\n",
            "Last Profit: 12.220\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.200\n",
            "Last Profit: 12.800\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.661\n",
            "Last Profit: 11.624\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 16\n",
            "Action:  [[ 0.11215389]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 0.42013812]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 0.4393618 ]\n",
            " [ 1.        ]\n",
            " [-0.80478966]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 5.2683305e-02 -3.1387468e-03 -2.3997266e-02 -1.6026486e-02\n",
            " -1.3310233e-02 -1.9635168e-01 -3.4842622e-02  1.7886600e-04\n",
            "  7.6483535e-03 -1.8614753e-03]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.244\n",
            "Last Profit: 13.466\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.860\n",
            "Last Profit: 14.301\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.899\n",
            "Last Profit: 14.494\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.410\n",
            "Last Profit: 4.104\n",
            "Step 17\n",
            "Action:  [[-1.       ]\n",
            " [ 1.       ]\n",
            " [-1.       ]\n",
            " [-0.4074483]\n",
            " [ 1.       ]\n",
            " [-1.       ]\n",
            " [-0.9454142]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [-1.       ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.02229514  0.0083387  -0.01759203 -0.12554836  0.01292652 -0.01280884\n",
            " -0.01223451 -0.00282021  0.00468493 -0.03101268]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.205\n",
            "Last Profit: 9.641\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.129\n",
            "Last Profit: 1.292\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Step 18\n",
            "Action:  [[ 1.        ]\n",
            " [-1.        ]\n",
            " [ 0.95707667]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [-0.07718915 -0.008975    0.00986193  0.11476333 -0.01360043 -0.01324708\n",
            "  0.0327674  -0.00948723  0.01142074  0.27992985]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 3.934\n",
            "Last Profit: 11.802\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 19\n",
            "Action:  [[ 0.00750458]\n",
            " [ 1.        ]\n",
            " [-0.13540864]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]\n",
            " [-1.        ]\n",
            " [-1.        ]\n",
            " [ 1.        ]\n",
            " [ 1.        ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.04702818 -0.00427284  0.01246776 -0.05104632  0.01118331  0.17417471\n",
            "  0.00121428 -0.00856918 -0.00382135  0.01068231]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.035\n",
            "Last Profit: 12.210\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.749\n",
            "Last Profit: 12.244\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Step 20\n",
            "Action:  [[ 1.       ]\n",
            " [-1.       ]\n",
            " [ 0.3778392]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [-0.2586671]\n",
            " [ 1.       ]\n",
            " [ 1.       ]\n",
            " [-1.       ]]\n",
            "obs= [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] reward= [ 0.08075276  0.0010863   0.0508916  -0.11071301  0.0085215   0.01003774\n",
            "  0.07840064 -0.00865396  0.15379044 -0.28655633]\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 2.776\n",
            "Last Profit: 13.878\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 1.503\n",
            "Last Profit: 10.519\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 4.020\n",
            "Last Profit: 8.040\n",
            "Reference Price: 1.000\n",
            "Last Action (Price Set by Firm): 0.020\n",
            "Last Profit: 0.200\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMr76rfiag8ScWIUuRKumCG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}