{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchaparov/Dynamic_Pricing_MARL/blob/main/FrozenLake_ppo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jc6PhCfc4Ts",
        "outputId": "271469b9-feb4-4eb0-a580-0efcecf1a0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stable-baselines3==2.0.0a5\n",
            "  Downloading stable_baselines3-2.0.0a5-py3-none-any.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.5/177.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium==0.28.1 (from stable-baselines3==2.0.0a5)\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5) (2.2.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3==2.0.0a5) (3.7.1)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3==2.0.0a5) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium==0.28.1->stable-baselines3==2.0.0a5)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3==2.0.0a5) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->stable-baselines3==2.0.0a5)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3==2.0.0a5) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.0.0a5) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3==2.0.0a5) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3==2.0.0a5) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->stable-baselines3==2.0.0a5) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3==2.0.0a5) (1.3.0)\n",
            "Installing collected packages: farama-notifications, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, jax-jumpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, gymnasium, nvidia-cusolver-cu12, stable-baselines3\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 stable-baselines3-2.0.0a5\n",
            "Collecting swig\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.2.1\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3==2.0.0a5\n",
        "!pip install swig\n",
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization:"
      ],
      "metadata": {
        "id": "v_DwJdEpPxQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment:"
      ],
      "metadata": {
        "id": "vy2pV7xwQj0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import gymnasium as gym\n",
        "from gymnasium.envs.toy_text.frozen_lake import generate_random_map\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=generate_random_map(size=8), is_slippery = True)"
      ],
      "metadata": {
        "id": "EqtgPq0QQijp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Then we reset this environment\n",
        "observation, info = env.reset()\n",
        "\n",
        "for _ in range(20):\n",
        "  # Take a random action\n",
        "  action = env.action_space.sample()\n",
        "  print(\"Action taken:\", action)\n",
        "\n",
        "  # Do this action in the environment and get\n",
        "  # next_state, reward, terminated, truncated and info\n",
        "  observation, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "  # If the game is terminated (in our case we land, crashed) or truncated (timeout)\n",
        "  if terminated or truncated:\n",
        "      # Reset the environment\n",
        "      print(\"Environment is reset\")\n",
        "      observation, info = env.reset()\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaqvsEDkS1xP",
        "outputId": "35de91d8-f719-4f00-c81e-8d40739c4584"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action taken: 1\n",
            "Action taken: 3\n",
            "Action taken: 2\n",
            "Action taken: 2\n",
            "Action taken: 2\n",
            "Action taken: 2\n",
            "Action taken: 1\n",
            "Action taken: 1\n",
            "Action taken: 2\n",
            "Environment is reset\n",
            "Action taken: 3\n",
            "Action taken: 3\n",
            "Action taken: 0\n",
            "Action taken: 2\n",
            "Environment is reset\n",
            "Action taken: 1\n",
            "Action taken: 0\n",
            "Action taken: 1\n",
            "Action taken: 3\n",
            "Action taken: 1\n",
            "Environment is reset\n",
            "Action taken: 1\n",
            "Action taken: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize environment\n",
        "vec_env = make_vec_env('FrozenLake-v1', n_envs=16)"
      ],
      "metadata": {
        "id": "SKzbzcHhTEi1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PPO Model"
      ],
      "metadata": {
        "id": "bodepTndUIJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PPO(\n",
        "    policy = 'MlpPolicy',\n",
        "    env = vec_env,\n",
        "    n_steps = 19,\n",
        "    learning_rate=0.00047,\n",
        "    batch_size = 64,\n",
        "    n_epochs = 5,\n",
        "    gamma = 0.996,\n",
        "    gae_lambda = 0.8776,\n",
        "    ent_coef = 0.001757,\n",
        "    verbose=1).learn(50000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH936wspUMIK",
        "outputId": "8a0e8f91-e866-4a20-99a4-cee9d8401224"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 5.24     |\n",
            "|    ep_rew_mean     | 0.0294   |\n",
            "| time/              |          |\n",
            "|    fps             | 10735    |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 0        |\n",
            "|    total_timesteps | 304      |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 304`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=19 and n_envs=16)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 7.71          |\n",
            "|    ep_rew_mean          | 0.0145        |\n",
            "| time/                   |               |\n",
            "|    fps                  | 2988          |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 0             |\n",
            "|    total_timesteps      | 608           |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00072643626 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | -1.3          |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00337       |\n",
            "|    n_updates            | 5             |\n",
            "|    policy_gradient_loss | -0.00403      |\n",
            "|    value_loss           | 0.0279        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.15         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2402         |\n",
            "|    iterations           | 3            |\n",
            "|    time_elapsed         | 0            |\n",
            "|    total_timesteps      | 912          |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003216194 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | -1.31        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00499     |\n",
            "|    n_updates            | 10           |\n",
            "|    policy_gradient_loss | -0.00293     |\n",
            "|    value_loss           | 0.00363      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 7.63         |\n",
            "|    ep_rew_mean          | 0            |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2295         |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 0            |\n",
            "|    total_timesteps      | 1216         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003529918 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -0.849       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0079      |\n",
            "|    n_updates            | 15           |\n",
            "|    policy_gradient_loss | -0.00197     |\n",
            "|    value_loss           | 0.000963     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 7.61         |\n",
            "|    ep_rew_mean          | 0            |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2190         |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 0            |\n",
            "|    total_timesteps      | 1520         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027888506 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.48        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0153      |\n",
            "|    n_updates            | 20           |\n",
            "|    policy_gradient_loss | -0.00874     |\n",
            "|    value_loss           | 0.000197     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.1          |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2138         |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 0            |\n",
            "|    total_timesteps      | 1824         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054520736 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | -0.852       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0123      |\n",
            "|    n_updates            | 25           |\n",
            "|    policy_gradient_loss | -0.00779     |\n",
            "|    value_loss           | 4.5e-05      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.64         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2132         |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 0            |\n",
            "|    total_timesteps      | 2128         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051357886 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.34        |\n",
            "|    explained_variance   | 0.0123       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00342     |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.00611     |\n",
            "|    value_loss           | 0.00273      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 8.54        |\n",
            "|    ep_rew_mean          | 0.01        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2119        |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 2432        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003952898 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | -5.57       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0114     |\n",
            "|    n_updates            | 35          |\n",
            "|    policy_gradient_loss | -0.00468    |\n",
            "|    value_loss           | 0.000348    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 7.77         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2111         |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 1            |\n",
            "|    total_timesteps      | 2736         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016827149 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.0616       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00185     |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.0054      |\n",
            "|    value_loss           | 0.0108       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 8.49         |\n",
            "|    ep_rew_mean          | 0.02         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2117         |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 1            |\n",
            "|    total_timesteps      | 3040         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013938588 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | -2.94        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0117      |\n",
            "|    n_updates            | 45           |\n",
            "|    policy_gradient_loss | -0.0043      |\n",
            "|    value_loss           | 0.00071      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 9.32         |\n",
            "|    ep_rew_mean          | 0.01         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2102         |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 1            |\n",
            "|    total_timesteps      | 3344         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013125956 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.2          |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00453     |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.003       |\n",
            "|    value_loss           | 0.0104       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 10.7        |\n",
            "|    ep_rew_mean          | 0.02        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2089        |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 3648        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006431789 |\n",
            "|    clip_fraction        | 0.00813     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | -1.49       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0321     |\n",
            "|    n_updates            | 55          |\n",
            "|    policy_gradient_loss | -0.00867    |\n",
            "|    value_loss           | 0.00118     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 10.9         |\n",
            "|    ep_rew_mean          | 0.04         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2065         |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 1            |\n",
            "|    total_timesteps      | 3952         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032370542 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.418        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00653     |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00862     |\n",
            "|    value_loss           | 0.00789      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 11.2         |\n",
            "|    ep_rew_mean          | 0.04         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2075         |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 4256         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021109523 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.166        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.000656    |\n",
            "|    n_updates            | 65           |\n",
            "|    policy_gradient_loss | -0.00637     |\n",
            "|    value_loss           | 0.0197       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 11.5         |\n",
            "|    ep_rew_mean          | 0.05         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2067         |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 4560         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015987229 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.27        |\n",
            "|    explained_variance   | 0.0907       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0227      |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00475     |\n",
            "|    value_loss           | 0.0159       |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 11.9       |\n",
            "|    ep_rew_mean          | 0.05       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 2074       |\n",
            "|    iterations           | 16         |\n",
            "|    time_elapsed         | 2          |\n",
            "|    total_timesteps      | 4864       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00256291 |\n",
            "|    clip_fraction        | 0.0025     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.25      |\n",
            "|    explained_variance   | -0.323     |\n",
            "|    learning_rate        | 0.00047    |\n",
            "|    loss                 | -0.00333   |\n",
            "|    n_updates            | 75         |\n",
            "|    policy_gradient_loss | -0.00537   |\n",
            "|    value_loss           | 0.00654    |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 12.1         |\n",
            "|    ep_rew_mean          | 0.04         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2083         |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 5168         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025529796 |\n",
            "|    clip_fraction        | 0.000833     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.22        |\n",
            "|    explained_variance   | 0.106        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00892     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00404     |\n",
            "|    value_loss           | 0.0128       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 12.4         |\n",
            "|    ep_rew_mean          | 0.04         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2084         |\n",
            "|    iterations           | 18           |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 5472         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029409968 |\n",
            "|    clip_fraction        | 0.00458      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.16        |\n",
            "|    explained_variance   | 0.232        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0237      |\n",
            "|    n_updates            | 85           |\n",
            "|    policy_gradient_loss | -0.00611     |\n",
            "|    value_loss           | 0.00811      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 12.7        |\n",
            "|    ep_rew_mean          | 0.04        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2091        |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 2           |\n",
            "|    total_timesteps      | 5776        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005681093 |\n",
            "|    clip_fraction        | 0.00979     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.14       |\n",
            "|    explained_variance   | 0.219       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0262     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 0.0132      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 12.8         |\n",
            "|    ep_rew_mean          | 0.05         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2087         |\n",
            "|    iterations           | 20           |\n",
            "|    time_elapsed         | 2            |\n",
            "|    total_timesteps      | 6080         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043309485 |\n",
            "|    clip_fraction        | 0.00896      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.09        |\n",
            "|    explained_variance   | 0.215        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0115      |\n",
            "|    n_updates            | 95           |\n",
            "|    policy_gradient_loss | -0.00865     |\n",
            "|    value_loss           | 0.00669      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 13.5        |\n",
            "|    ep_rew_mean          | 0.05        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2085        |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 6384        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007833274 |\n",
            "|    clip_fraction        | 0.0202      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.973      |\n",
            "|    explained_variance   | -0.082      |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0292     |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0108     |\n",
            "|    value_loss           | 0.0136      |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 14.9       |\n",
            "|    ep_rew_mean          | 0.06       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 2093       |\n",
            "|    iterations           | 22         |\n",
            "|    time_elapsed         | 3          |\n",
            "|    total_timesteps      | 6688       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01446484 |\n",
            "|    clip_fraction        | 0.168      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.861     |\n",
            "|    explained_variance   | -0.0848    |\n",
            "|    learning_rate        | 0.00047    |\n",
            "|    loss                 | -0.0363    |\n",
            "|    n_updates            | 105        |\n",
            "|    policy_gradient_loss | -0.0215    |\n",
            "|    value_loss           | 0.00348    |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 15.8        |\n",
            "|    ep_rew_mean          | 0.06        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2078        |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 6992        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005721815 |\n",
            "|    clip_fraction        | 0.0183      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.852      |\n",
            "|    explained_variance   | 0.223       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0122     |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00753    |\n",
            "|    value_loss           | 0.018       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 18.6        |\n",
            "|    ep_rew_mean          | 0.05        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2081        |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 3           |\n",
            "|    total_timesteps      | 7296        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006667568 |\n",
            "|    clip_fraction        | 0.0379      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.768      |\n",
            "|    explained_variance   | -0.118      |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0205     |\n",
            "|    n_updates            | 115         |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    value_loss           | 0.00802     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 19.7         |\n",
            "|    ep_rew_mean          | 0.04         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2081         |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 3            |\n",
            "|    total_timesteps      | 7600         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045553967 |\n",
            "|    clip_fraction        | 0.00646      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.78        |\n",
            "|    explained_variance   | -2.39        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0114      |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00589     |\n",
            "|    value_loss           | 0.0089       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 20.1         |\n",
            "|    ep_rew_mean          | 0.06         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2080         |\n",
            "|    iterations           | 26           |\n",
            "|    time_elapsed         | 3            |\n",
            "|    total_timesteps      | 7904         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070973425 |\n",
            "|    clip_fraction        | 0.0721       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.721       |\n",
            "|    explained_variance   | -0.196       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0266      |\n",
            "|    n_updates            | 125          |\n",
            "|    policy_gradient_loss | -0.00962     |\n",
            "|    value_loss           | 0.000989     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 20.9         |\n",
            "|    ep_rew_mean          | 0.06         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2081         |\n",
            "|    iterations           | 27           |\n",
            "|    time_elapsed         | 3            |\n",
            "|    total_timesteps      | 8208         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013996267 |\n",
            "|    clip_fraction        | 0.00333      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.706       |\n",
            "|    explained_variance   | 0.0411       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0206      |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.00424     |\n",
            "|    value_loss           | 0.0127       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.2        |\n",
            "|    ep_rew_mean          | 0.08        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2085        |\n",
            "|    iterations           | 28          |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 8512        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008330181 |\n",
            "|    clip_fraction        | 0.039       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.755      |\n",
            "|    explained_variance   | 0.21        |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.00694     |\n",
            "|    n_updates            | 135         |\n",
            "|    policy_gradient_loss | -0.00803    |\n",
            "|    value_loss           | 0.012       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 22.4         |\n",
            "|    ep_rew_mean          | 0.1          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2089         |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 4            |\n",
            "|    total_timesteps      | 8816         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061129937 |\n",
            "|    clip_fraction        | 0.0396       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.773       |\n",
            "|    explained_variance   | 0.265        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00308     |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00582     |\n",
            "|    value_loss           | 0.0215       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.1        |\n",
            "|    ep_rew_mean          | 0.09        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2094        |\n",
            "|    iterations           | 30          |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 9120        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002432154 |\n",
            "|    clip_fraction        | 0.0108      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.678      |\n",
            "|    explained_variance   | 0.29        |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.00544    |\n",
            "|    n_updates            | 145         |\n",
            "|    policy_gradient_loss | -0.00471    |\n",
            "|    value_loss           | 0.0255      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 23.1         |\n",
            "|    ep_rew_mean          | 0.14         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2097         |\n",
            "|    iterations           | 31           |\n",
            "|    time_elapsed         | 4            |\n",
            "|    total_timesteps      | 9424         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026907916 |\n",
            "|    clip_fraction        | 0.0156       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.654       |\n",
            "|    explained_variance   | -0.161       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0126      |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00785     |\n",
            "|    value_loss           | 0.0268       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 23.1        |\n",
            "|    ep_rew_mean          | 0.16        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2095        |\n",
            "|    iterations           | 32          |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 9728        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006170586 |\n",
            "|    clip_fraction        | 0.045       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.665      |\n",
            "|    explained_variance   | 0.341       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.00459     |\n",
            "|    n_updates            | 155         |\n",
            "|    policy_gradient_loss | -0.00663    |\n",
            "|    value_loss           | 0.0385      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.9        |\n",
            "|    ep_rew_mean          | 0.19        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2097        |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 10032       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012380605 |\n",
            "|    clip_fraction        | 0.131       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.691      |\n",
            "|    explained_variance   | 0.0148      |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0193     |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.0111     |\n",
            "|    value_loss           | 0.0286      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 22.1        |\n",
            "|    ep_rew_mean          | 0.2         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2088        |\n",
            "|    iterations           | 34          |\n",
            "|    time_elapsed         | 4           |\n",
            "|    total_timesteps      | 10336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017852139 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.631      |\n",
            "|    explained_variance   | 0.311       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.023      |\n",
            "|    n_updates            | 165         |\n",
            "|    policy_gradient_loss | -0.00919    |\n",
            "|    value_loss           | 0.0283      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 23.1         |\n",
            "|    ep_rew_mean          | 0.2          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2083         |\n",
            "|    iterations           | 35           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 10640        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017033089 |\n",
            "|    clip_fraction        | 0.00542      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.634       |\n",
            "|    explained_variance   | 0.307        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00309     |\n",
            "|    n_updates            | 170          |\n",
            "|    policy_gradient_loss | -0.00597     |\n",
            "|    value_loss           | 0.0279       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 22.2         |\n",
            "|    ep_rew_mean          | 0.18         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2084         |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 10944        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039626025 |\n",
            "|    clip_fraction        | 0.00792      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.585       |\n",
            "|    explained_variance   | -0.846       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0349      |\n",
            "|    n_updates            | 175          |\n",
            "|    policy_gradient_loss | -0.00816     |\n",
            "|    value_loss           | 0.02         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 23.2         |\n",
            "|    ep_rew_mean          | 0.19         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2082         |\n",
            "|    iterations           | 37           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 11248        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067206398 |\n",
            "|    clip_fraction        | 0.0556       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.464       |\n",
            "|    explained_variance   | 0.0586       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0175      |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | -0.00773     |\n",
            "|    value_loss           | 0.0128       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 23.1         |\n",
            "|    ep_rew_mean          | 0.19         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2085         |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 11552        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035163525 |\n",
            "|    clip_fraction        | 0.0202       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.493       |\n",
            "|    explained_variance   | 0.0555       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00974     |\n",
            "|    n_updates            | 185          |\n",
            "|    policy_gradient_loss | -0.00731     |\n",
            "|    value_loss           | 0.0259       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 22.7         |\n",
            "|    ep_rew_mean          | 0.19         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2086         |\n",
            "|    iterations           | 39           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 11856        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054198434 |\n",
            "|    clip_fraction        | 0.0319       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.471       |\n",
            "|    explained_variance   | 0.158        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0226       |\n",
            "|    n_updates            | 190          |\n",
            "|    policy_gradient_loss | -0.0124      |\n",
            "|    value_loss           | 0.0197       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 23.3         |\n",
            "|    ep_rew_mean          | 0.21         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2085         |\n",
            "|    iterations           | 40           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 12160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021330982 |\n",
            "|    clip_fraction        | 0.00563      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.468       |\n",
            "|    explained_variance   | 0.19         |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0115       |\n",
            "|    n_updates            | 195          |\n",
            "|    policy_gradient_loss | -0.00603     |\n",
            "|    value_loss           | 0.0224       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 24.7         |\n",
            "|    ep_rew_mean          | 0.22         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2081         |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 5            |\n",
            "|    total_timesteps      | 12464        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031314692 |\n",
            "|    clip_fraction        | 0.0146       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.4         |\n",
            "|    explained_variance   | 0.228        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0125       |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00636     |\n",
            "|    value_loss           | 0.0347       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 24.9         |\n",
            "|    ep_rew_mean          | 0.21         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2083         |\n",
            "|    iterations           | 42           |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 12768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033891506 |\n",
            "|    clip_fraction        | 0.0238       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.389       |\n",
            "|    explained_variance   | 0.15         |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0142      |\n",
            "|    n_updates            | 205          |\n",
            "|    policy_gradient_loss | -0.0061      |\n",
            "|    value_loss           | 0.0345       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.3        |\n",
            "|    ep_rew_mean          | 0.23        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2085        |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 13072       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009116139 |\n",
            "|    clip_fraction        | 0.0671      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.356      |\n",
            "|    explained_variance   | 0.0866      |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.0176      |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.0122     |\n",
            "|    value_loss           | 0.0203      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 26.9        |\n",
            "|    ep_rew_mean          | 0.23        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2082        |\n",
            "|    iterations           | 44          |\n",
            "|    time_elapsed         | 6           |\n",
            "|    total_timesteps      | 13376       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002464847 |\n",
            "|    clip_fraction        | 0.0106      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.343      |\n",
            "|    explained_variance   | 0.315       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.00542    |\n",
            "|    n_updates            | 215         |\n",
            "|    policy_gradient_loss | -0.0028     |\n",
            "|    value_loss           | 0.0154      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 24.8         |\n",
            "|    ep_rew_mean          | 0.25         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2087         |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 13680        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036075134 |\n",
            "|    clip_fraction        | 0.0215       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.334       |\n",
            "|    explained_variance   | -0.187       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.021        |\n",
            "|    n_updates            | 220          |\n",
            "|    policy_gradient_loss | -0.00745     |\n",
            "|    value_loss           | 0.0304       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 25.1         |\n",
            "|    ep_rew_mean          | 0.24         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2087         |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 13984        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027535828 |\n",
            "|    clip_fraction        | 0.00917      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.241       |\n",
            "|    explained_variance   | 0.0614       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00978      |\n",
            "|    n_updates            | 225          |\n",
            "|    policy_gradient_loss | -0.00604     |\n",
            "|    value_loss           | 0.0229       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 26.4         |\n",
            "|    ep_rew_mean          | 0.28         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2085         |\n",
            "|    iterations           | 47           |\n",
            "|    time_elapsed         | 6            |\n",
            "|    total_timesteps      | 14288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035225893 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.212       |\n",
            "|    explained_variance   | 0.146        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00304      |\n",
            "|    n_updates            | 230          |\n",
            "|    policy_gradient_loss | -0.0135      |\n",
            "|    value_loss           | 0.0175       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 26           |\n",
            "|    ep_rew_mean          | 0.29         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2083         |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 14592        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017239762 |\n",
            "|    clip_fraction        | 0.00917      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.242       |\n",
            "|    explained_variance   | 0.268        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00213      |\n",
            "|    n_updates            | 235          |\n",
            "|    policy_gradient_loss | -0.00481     |\n",
            "|    value_loss           | 0.0481       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 26.6         |\n",
            "|    ep_rew_mean          | 0.32         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2086         |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 14896        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017254347 |\n",
            "|    clip_fraction        | 0.00937      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.202       |\n",
            "|    explained_variance   | -0.146       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0039       |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.00742     |\n",
            "|    value_loss           | 0.0354       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 25.9        |\n",
            "|    ep_rew_mean          | 0.31        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2086        |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 15200       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002129098 |\n",
            "|    clip_fraction        | 0.0156      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.229      |\n",
            "|    explained_variance   | 0.257       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.0133      |\n",
            "|    n_updates            | 245         |\n",
            "|    policy_gradient_loss | -0.00798    |\n",
            "|    value_loss           | 0.0382      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 26.9         |\n",
            "|    ep_rew_mean          | 0.32         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2087         |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 15504        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028599212 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.18        |\n",
            "|    explained_variance   | -0.333       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00299      |\n",
            "|    n_updates            | 250          |\n",
            "|    policy_gradient_loss | -0.00613     |\n",
            "|    value_loss           | 0.0174       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 27.9         |\n",
            "|    ep_rew_mean          | 0.34         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2090         |\n",
            "|    iterations           | 52           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 15808        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017558709 |\n",
            "|    clip_fraction        | 0.00833      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.161       |\n",
            "|    explained_variance   | 0.0581       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00376      |\n",
            "|    n_updates            | 255          |\n",
            "|    policy_gradient_loss | -0.00589     |\n",
            "|    value_loss           | 0.0175       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 27.5         |\n",
            "|    ep_rew_mean          | 0.4          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2092         |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 16112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014943719 |\n",
            "|    clip_fraction        | 0.00729      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.211       |\n",
            "|    explained_variance   | 0.362        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0143      |\n",
            "|    n_updates            | 260          |\n",
            "|    policy_gradient_loss | -0.0044      |\n",
            "|    value_loss           | 0.0143       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 28.7         |\n",
            "|    ep_rew_mean          | 0.44         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2093         |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 16416        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029906617 |\n",
            "|    clip_fraction        | 0.0196       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.155       |\n",
            "|    explained_variance   | 0.328        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0129       |\n",
            "|    n_updates            | 265          |\n",
            "|    policy_gradient_loss | -0.00598     |\n",
            "|    value_loss           | 0.0281       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 30.9         |\n",
            "|    ep_rew_mean          | 0.5          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2093         |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 7            |\n",
            "|    total_timesteps      | 16720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010535668 |\n",
            "|    clip_fraction        | 0.00708      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.126       |\n",
            "|    explained_variance   | 0.547        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00164      |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.00205     |\n",
            "|    value_loss           | 0.0206       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 31.4          |\n",
            "|    ep_rew_mean          | 0.54          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 2092          |\n",
            "|    iterations           | 56            |\n",
            "|    time_elapsed         | 8             |\n",
            "|    total_timesteps      | 17024         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00036579167 |\n",
            "|    clip_fraction        | 0.00187       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.142        |\n",
            "|    explained_variance   | 0.398         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0135        |\n",
            "|    n_updates            | 275           |\n",
            "|    policy_gradient_loss | -0.00111      |\n",
            "|    value_loss           | 0.0281        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 33            |\n",
            "|    ep_rew_mean          | 0.57          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 2095          |\n",
            "|    iterations           | 57            |\n",
            "|    time_elapsed         | 8             |\n",
            "|    total_timesteps      | 17328         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00048537174 |\n",
            "|    clip_fraction        | 0.00271       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.136        |\n",
            "|    explained_variance   | 0.438         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00314       |\n",
            "|    n_updates            | 280           |\n",
            "|    policy_gradient_loss | -0.00163      |\n",
            "|    value_loss           | 0.0207        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 33.6         |\n",
            "|    ep_rew_mean          | 0.58         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2095         |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 17632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001603984 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.137       |\n",
            "|    explained_variance   | 0.394        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0036       |\n",
            "|    n_updates            | 285          |\n",
            "|    policy_gradient_loss | -0.000222    |\n",
            "|    value_loss           | 0.0188       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 33.8         |\n",
            "|    ep_rew_mean          | 0.58         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2097         |\n",
            "|    iterations           | 59           |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 17936        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010783364 |\n",
            "|    clip_fraction        | 0.00458      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.115       |\n",
            "|    explained_variance   | 0.261        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00784     |\n",
            "|    n_updates            | 290          |\n",
            "|    policy_gradient_loss | -0.00395     |\n",
            "|    value_loss           | 0.0154       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 35.5         |\n",
            "|    ep_rew_mean          | 0.58         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2098         |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 18240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012141186 |\n",
            "|    clip_fraction        | 0.00604      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.176       |\n",
            "|    explained_variance   | 0.155        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00398      |\n",
            "|    n_updates            | 295          |\n",
            "|    policy_gradient_loss | -0.00497     |\n",
            "|    value_loss           | 0.0443       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 36           |\n",
            "|    ep_rew_mean          | 0.55         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2100         |\n",
            "|    iterations           | 61           |\n",
            "|    time_elapsed         | 8            |\n",
            "|    total_timesteps      | 18544        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010349622 |\n",
            "|    clip_fraction        | 0.00396      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.101       |\n",
            "|    explained_variance   | 0.276        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00481      |\n",
            "|    n_updates            | 300          |\n",
            "|    policy_gradient_loss | -0.00426     |\n",
            "|    value_loss           | 0.0243       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 37.2          |\n",
            "|    ep_rew_mean          | 0.58          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 2099          |\n",
            "|    iterations           | 62            |\n",
            "|    time_elapsed         | 8             |\n",
            "|    total_timesteps      | 18848         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00033771404 |\n",
            "|    clip_fraction        | 0.00271       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0845       |\n",
            "|    explained_variance   | 0.347         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00141       |\n",
            "|    n_updates            | 305           |\n",
            "|    policy_gradient_loss | -0.000931     |\n",
            "|    value_loss           | 0.00839       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.1         |\n",
            "|    ep_rew_mean          | 0.64         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2098         |\n",
            "|    iterations           | 63           |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 19152        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010084107 |\n",
            "|    clip_fraction        | 0.00708      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.121       |\n",
            "|    explained_variance   | 0.183        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00534      |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.00467     |\n",
            "|    value_loss           | 0.0261       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 35.9         |\n",
            "|    ep_rew_mean          | 0.65         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2096         |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 9            |\n",
            "|    total_timesteps      | 19456        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007753707 |\n",
            "|    clip_fraction        | 0.00417      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0925      |\n",
            "|    explained_variance   | 0.338        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00758      |\n",
            "|    n_updates            | 315          |\n",
            "|    policy_gradient_loss | -0.00445     |\n",
            "|    value_loss           | 0.0269       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 36.4          |\n",
            "|    ep_rew_mean          | 0.62          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 2093          |\n",
            "|    iterations           | 65            |\n",
            "|    time_elapsed         | 9             |\n",
            "|    total_timesteps      | 19760         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00028947156 |\n",
            "|    clip_fraction        | 0.00271       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0746       |\n",
            "|    explained_variance   | 0.145         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0025        |\n",
            "|    n_updates            | 320           |\n",
            "|    policy_gradient_loss | -0.00134      |\n",
            "|    value_loss           | 0.0131        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 37.4        |\n",
            "|    ep_rew_mean          | 0.64        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2089        |\n",
            "|    iterations           | 66          |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 20064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000636794 |\n",
            "|    clip_fraction        | 0.00458     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0805     |\n",
            "|    explained_variance   | 0.27        |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.00902     |\n",
            "|    n_updates            | 325         |\n",
            "|    policy_gradient_loss | -0.00359    |\n",
            "|    value_loss           | 0.0167      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 37.2        |\n",
            "|    ep_rew_mean          | 0.63        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2074        |\n",
            "|    iterations           | 67          |\n",
            "|    time_elapsed         | 9           |\n",
            "|    total_timesteps      | 20368       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000711791 |\n",
            "|    clip_fraction        | 0.0117      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0938     |\n",
            "|    explained_variance   | 0.217       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.00906     |\n",
            "|    n_updates            | 330         |\n",
            "|    policy_gradient_loss | -0.00217    |\n",
            "|    value_loss           | 0.0152      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 37.5          |\n",
            "|    ep_rew_mean          | 0.61          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 2052          |\n",
            "|    iterations           | 68            |\n",
            "|    time_elapsed         | 10            |\n",
            "|    total_timesteps      | 20672         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032375037 |\n",
            "|    clip_fraction        | 0.00187       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0707       |\n",
            "|    explained_variance   | 0.291         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00877       |\n",
            "|    n_updates            | 335           |\n",
            "|    policy_gradient_loss | -0.00139      |\n",
            "|    value_loss           | 0.022         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.4         |\n",
            "|    ep_rew_mean          | 0.61         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2031         |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 20976        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006339092 |\n",
            "|    clip_fraction        | 0.00438      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0687      |\n",
            "|    explained_variance   | 0.0487       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00354      |\n",
            "|    n_updates            | 340          |\n",
            "|    policy_gradient_loss | -0.00385     |\n",
            "|    value_loss           | 0.014        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 38            |\n",
            "|    ep_rew_mean          | 0.63          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 2013          |\n",
            "|    iterations           | 70            |\n",
            "|    time_elapsed         | 10            |\n",
            "|    total_timesteps      | 21280         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00044117804 |\n",
            "|    clip_fraction        | 0.00333       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0586       |\n",
            "|    explained_variance   | 0.164         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | -0.0124       |\n",
            "|    n_updates            | 345           |\n",
            "|    policy_gradient_loss | -0.00441      |\n",
            "|    value_loss           | 0.0168        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.7         |\n",
            "|    ep_rew_mean          | 0.67         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 2005         |\n",
            "|    iterations           | 71           |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 21584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012170147 |\n",
            "|    clip_fraction        | 0.00708      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.07        |\n",
            "|    explained_variance   | 0.325        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0166       |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    value_loss           | 0.0183       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 38.6         |\n",
            "|    ep_rew_mean          | 0.69         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1989         |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 21888        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014478295 |\n",
            "|    clip_fraction        | 0.0117       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.071       |\n",
            "|    explained_variance   | 0.357        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00289     |\n",
            "|    n_updates            | 355          |\n",
            "|    policy_gradient_loss | -0.00609     |\n",
            "|    value_loss           | 0.0157       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 37.8          |\n",
            "|    ep_rew_mean          | 0.74          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1966          |\n",
            "|    iterations           | 73            |\n",
            "|    time_elapsed         | 11            |\n",
            "|    total_timesteps      | 22192         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013913028 |\n",
            "|    clip_fraction        | 0.00187       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0462       |\n",
            "|    explained_variance   | 0.227         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00265       |\n",
            "|    n_updates            | 360           |\n",
            "|    policy_gradient_loss | -0.00137      |\n",
            "|    value_loss           | 0.008         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.5         |\n",
            "|    ep_rew_mean          | 0.73         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1945         |\n",
            "|    iterations           | 74           |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 22496        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022255438 |\n",
            "|    clip_fraction        | 0.00729      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0549      |\n",
            "|    explained_variance   | 0.275        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00112      |\n",
            "|    n_updates            | 365          |\n",
            "|    policy_gradient_loss | -0.00469     |\n",
            "|    value_loss           | 0.0143       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 39           |\n",
            "|    ep_rew_mean          | 0.74         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1927         |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 22800        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016141575 |\n",
            "|    clip_fraction        | 0.0104       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.07        |\n",
            "|    explained_variance   | 0.0245       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0112       |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.00402     |\n",
            "|    value_loss           | 0.0218       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 38.5          |\n",
            "|    ep_rew_mean          | 0.73          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1912          |\n",
            "|    iterations           | 76            |\n",
            "|    time_elapsed         | 12            |\n",
            "|    total_timesteps      | 23104         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00059643964 |\n",
            "|    clip_fraction        | 0.00313       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0627       |\n",
            "|    explained_variance   | 0.195         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00175       |\n",
            "|    n_updates            | 375           |\n",
            "|    policy_gradient_loss | -0.00296      |\n",
            "|    value_loss           | 0.0104        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 38.5          |\n",
            "|    ep_rew_mean          | 0.72          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1899          |\n",
            "|    iterations           | 77            |\n",
            "|    time_elapsed         | 12            |\n",
            "|    total_timesteps      | 23408         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00018940712 |\n",
            "|    clip_fraction        | 0.00125       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0546       |\n",
            "|    explained_variance   | 0.3           |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00508       |\n",
            "|    n_updates            | 380           |\n",
            "|    policy_gradient_loss | -0.000703     |\n",
            "|    value_loss           | 0.0121        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 38.3         |\n",
            "|    ep_rew_mean          | 0.72         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1899         |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 23712        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029798555 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0664      |\n",
            "|    explained_variance   | 0.179        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0116       |\n",
            "|    n_updates            | 385          |\n",
            "|    policy_gradient_loss | -0.00602     |\n",
            "|    value_loss           | 0.0358       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 36.8         |\n",
            "|    ep_rew_mean          | 0.7          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1900         |\n",
            "|    iterations           | 79           |\n",
            "|    time_elapsed         | 12           |\n",
            "|    total_timesteps      | 24016        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001997675 |\n",
            "|    clip_fraction        | 0.00187      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0548      |\n",
            "|    explained_variance   | -0.331       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00292      |\n",
            "|    n_updates            | 390          |\n",
            "|    policy_gradient_loss | -0.00264     |\n",
            "|    value_loss           | 0.0169       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 37.5          |\n",
            "|    ep_rew_mean          | 0.68          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1901          |\n",
            "|    iterations           | 80            |\n",
            "|    time_elapsed         | 12            |\n",
            "|    total_timesteps      | 24320         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00025674843 |\n",
            "|    clip_fraction        | 0.00125       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0441       |\n",
            "|    explained_variance   | 0.153         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00753       |\n",
            "|    n_updates            | 395           |\n",
            "|    policy_gradient_loss | -0.00177      |\n",
            "|    value_loss           | 0.0197        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 36.8          |\n",
            "|    ep_rew_mean          | 0.68          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1901          |\n",
            "|    iterations           | 81            |\n",
            "|    time_elapsed         | 12            |\n",
            "|    total_timesteps      | 24624         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010165585 |\n",
            "|    clip_fraction        | 0.000625      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.061        |\n",
            "|    explained_variance   | 0.372         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0128        |\n",
            "|    n_updates            | 400           |\n",
            "|    policy_gradient_loss | -0.000357     |\n",
            "|    value_loss           | 0.0238        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 36.1         |\n",
            "|    ep_rew_mean          | 0.66         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1904         |\n",
            "|    iterations           | 82           |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 24928        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008231445 |\n",
            "|    clip_fraction        | 0.00583      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0535      |\n",
            "|    explained_variance   | 0.212        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00473      |\n",
            "|    n_updates            | 405          |\n",
            "|    policy_gradient_loss | -0.00179     |\n",
            "|    value_loss           | 0.0245       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 36.4         |\n",
            "|    ep_rew_mean          | 0.66         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1904         |\n",
            "|    iterations           | 83           |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 25232        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009895884 |\n",
            "|    clip_fraction        | 0.00562      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0514      |\n",
            "|    explained_variance   | 0.457        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00541      |\n",
            "|    n_updates            | 410          |\n",
            "|    policy_gradient_loss | -0.00423     |\n",
            "|    value_loss           | 0.0191       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 36.4          |\n",
            "|    ep_rew_mean          | 0.67          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1906          |\n",
            "|    iterations           | 84            |\n",
            "|    time_elapsed         | 13            |\n",
            "|    total_timesteps      | 25536         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00069842295 |\n",
            "|    clip_fraction        | 0.00208       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0375       |\n",
            "|    explained_variance   | 0.319         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00501       |\n",
            "|    n_updates            | 415           |\n",
            "|    policy_gradient_loss | -0.00109      |\n",
            "|    value_loss           | 0.0168        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 37.6          |\n",
            "|    ep_rew_mean          | 0.66          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1909          |\n",
            "|    iterations           | 85            |\n",
            "|    time_elapsed         | 13            |\n",
            "|    total_timesteps      | 25840         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00030161615 |\n",
            "|    clip_fraction        | 0.00208       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0512       |\n",
            "|    explained_variance   | 0.452         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0051        |\n",
            "|    n_updates            | 420           |\n",
            "|    policy_gradient_loss | -0.00314      |\n",
            "|    value_loss           | 0.0147        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 37.7          |\n",
            "|    ep_rew_mean          | 0.69          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1913          |\n",
            "|    iterations           | 86            |\n",
            "|    time_elapsed         | 13            |\n",
            "|    total_timesteps      | 26144         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.1154807e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0344       |\n",
            "|    explained_variance   | 0.451         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.003         |\n",
            "|    n_updates            | 425           |\n",
            "|    policy_gradient_loss | -0.00138      |\n",
            "|    value_loss           | 0.00698       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.7         |\n",
            "|    ep_rew_mean          | 0.69         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1915         |\n",
            "|    iterations           | 87           |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 26448        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.013775e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.05        |\n",
            "|    explained_variance   | 0.303        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00853      |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.000218    |\n",
            "|    value_loss           | 0.0146       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37           |\n",
            "|    ep_rew_mean          | 0.67         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1916         |\n",
            "|    iterations           | 88           |\n",
            "|    time_elapsed         | 13           |\n",
            "|    total_timesteps      | 26752        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009381446 |\n",
            "|    clip_fraction        | 0.00562      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0603      |\n",
            "|    explained_variance   | 0.31         |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0122       |\n",
            "|    n_updates            | 435          |\n",
            "|    policy_gradient_loss | -0.00411     |\n",
            "|    value_loss           | 0.0189       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 37.4          |\n",
            "|    ep_rew_mean          | 0.66          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1918          |\n",
            "|    iterations           | 89            |\n",
            "|    time_elapsed         | 14            |\n",
            "|    total_timesteps      | 27056         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00027424048 |\n",
            "|    clip_fraction        | 0.00229       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0474       |\n",
            "|    explained_variance   | 0.249         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00762       |\n",
            "|    n_updates            | 440           |\n",
            "|    policy_gradient_loss | -0.00219      |\n",
            "|    value_loss           | 0.022         |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 37.7           |\n",
            "|    ep_rew_mean          | 0.68           |\n",
            "| time/                   |                |\n",
            "|    fps                  | 1919           |\n",
            "|    iterations           | 90             |\n",
            "|    time_elapsed         | 14             |\n",
            "|    total_timesteps      | 27360          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000110052584 |\n",
            "|    clip_fraction        | 0.000625       |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -0.0455        |\n",
            "|    explained_variance   | 0.259          |\n",
            "|    learning_rate        | 0.00047        |\n",
            "|    loss                 | 0.00299        |\n",
            "|    n_updates            | 445            |\n",
            "|    policy_gradient_loss | -0.000453      |\n",
            "|    value_loss           | 0.0182         |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 38           |\n",
            "|    ep_rew_mean          | 0.67         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1921         |\n",
            "|    iterations           | 91           |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 27664        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002450493 |\n",
            "|    clip_fraction        | 0.00187      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0453      |\n",
            "|    explained_variance   | 0.396        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0102       |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    value_loss           | 0.0174       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 38.9         |\n",
            "|    ep_rew_mean          | 0.7          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1923         |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 27968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008928937 |\n",
            "|    clip_fraction        | 0.00146      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.038       |\n",
            "|    explained_variance   | 0.0351       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00365     |\n",
            "|    n_updates            | 455          |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    value_loss           | 0.0149       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 39.1          |\n",
            "|    ep_rew_mean          | 0.71          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1924          |\n",
            "|    iterations           | 93            |\n",
            "|    time_elapsed         | 14            |\n",
            "|    total_timesteps      | 28272         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.6504279e-06 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.034        |\n",
            "|    explained_variance   | 0.185         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00261       |\n",
            "|    n_updates            | 460           |\n",
            "|    policy_gradient_loss | -0.00014      |\n",
            "|    value_loss           | 0.00686       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 40.5         |\n",
            "|    ep_rew_mean          | 0.69         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1925         |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 14           |\n",
            "|    total_timesteps      | 28576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002504527 |\n",
            "|    clip_fraction        | 0.00125      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0336      |\n",
            "|    explained_variance   | 0.268        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00622      |\n",
            "|    n_updates            | 465          |\n",
            "|    policy_gradient_loss | -0.000566    |\n",
            "|    value_loss           | 0.00855      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 40.7        |\n",
            "|    ep_rew_mean          | 0.69        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1926        |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 14          |\n",
            "|    total_timesteps      | 28880       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000451473 |\n",
            "|    clip_fraction        | 0.00292     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0387     |\n",
            "|    explained_variance   | 0.222       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.00303    |\n",
            "|    n_updates            | 470         |\n",
            "|    policy_gradient_loss | -0.00208    |\n",
            "|    value_loss           | 0.0215      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 41            |\n",
            "|    ep_rew_mean          | 0.68          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1927          |\n",
            "|    iterations           | 96            |\n",
            "|    time_elapsed         | 15            |\n",
            "|    total_timesteps      | 29184         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00034133586 |\n",
            "|    clip_fraction        | 0.00458       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0432       |\n",
            "|    explained_variance   | 0.241         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00984       |\n",
            "|    n_updates            | 475           |\n",
            "|    policy_gradient_loss | -0.000739     |\n",
            "|    value_loss           | 0.0187        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 42.2          |\n",
            "|    ep_rew_mean          | 0.66          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1927          |\n",
            "|    iterations           | 97            |\n",
            "|    time_elapsed         | 15            |\n",
            "|    total_timesteps      | 29488         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00047638506 |\n",
            "|    clip_fraction        | 0.00333       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0372       |\n",
            "|    explained_variance   | 0.0179        |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0109        |\n",
            "|    n_updates            | 480           |\n",
            "|    policy_gradient_loss | -0.00205      |\n",
            "|    value_loss           | 0.0232        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 42           |\n",
            "|    ep_rew_mean          | 0.67         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1928         |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 15           |\n",
            "|    total_timesteps      | 29792        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.664338e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0461      |\n",
            "|    explained_variance   | 0.0952       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0031       |\n",
            "|    n_updates            | 485          |\n",
            "|    policy_gradient_loss | 1.64e-06     |\n",
            "|    value_loss           | 0.00769      |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 43.5          |\n",
            "|    ep_rew_mean          | 0.66          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1929          |\n",
            "|    iterations           | 99            |\n",
            "|    time_elapsed         | 15            |\n",
            "|    total_timesteps      | 30096         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.1270369e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0474       |\n",
            "|    explained_variance   | 0.561         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00321       |\n",
            "|    n_updates            | 490           |\n",
            "|    policy_gradient_loss | -1.58e-05     |\n",
            "|    value_loss           | 0.00517       |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 42.8        |\n",
            "|    ep_rew_mean          | 0.64        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1929        |\n",
            "|    iterations           | 100         |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 30400       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000302238 |\n",
            "|    clip_fraction        | 0.00396     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0438     |\n",
            "|    explained_variance   | 0.215       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.00893     |\n",
            "|    n_updates            | 495         |\n",
            "|    policy_gradient_loss | -0.00202    |\n",
            "|    value_loss           | 0.0164      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 42.1          |\n",
            "|    ep_rew_mean          | 0.68          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1930          |\n",
            "|    iterations           | 101           |\n",
            "|    time_elapsed         | 15            |\n",
            "|    total_timesteps      | 30704         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016773293 |\n",
            "|    clip_fraction        | 0.00125       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0481       |\n",
            "|    explained_variance   | -0.0206       |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0103        |\n",
            "|    n_updates            | 500           |\n",
            "|    policy_gradient_loss | -0.00117      |\n",
            "|    value_loss           | 0.0243        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 42.4          |\n",
            "|    ep_rew_mean          | 0.69          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1931          |\n",
            "|    iterations           | 102           |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 31008         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.1231353e-06 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.042        |\n",
            "|    explained_variance   | 0.307         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00203       |\n",
            "|    n_updates            | 505           |\n",
            "|    policy_gradient_loss | -0.000202     |\n",
            "|    value_loss           | 0.00533       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 42.1          |\n",
            "|    ep_rew_mean          | 0.68          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1934          |\n",
            "|    iterations           | 103           |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 31312         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00053495483 |\n",
            "|    clip_fraction        | 0.00333       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0306       |\n",
            "|    explained_variance   | 0.31          |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | -0.00642      |\n",
            "|    n_updates            | 510           |\n",
            "|    policy_gradient_loss | -0.00227      |\n",
            "|    value_loss           | 0.00827       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 42.4          |\n",
            "|    ep_rew_mean          | 0.69          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1934          |\n",
            "|    iterations           | 104           |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 31616         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010499401 |\n",
            "|    clip_fraction        | 0.000833      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0343       |\n",
            "|    explained_variance   | 0.185         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00705       |\n",
            "|    n_updates            | 515           |\n",
            "|    policy_gradient_loss | -0.00035      |\n",
            "|    value_loss           | 0.0209        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 42.6        |\n",
            "|    ep_rew_mean          | 0.67        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1936        |\n",
            "|    iterations           | 105         |\n",
            "|    time_elapsed         | 16          |\n",
            "|    total_timesteps      | 31920       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000705279 |\n",
            "|    clip_fraction        | 0.00375     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0347     |\n",
            "|    explained_variance   | 0.318       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.00662     |\n",
            "|    n_updates            | 520         |\n",
            "|    policy_gradient_loss | -0.00195    |\n",
            "|    value_loss           | 0.0139      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 41.8          |\n",
            "|    ep_rew_mean          | 0.65          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1937          |\n",
            "|    iterations           | 106           |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 32224         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016454495 |\n",
            "|    clip_fraction        | 0.00125       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0381       |\n",
            "|    explained_variance   | 0.375         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0105        |\n",
            "|    n_updates            | 525           |\n",
            "|    policy_gradient_loss | -0.00113      |\n",
            "|    value_loss           | 0.0216        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 41.4          |\n",
            "|    ep_rew_mean          | 0.66          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1939          |\n",
            "|    iterations           | 107           |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 32528         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00018168594 |\n",
            "|    clip_fraction        | 0.00146       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0272       |\n",
            "|    explained_variance   | 0.292         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00782       |\n",
            "|    n_updates            | 530           |\n",
            "|    policy_gradient_loss | -0.000605     |\n",
            "|    value_loss           | 0.0145        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 41.1          |\n",
            "|    ep_rew_mean          | 0.68          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1939          |\n",
            "|    iterations           | 108           |\n",
            "|    time_elapsed         | 16            |\n",
            "|    total_timesteps      | 32832         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00057581754 |\n",
            "|    clip_fraction        | 0.00396       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0331       |\n",
            "|    explained_variance   | -0.449        |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00564       |\n",
            "|    n_updates            | 535           |\n",
            "|    policy_gradient_loss | -0.00257      |\n",
            "|    value_loss           | 0.0158        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 42.4         |\n",
            "|    ep_rew_mean          | 0.69         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1943         |\n",
            "|    iterations           | 109          |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 33136        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.438233e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0331      |\n",
            "|    explained_variance   | -0.293       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.000609     |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00093     |\n",
            "|    value_loss           | 0.00736      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 45.3         |\n",
            "|    ep_rew_mean          | 0.68         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1946         |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 33440        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005878691 |\n",
            "|    clip_fraction        | 0.00292      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0313      |\n",
            "|    explained_variance   | 0.0298       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00425     |\n",
            "|    n_updates            | 545          |\n",
            "|    policy_gradient_loss | -0.00121     |\n",
            "|    value_loss           | 0.0111       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 44.7          |\n",
            "|    ep_rew_mean          | 0.71          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1947          |\n",
            "|    iterations           | 111           |\n",
            "|    time_elapsed         | 17            |\n",
            "|    total_timesteps      | 33744         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.3977538e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0326       |\n",
            "|    explained_variance   | 0.232         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00348       |\n",
            "|    n_updates            | 550           |\n",
            "|    policy_gradient_loss | -0.00112      |\n",
            "|    value_loss           | 0.00713       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 44.1         |\n",
            "|    ep_rew_mean          | 0.69         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1949         |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 34048        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.597759e-05 |\n",
            "|    clip_fraction        | 0.00146      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0379      |\n",
            "|    explained_variance   | 0.4          |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00203      |\n",
            "|    n_updates            | 555          |\n",
            "|    policy_gradient_loss | -0.000366    |\n",
            "|    value_loss           | 0.00635      |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 42.3          |\n",
            "|    ep_rew_mean          | 0.67          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1951          |\n",
            "|    iterations           | 113           |\n",
            "|    time_elapsed         | 17            |\n",
            "|    total_timesteps      | 34352         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.1421101e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0362       |\n",
            "|    explained_variance   | 0.138         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00989       |\n",
            "|    n_updates            | 560           |\n",
            "|    policy_gradient_loss | 1.58e-05      |\n",
            "|    value_loss           | 0.0253        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 42.8         |\n",
            "|    ep_rew_mean          | 0.67         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1953         |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 17           |\n",
            "|    total_timesteps      | 34656        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.263818e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.032       |\n",
            "|    explained_variance   | 0.283        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0126       |\n",
            "|    n_updates            | 565          |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    value_loss           | 0.0154       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 43            |\n",
            "|    ep_rew_mean          | 0.65          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1955          |\n",
            "|    iterations           | 115           |\n",
            "|    time_elapsed         | 17            |\n",
            "|    total_timesteps      | 34960         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011419008 |\n",
            "|    clip_fraction        | 0.00313       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0535       |\n",
            "|    explained_variance   | 0.177         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00528       |\n",
            "|    n_updates            | 570           |\n",
            "|    policy_gradient_loss | 0.000396      |\n",
            "|    value_loss           | 0.0201        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 43.4          |\n",
            "|    ep_rew_mean          | 0.63          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1956          |\n",
            "|    iterations           | 116           |\n",
            "|    time_elapsed         | 18            |\n",
            "|    total_timesteps      | 35264         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00011415258 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0474       |\n",
            "|    explained_variance   | 0.228         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00622       |\n",
            "|    n_updates            | 575           |\n",
            "|    policy_gradient_loss | -0.000513     |\n",
            "|    value_loss           | 0.0164        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 44.3        |\n",
            "|    ep_rew_mean          | 0.63        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1958        |\n",
            "|    iterations           | 117         |\n",
            "|    time_elapsed         | 18          |\n",
            "|    total_timesteps      | 35568       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001043059 |\n",
            "|    clip_fraction        | 0.00375     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0308     |\n",
            "|    explained_variance   | 0.136       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.00764     |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | -0.00451    |\n",
            "|    value_loss           | 0.0141      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 44.4          |\n",
            "|    ep_rew_mean          | 0.64          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1959          |\n",
            "|    iterations           | 118           |\n",
            "|    time_elapsed         | 18            |\n",
            "|    total_timesteps      | 35872         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.7435086e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0395       |\n",
            "|    explained_variance   | 0.255         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00598       |\n",
            "|    n_updates            | 585           |\n",
            "|    policy_gradient_loss | -5.57e-05     |\n",
            "|    value_loss           | 0.0129        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 44           |\n",
            "|    ep_rew_mean          | 0.65         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1959         |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 36176        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010513939 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0536      |\n",
            "|    explained_variance   | 0.28         |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0143      |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.004       |\n",
            "|    value_loss           | 0.0254       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 42.9         |\n",
            "|    ep_rew_mean          | 0.7          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1960         |\n",
            "|    iterations           | 120          |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 36480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013454822 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0458      |\n",
            "|    explained_variance   | 0.226        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0023      |\n",
            "|    n_updates            | 595          |\n",
            "|    policy_gradient_loss | -0.00638     |\n",
            "|    value_loss           | 0.0152       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 41.3         |\n",
            "|    ep_rew_mean          | 0.71         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1962         |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 18           |\n",
            "|    total_timesteps      | 36784        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022125575 |\n",
            "|    clip_fraction        | 0.00875      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0524      |\n",
            "|    explained_variance   | 0.315        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0168      |\n",
            "|    n_updates            | 600          |\n",
            "|    policy_gradient_loss | -0.00415     |\n",
            "|    value_loss           | 0.00872      |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 40.1          |\n",
            "|    ep_rew_mean          | 0.71          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1963          |\n",
            "|    iterations           | 122           |\n",
            "|    time_elapsed         | 18            |\n",
            "|    total_timesteps      | 37088         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00047568366 |\n",
            "|    clip_fraction        | 0.00187       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0386       |\n",
            "|    explained_variance   | 0.333         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00517       |\n",
            "|    n_updates            | 605           |\n",
            "|    policy_gradient_loss | -0.00229      |\n",
            "|    value_loss           | 0.0124        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 38.2        |\n",
            "|    ep_rew_mean          | 0.72        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1965        |\n",
            "|    iterations           | 123         |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 37392       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000470634 |\n",
            "|    clip_fraction        | 0.00208     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0355     |\n",
            "|    explained_variance   | -0.06       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | 0.0127      |\n",
            "|    n_updates            | 610         |\n",
            "|    policy_gradient_loss | -0.00404    |\n",
            "|    value_loss           | 0.0224      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 39          |\n",
            "|    ep_rew_mean          | 0.7         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1965        |\n",
            "|    iterations           | 124         |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 37696       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001434892 |\n",
            "|    clip_fraction        | 0.01        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0485     |\n",
            "|    explained_variance   | -0.337      |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0105     |\n",
            "|    n_updates            | 615         |\n",
            "|    policy_gradient_loss | -0.00279    |\n",
            "|    value_loss           | 0.0124      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 39.4         |\n",
            "|    ep_rew_mean          | 0.7          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1967         |\n",
            "|    iterations           | 125          |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 38000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021470222 |\n",
            "|    clip_fraction        | 0.0121       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0489      |\n",
            "|    explained_variance   | 0.126        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0201       |\n",
            "|    n_updates            | 620          |\n",
            "|    policy_gradient_loss | -0.00385     |\n",
            "|    value_loss           | 0.0128       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 38.3          |\n",
            "|    ep_rew_mean          | 0.72          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1967          |\n",
            "|    iterations           | 126           |\n",
            "|    time_elapsed         | 19            |\n",
            "|    total_timesteps      | 38304         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00017374381 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0547       |\n",
            "|    explained_variance   | 0.23          |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00763       |\n",
            "|    n_updates            | 625           |\n",
            "|    policy_gradient_loss | -8.1e-05      |\n",
            "|    value_loss           | 0.026         |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.7         |\n",
            "|    ep_rew_mean          | 0.73         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1967         |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 19           |\n",
            "|    total_timesteps      | 38608        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004401416 |\n",
            "|    clip_fraction        | 0.000625     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0472      |\n",
            "|    explained_variance   | 0.198        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0142       |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.000277    |\n",
            "|    value_loss           | 0.0232       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 36.7          |\n",
            "|    ep_rew_mean          | 0.76          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1969          |\n",
            "|    iterations           | 128           |\n",
            "|    time_elapsed         | 19            |\n",
            "|    total_timesteps      | 38912         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00077496486 |\n",
            "|    clip_fraction        | 0.00396       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.038        |\n",
            "|    explained_variance   | 0.1           |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00433       |\n",
            "|    n_updates            | 635           |\n",
            "|    policy_gradient_loss | -0.00193      |\n",
            "|    value_loss           | 0.0111        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 36.9        |\n",
            "|    ep_rew_mean          | 0.74        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1969        |\n",
            "|    iterations           | 129         |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 39216       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001408055 |\n",
            "|    clip_fraction        | 0.00208     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0345     |\n",
            "|    explained_variance   | 0.274       |\n",
            "|    learning_rate        | 0.00047     |\n",
            "|    loss                 | -0.0116     |\n",
            "|    n_updates            | 640         |\n",
            "|    policy_gradient_loss | -0.00279    |\n",
            "|    value_loss           | 0.0125      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 36.2         |\n",
            "|    ep_rew_mean          | 0.76         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1970         |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 39520        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010425926 |\n",
            "|    clip_fraction        | 0.00479      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0393      |\n",
            "|    explained_variance   | 0.229        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0203       |\n",
            "|    n_updates            | 645          |\n",
            "|    policy_gradient_loss | -0.00379     |\n",
            "|    value_loss           | 0.0218       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 35.6         |\n",
            "|    ep_rew_mean          | 0.76         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1970         |\n",
            "|    iterations           | 131          |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 39824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005194936 |\n",
            "|    clip_fraction        | 0.00125      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0463      |\n",
            "|    explained_variance   | 0.249        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0219       |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.000401    |\n",
            "|    value_loss           | 0.0235       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 34.8         |\n",
            "|    ep_rew_mean          | 0.74         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1968         |\n",
            "|    iterations           | 132          |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 40128        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014695317 |\n",
            "|    clip_fraction        | 0.00813      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0353      |\n",
            "|    explained_variance   | 0.349        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00964     |\n",
            "|    n_updates            | 655          |\n",
            "|    policy_gradient_loss | -0.00374     |\n",
            "|    value_loss           | 0.0121       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 36.3         |\n",
            "|    ep_rew_mean          | 0.7          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1968         |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 40432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035796468 |\n",
            "|    clip_fraction        | 0.0117       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0316      |\n",
            "|    explained_variance   | 0.261        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0083      |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00567     |\n",
            "|    value_loss           | 0.0204       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 35.6          |\n",
            "|    ep_rew_mean          | 0.72          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1969          |\n",
            "|    iterations           | 134           |\n",
            "|    time_elapsed         | 20            |\n",
            "|    total_timesteps      | 40736         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.5523347e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0354       |\n",
            "|    explained_variance   | 0.422         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00694       |\n",
            "|    n_updates            | 665           |\n",
            "|    policy_gradient_loss | -2.12e-05     |\n",
            "|    value_loss           | 0.0128        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37           |\n",
            "|    ep_rew_mean          | 0.72         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1970         |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 20           |\n",
            "|    total_timesteps      | 41040        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012000047 |\n",
            "|    clip_fraction        | 0.00583      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0286      |\n",
            "|    explained_variance   | 0.337        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00852      |\n",
            "|    n_updates            | 670          |\n",
            "|    policy_gradient_loss | -0.000646    |\n",
            "|    value_loss           | 0.013        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 35.3          |\n",
            "|    ep_rew_mean          | 0.73          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1969          |\n",
            "|    iterations           | 136           |\n",
            "|    time_elapsed         | 20            |\n",
            "|    total_timesteps      | 41344         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00053472724 |\n",
            "|    clip_fraction        | 0.00333       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0389       |\n",
            "|    explained_variance   | 0.0731        |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.003         |\n",
            "|    n_updates            | 675           |\n",
            "|    policy_gradient_loss | -0.0015       |\n",
            "|    value_loss           | 0.0219        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 35            |\n",
            "|    ep_rew_mean          | 0.75          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1969          |\n",
            "|    iterations           | 137           |\n",
            "|    time_elapsed         | 21            |\n",
            "|    total_timesteps      | 41648         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 6.3808017e-07 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0259       |\n",
            "|    explained_variance   | 0.163         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00357       |\n",
            "|    n_updates            | 680           |\n",
            "|    policy_gradient_loss | 3.83e-05      |\n",
            "|    value_loss           | 0.0126        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 36.1         |\n",
            "|    ep_rew_mean          | 0.74         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1971         |\n",
            "|    iterations           | 138          |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 41952        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011446003 |\n",
            "|    clip_fraction        | 0.00458      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0365      |\n",
            "|    explained_variance   | 0.3          |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00386      |\n",
            "|    n_updates            | 685          |\n",
            "|    policy_gradient_loss | -0.00108     |\n",
            "|    value_loss           | 0.014        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 36.8         |\n",
            "|    ep_rew_mean          | 0.72         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1971         |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 42256        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003790833 |\n",
            "|    clip_fraction        | 0.00229      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0223      |\n",
            "|    explained_variance   | 0.0815       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.00837     |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00212     |\n",
            "|    value_loss           | 0.0169       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 38.4          |\n",
            "|    ep_rew_mean          | 0.72          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1970          |\n",
            "|    iterations           | 140           |\n",
            "|    time_elapsed         | 21            |\n",
            "|    total_timesteps      | 42560         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00096020254 |\n",
            "|    clip_fraction        | 0.00333       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0301       |\n",
            "|    explained_variance   | 0.161         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.000661      |\n",
            "|    n_updates            | 695           |\n",
            "|    policy_gradient_loss | -0.00222      |\n",
            "|    value_loss           | 0.0175        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 37.1          |\n",
            "|    ep_rew_mean          | 0.74          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1970          |\n",
            "|    iterations           | 141           |\n",
            "|    time_elapsed         | 21            |\n",
            "|    total_timesteps      | 42864         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00064074283 |\n",
            "|    clip_fraction        | 0.00333       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0322       |\n",
            "|    explained_variance   | 0.156         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0129        |\n",
            "|    n_updates            | 700           |\n",
            "|    policy_gradient_loss | -0.00177      |\n",
            "|    value_loss           | 0.0227        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 37.2         |\n",
            "|    ep_rew_mean          | 0.72         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1971         |\n",
            "|    iterations           | 142          |\n",
            "|    time_elapsed         | 21           |\n",
            "|    total_timesteps      | 43168        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006153131 |\n",
            "|    clip_fraction        | 0.00271      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0203      |\n",
            "|    explained_variance   | 0.322        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | -0.0106      |\n",
            "|    n_updates            | 705          |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    value_loss           | 0.0167       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 38.1          |\n",
            "|    ep_rew_mean          | 0.69          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1971          |\n",
            "|    iterations           | 143           |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 43472         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015639322 |\n",
            "|    clip_fraction        | 0.000625      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0193       |\n",
            "|    explained_variance   | 0.38          |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00945       |\n",
            "|    n_updates            | 710           |\n",
            "|    policy_gradient_loss | -0.00039      |\n",
            "|    value_loss           | 0.0183        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 38.7          |\n",
            "|    ep_rew_mean          | 0.67          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1973          |\n",
            "|    iterations           | 144           |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 43776         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013573616 |\n",
            "|    clip_fraction        | 0.00125       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0231       |\n",
            "|    explained_variance   | 0.374         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00657       |\n",
            "|    n_updates            | 715           |\n",
            "|    policy_gradient_loss | -0.000382     |\n",
            "|    value_loss           | 0.0226        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 39.9          |\n",
            "|    ep_rew_mean          | 0.68          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1970          |\n",
            "|    iterations           | 145           |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 44080         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00030930756 |\n",
            "|    clip_fraction        | 0.00125       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0215       |\n",
            "|    explained_variance   | 0.159         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00695       |\n",
            "|    n_updates            | 720           |\n",
            "|    policy_gradient_loss | -0.000709     |\n",
            "|    value_loss           | 0.0178        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 38.3         |\n",
            "|    ep_rew_mean          | 0.7          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1963         |\n",
            "|    iterations           | 146          |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 44384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.073845e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0281      |\n",
            "|    explained_variance   | 0.306        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.0154       |\n",
            "|    n_updates            | 725          |\n",
            "|    policy_gradient_loss | 1.53e-06     |\n",
            "|    value_loss           | 0.0268       |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 39.5          |\n",
            "|    ep_rew_mean          | 0.69          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1959          |\n",
            "|    iterations           | 147           |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 44688         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.2309398e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0248       |\n",
            "|    explained_variance   | 0.238         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00904       |\n",
            "|    n_updates            | 730           |\n",
            "|    policy_gradient_loss | 0.000229      |\n",
            "|    value_loss           | 0.0195        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 38.6          |\n",
            "|    ep_rew_mean          | 0.69          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1956          |\n",
            "|    iterations           | 148           |\n",
            "|    time_elapsed         | 22            |\n",
            "|    total_timesteps      | 44992         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021652188 |\n",
            "|    clip_fraction        | 0.000625      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.027        |\n",
            "|    explained_variance   | 0.547         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00333       |\n",
            "|    n_updates            | 735           |\n",
            "|    policy_gradient_loss | -0.000609     |\n",
            "|    value_loss           | 0.0128        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 39.4         |\n",
            "|    ep_rew_mean          | 0.69         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1953         |\n",
            "|    iterations           | 149          |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 45296        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007420836 |\n",
            "|    clip_fraction        | 0.00187      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0156      |\n",
            "|    explained_variance   | -0.161       |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00261      |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    value_loss           | 0.017        |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 40.2           |\n",
            "|    ep_rew_mean          | 0.69           |\n",
            "| time/                   |                |\n",
            "|    fps                  | 1950           |\n",
            "|    iterations           | 150            |\n",
            "|    time_elapsed         | 23             |\n",
            "|    total_timesteps      | 45600          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000114919676 |\n",
            "|    clip_fraction        | 0.000625       |\n",
            "|    clip_range           | 0.2            |\n",
            "|    entropy_loss         | -0.0172        |\n",
            "|    explained_variance   | 0.343          |\n",
            "|    learning_rate        | 0.00047        |\n",
            "|    loss                 | 0.0067         |\n",
            "|    n_updates            | 745            |\n",
            "|    policy_gradient_loss | -0.000339      |\n",
            "|    value_loss           | 0.00914        |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 38.5         |\n",
            "|    ep_rew_mean          | 0.69         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1943         |\n",
            "|    iterations           | 151          |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 45904        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 2.630676e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0162      |\n",
            "|    explained_variance   | 0.403        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00305      |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -6.99e-05    |\n",
            "|    value_loss           | 0.00696      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 40.2         |\n",
            "|    ep_rew_mean          | 0.73         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1937         |\n",
            "|    iterations           | 152          |\n",
            "|    time_elapsed         | 23           |\n",
            "|    total_timesteps      | 46208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.227789e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0171      |\n",
            "|    explained_variance   | 0.548        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00193      |\n",
            "|    n_updates            | 755          |\n",
            "|    policy_gradient_loss | -5.98e-05    |\n",
            "|    value_loss           | 0.00718      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 40.2         |\n",
            "|    ep_rew_mean          | 0.73         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1929         |\n",
            "|    iterations           | 153          |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 46512        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 2.656132e-07 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0184      |\n",
            "|    explained_variance   | 0.425        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00168      |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -6.33e-05    |\n",
            "|    value_loss           | 0.0061       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 39.9         |\n",
            "|    ep_rew_mean          | 0.75         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1924         |\n",
            "|    iterations           | 154          |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 46816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003204417 |\n",
            "|    clip_fraction        | 0.00208      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0196      |\n",
            "|    explained_variance   | 0.315        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00122      |\n",
            "|    n_updates            | 765          |\n",
            "|    policy_gradient_loss | -0.000358    |\n",
            "|    value_loss           | 0.0128       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 40.9         |\n",
            "|    ep_rew_mean          | 0.74         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1916         |\n",
            "|    iterations           | 155          |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 47120        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014860871 |\n",
            "|    clip_fraction        | 0.00375      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0192      |\n",
            "|    explained_variance   | 0.405        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00198      |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00155     |\n",
            "|    value_loss           | 0.00502      |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 42.6          |\n",
            "|    ep_rew_mean          | 0.73          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1909          |\n",
            "|    iterations           | 156           |\n",
            "|    time_elapsed         | 24            |\n",
            "|    total_timesteps      | 47424         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.4901161e-09 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0132       |\n",
            "|    explained_variance   | 0.2           |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00699       |\n",
            "|    n_updates            | 775           |\n",
            "|    policy_gradient_loss | 2.35e-06      |\n",
            "|    value_loss           | 0.0109        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 44.1          |\n",
            "|    ep_rew_mean          | 0.73          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1907          |\n",
            "|    iterations           | 157           |\n",
            "|    time_elapsed         | 25            |\n",
            "|    total_timesteps      | 47728         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016639406 |\n",
            "|    clip_fraction        | 0.00125       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0214       |\n",
            "|    explained_variance   | 0.0779        |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.0133        |\n",
            "|    n_updates            | 780           |\n",
            "|    policy_gradient_loss | -0.000221     |\n",
            "|    value_loss           | 0.0248        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 44            |\n",
            "|    ep_rew_mean          | 0.73          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1907          |\n",
            "|    iterations           | 158           |\n",
            "|    time_elapsed         | 25            |\n",
            "|    total_timesteps      | 48032         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 7.0276605e-05 |\n",
            "|    clip_fraction        | 0.000625      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0261       |\n",
            "|    explained_variance   | 0.211         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00797       |\n",
            "|    n_updates            | 785           |\n",
            "|    policy_gradient_loss | -0.000135     |\n",
            "|    value_loss           | 0.0179        |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 44.4         |\n",
            "|    ep_rew_mean          | 0.73         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1907         |\n",
            "|    iterations           | 159          |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 48336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.556511e-08 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0189      |\n",
            "|    explained_variance   | 0.268        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00302      |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -1.17e-05    |\n",
            "|    value_loss           | 0.0115       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 44.5         |\n",
            "|    ep_rew_mean          | 0.71         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1907         |\n",
            "|    iterations           | 160          |\n",
            "|    time_elapsed         | 25           |\n",
            "|    total_timesteps      | 48640        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006740883 |\n",
            "|    clip_fraction        | 0.00187      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0189      |\n",
            "|    explained_variance   | 0.354        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.00353      |\n",
            "|    n_updates            | 795          |\n",
            "|    policy_gradient_loss | -0.00104     |\n",
            "|    value_loss           | 0.00659      |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 46.6          |\n",
            "|    ep_rew_mean          | 0.72          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1906          |\n",
            "|    iterations           | 161           |\n",
            "|    time_elapsed         | 25            |\n",
            "|    total_timesteps      | 48944         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00041454198 |\n",
            "|    clip_fraction        | 0.00125       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0257       |\n",
            "|    explained_variance   | 0.158         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00695       |\n",
            "|    n_updates            | 800           |\n",
            "|    policy_gradient_loss | -0.00095      |\n",
            "|    value_loss           | 0.0172        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 46.3          |\n",
            "|    ep_rew_mean          | 0.72          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1904          |\n",
            "|    iterations           | 162           |\n",
            "|    time_elapsed         | 25            |\n",
            "|    total_timesteps      | 49248         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.8743018e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0155       |\n",
            "|    explained_variance   | 0.271         |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00121       |\n",
            "|    n_updates            | 805           |\n",
            "|    policy_gradient_loss | -3.27e-06     |\n",
            "|    value_loss           | 0.0125        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 45.6          |\n",
            "|    ep_rew_mean          | 0.74          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1903          |\n",
            "|    iterations           | 163           |\n",
            "|    time_elapsed         | 26            |\n",
            "|    total_timesteps      | 49552         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00069701264 |\n",
            "|    clip_fraction        | 0.00187       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0169       |\n",
            "|    explained_variance   | -0.0493       |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00488       |\n",
            "|    n_updates            | 810           |\n",
            "|    policy_gradient_loss | -0.00207      |\n",
            "|    value_loss           | 0.0129        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 47.4          |\n",
            "|    ep_rew_mean          | 0.72          |\n",
            "| time/                   |               |\n",
            "|    fps                  | 1903          |\n",
            "|    iterations           | 164           |\n",
            "|    time_elapsed         | 26            |\n",
            "|    total_timesteps      | 49856         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.5516456e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.017        |\n",
            "|    explained_variance   | -0.149        |\n",
            "|    learning_rate        | 0.00047       |\n",
            "|    loss                 | 0.00341       |\n",
            "|    n_updates            | 815           |\n",
            "|    policy_gradient_loss | -0.000284     |\n",
            "|    value_loss           | 0.00808       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 47.4         |\n",
            "|    ep_rew_mean          | 0.73         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1903         |\n",
            "|    iterations           | 165          |\n",
            "|    time_elapsed         | 26           |\n",
            "|    total_timesteps      | 50160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.284084e-08 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.013       |\n",
            "|    explained_variance   | 0.217        |\n",
            "|    learning_rate        | 0.00047      |\n",
            "|    loss                 | 0.000803     |\n",
            "|    n_updates            | 820          |\n",
            "|    policy_gradient_loss | 9.54e-06     |\n",
            "|    value_loss           | 0.00929      |\n",
            "------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgle0mkpPz2j",
        "outputId": "63e28645-730c-41ad-d744-854bb8517b64"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.29)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.3 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    # Suggest hyperparameters\n",
        "    n_steps = trial.suggest_int('n_steps', 10, 2048, log=True)\n",
        "    n_epochs = trial.suggest_int('n_epochs', 3, 10)\n",
        "    gamma = trial.suggest_loguniform('gamma', 0.8, 0.9999)\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
        "    ent_coef = trial.suggest_loguniform('ent_coef', 0.00001, 0.1)\n",
        "    gae_lambda = trial.suggest_uniform('gae_lambda', 0.8, 1.0)\n",
        "\n",
        "    # Create the PPO model\n",
        "    model = PPO('MlpPolicy', vec_env, verbose=0, gamma=gamma,\n",
        "                n_steps=n_steps, ent_coef=ent_coef,\n",
        "                learning_rate=learning_rate, gae_lambda=gae_lambda,\n",
        "                tensorboard_log=\"./ppo_frozenlake_tensorboard/\")\n",
        "\n",
        "    # Train the model\n",
        "    model.learn(total_timesteps=20000)\n",
        "\n",
        "    # Evaluate the model\n",
        "    mean_reward, _ = evaluate_policy(model, vec_env, n_eval_episodes=10)\n",
        "\n",
        "    # Close the environment\n",
        "    env.close()\n",
        "\n",
        "    return mean_reward\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU8RYq8GQFsk",
        "outputId": "73f3aefe-f9cc-46b6-dde0-dc3e5c07ee4d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\" Value: {}\".format(trial.value))\n",
        "print(\" Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Kc88uuQQY-",
        "outputId": "f03c65b9-443e-4eeb-d682-fb59bd07cbd1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-05-02 08:07:56,458] A new study created in memory with name: no-name-52450b12-3d47-405b-8959-9701df3db926\n",
            "<ipython-input-11-dd22a8f3e999>:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  gamma = trial.suggest_loguniform('gamma', 0.8, 0.9999)\n",
            "<ipython-input-11-dd22a8f3e999>:11: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
            "<ipython-input-11-dd22a8f3e999>:12: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  ent_coef = trial.suggest_loguniform('ent_coef', 0.00001, 0.1)\n",
            "<ipython-input-11-dd22a8f3e999>:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
            "  gae_lambda = trial.suggest_uniform('gae_lambda', 0.8, 1.0)\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 720`, after every 11 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=45 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:08:16,244] Trial 0 finished with value: 0.4 and parameters: {'n_steps': 45, 'n_epochs': 5, 'gamma': 0.8621868432424161, 'learning_rate': 0.0013379853472463628, 'ent_coef': 6.718476772110237e-05, 'gae_lambda': 0.9622328268152331}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 5008`, after every 78 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=313 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:08:33,054] Trial 1 finished with value: 0.3 and parameters: {'n_steps': 313, 'n_epochs': 3, 'gamma': 0.8945368732353852, 'learning_rate': 1.0794745987461867e-05, 'ent_coef': 0.04825099947378319, 'gae_lambda': 0.8520069250563038}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 20176`, after every 315 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=1261 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:08:49,935] Trial 2 finished with value: 0.0 and parameters: {'n_steps': 1261, 'n_epochs': 3, 'gamma': 0.8167695343172742, 'learning_rate': 0.0017184364233836127, 'ent_coef': 0.00015901553961058306, 'gae_lambda': 0.9235622237721419}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 992`, after every 15 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=62 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:09:07,869] Trial 3 finished with value: 0.1 and parameters: {'n_steps': 62, 'n_epochs': 8, 'gamma': 0.8728708025175751, 'learning_rate': 4.5886696071539926e-05, 'ent_coef': 0.010938563402575784, 'gae_lambda': 0.9500696517585141}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 1712`, after every 26 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=107 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:09:24,363] Trial 4 finished with value: 0.2 and parameters: {'n_steps': 107, 'n_epochs': 6, 'gamma': 0.9297500036875787, 'learning_rate': 0.0005039294495227673, 'ent_coef': 0.06832191164872857, 'gae_lambda': 0.9538270851365309}. Best is trial 0 with value: 0.4.\n",
            "[I 2024-05-02 08:09:41,928] Trial 5 finished with value: 0.1 and parameters: {'n_steps': 52, 'n_epochs': 3, 'gamma': 0.8443409079489556, 'learning_rate': 1.1206698002250353e-05, 'ent_coef': 0.00017159756948623137, 'gae_lambda': 0.8215151755140682}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 23088`, after every 360 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=1443 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:10:01,719] Trial 6 finished with value: 0.0 and parameters: {'n_steps': 1443, 'n_epochs': 10, 'gamma': 0.8523273871019977, 'learning_rate': 0.005190201837389413, 'ent_coef': 5.529941642873401e-05, 'gae_lambda': 0.9082247377611081}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 3568`, after every 55 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=223 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:10:21,884] Trial 7 finished with value: 0.2 and parameters: {'n_steps': 223, 'n_epochs': 7, 'gamma': 0.8409670697451574, 'learning_rate': 9.47907180030525e-05, 'ent_coef': 0.03571714602850729, 'gae_lambda': 0.9594921517893323}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 9232`, after every 144 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=577 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:10:44,657] Trial 8 finished with value: 0.1 and parameters: {'n_steps': 577, 'n_epochs': 6, 'gamma': 0.9331319631510218, 'learning_rate': 1.093975533107708e-05, 'ent_coef': 0.03012510013326994, 'gae_lambda': 0.9944636468792744}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 3088`, after every 48 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=193 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:11:01,613] Trial 9 finished with value: 0.1 and parameters: {'n_steps': 193, 'n_epochs': 4, 'gamma': 0.8522218012661221, 'learning_rate': 0.002325713036732358, 'ent_coef': 3.899216430073487e-05, 'gae_lambda': 0.8388553167289162}. Best is trial 0 with value: 0.4.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 304`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=19 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:11:19,408] Trial 10 finished with value: 0.9 and parameters: {'n_steps': 19, 'n_epochs': 5, 'gamma': 0.9960282545103997, 'learning_rate': 0.00046974064922605227, 'ent_coef': 0.001757185895722159, 'gae_lambda': 0.8776126713871909}. Best is trial 10 with value: 0.9.\n",
            "[I 2024-05-02 08:11:36,504] Trial 11 finished with value: 0.4 and parameters: {'n_steps': 16, 'n_epochs': 5, 'gamma': 0.9859432458205895, 'learning_rate': 0.0005938396910609131, 'ent_coef': 0.002214490387829756, 'gae_lambda': 0.8782302721491182}. Best is trial 10 with value: 0.9.\n",
            "[I 2024-05-02 08:11:53,779] Trial 12 finished with value: 0.2 and parameters: {'n_steps': 19, 'n_epochs': 5, 'gamma': 0.9958460204282142, 'learning_rate': 0.0001410492013313675, 'ent_coef': 1.0264461221427102e-05, 'gae_lambda': 0.8790519399066785}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 544`, after every 8 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=34 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:12:12,836] Trial 13 finished with value: 0.5 and parameters: {'n_steps': 34, 'n_epochs': 5, 'gamma': 0.9143270520965852, 'learning_rate': 0.0010353160771184565, 'ent_coef': 0.0012489751599500968, 'gae_lambda': 0.8811722229648625}. Best is trial 10 with value: 0.9.\n",
            "[I 2024-05-02 08:12:29,610] Trial 14 finished with value: 0.5 and parameters: {'n_steps': 28, 'n_epochs': 8, 'gamma': 0.9600429353370274, 'learning_rate': 0.0073031923258696655, 'ent_coef': 0.0014327108486538896, 'gae_lambda': 0.8751774169214053}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 480`, after every 7 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=30 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:12:48,131] Trial 15 finished with value: 0.8 and parameters: {'n_steps': 30, 'n_epochs': 4, 'gamma': 0.9141325055266784, 'learning_rate': 0.00024146203878281725, 'ent_coef': 0.004572832357398887, 'gae_lambda': 0.8582533557459262}. Best is trial 10 with value: 0.9.\n",
            "[I 2024-05-02 08:13:06,526] Trial 16 finished with value: 0.4 and parameters: {'n_steps': 104, 'n_epochs': 4, 'gamma': 0.9645875816578353, 'learning_rate': 0.0002316069642105473, 'ent_coef': 0.006788926755587372, 'gae_lambda': 0.8078985974439286}. Best is trial 10 with value: 0.9.\n",
            "[I 2024-05-02 08:13:24,969] Trial 17 finished with value: 0.1 and parameters: {'n_steps': 80, 'n_epochs': 4, 'gamma': 0.8925730894496986, 'learning_rate': 5.843218224684978e-05, 'ent_coef': 0.005619471680906238, 'gae_lambda': 0.854031188970815}. Best is trial 10 with value: 0.9.\n",
            "[I 2024-05-02 08:13:49,529] Trial 18 finished with value: 0.1 and parameters: {'n_steps': 24, 'n_epochs': 7, 'gamma': 0.9572812153187512, 'learning_rate': 0.0002864387746016685, 'ent_coef': 0.0005006349343582221, 'gae_lambda': 0.9126024193567818}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 560`, after every 8 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=35 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:14:07,915] Trial 19 finished with value: 0.1 and parameters: {'n_steps': 35, 'n_epochs': 10, 'gamma': 0.8061281401843219, 'learning_rate': 2.7838877535881268e-05, 'ent_coef': 0.0004406557982198289, 'gae_lambda': 0.8338267361587511}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 7648`, after every 119 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=478 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:14:27,327] Trial 20 finished with value: 0.0 and parameters: {'n_steps': 478, 'n_epochs': 4, 'gamma': 0.9354997855655401, 'learning_rate': 0.0005510624229310748, 'ent_coef': 0.0036846512843830403, 'gae_lambda': 0.8581335209559536}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 496`, after every 7 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=31 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:14:47,944] Trial 21 finished with value: 0.0 and parameters: {'n_steps': 31, 'n_epochs': 5, 'gamma': 0.907322109953178, 'learning_rate': 0.0011224741051217987, 'ent_coef': 0.0008490436880608821, 'gae_lambda': 0.8901144362037156}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 272`, after every 4 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=17 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:15:10,453] Trial 22 finished with value: 0.3 and parameters: {'n_steps': 17, 'n_epochs': 6, 'gamma': 0.9232451918328567, 'learning_rate': 0.0030188168426122245, 'ent_coef': 0.013437057011666274, 'gae_lambda': 0.9296836675347752}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 624`, after every 9 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=39 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:15:30,118] Trial 23 finished with value: 0.5 and parameters: {'n_steps': 39, 'n_epochs': 5, 'gamma': 0.8820899837641819, 'learning_rate': 0.00072952309023799, 'ent_coef': 0.0024518932269009747, 'gae_lambda': 0.8930763133180663}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 2000`, after every 31 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=125 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:15:47,013] Trial 24 finished with value: 0.4 and parameters: {'n_steps': 125, 'n_epochs': 4, 'gamma': 0.9757261376560314, 'learning_rate': 0.00019458146545241393, 'ent_coef': 0.0009230071495013061, 'gae_lambda': 0.8665811872833531}. Best is trial 10 with value: 0.9.\n",
            "[I 2024-05-02 08:16:05,433] Trial 25 finished with value: 0.0 and parameters: {'n_steps': 64, 'n_epochs': 6, 'gamma': 0.9122773431277361, 'learning_rate': 0.00034770739955757626, 'ent_coef': 0.014051969405843552, 'gae_lambda': 0.8402267156604807}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 416`, after every 6 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=26 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:16:24,298] Trial 26 finished with value: 0.3 and parameters: {'n_steps': 26, 'n_epochs': 3, 'gamma': 0.9439854233306892, 'learning_rate': 0.0010242080977839836, 'ent_coef': 0.000313874818502215, 'gae_lambda': 0.8965156120235096}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 368`, after every 5 untruncated mini-batches, there will be a truncated mini-batch of size 48\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=23 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:16:43,301] Trial 27 finished with value: 0.4 and parameters: {'n_steps': 23, 'n_epochs': 7, 'gamma': 0.9145449492822256, 'learning_rate': 0.00011463632676163471, 'ent_coef': 0.001502305484761559, 'gae_lambda': 0.8080512259271218}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 656`, after every 10 untruncated mini-batches, there will be a truncated mini-batch of size 16\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=41 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:17:02,132] Trial 28 finished with value: 0.4 and parameters: {'n_steps': 41, 'n_epochs': 5, 'gamma': 0.9480185536864275, 'learning_rate': 0.0003716312901928679, 'ent_coef': 0.0038680160985276146, 'gae_lambda': 0.8618668026497097}. Best is trial 10 with value: 0.9.\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/ppo/ppo.py:148: UserWarning: You have specified a mini-batch size of 64, but because the `RolloutBuffer` is of size `n_steps * n_envs = 736`, after every 11 untruncated mini-batches, there will be a truncated mini-batch of size 32\n",
            "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
            "Info: (n_steps=46 and n_envs=16)\n",
            "  warnings.warn(\n",
            "[I 2024-05-02 08:17:21,845] Trial 29 finished with value: 0.4 and parameters: {'n_steps': 46, 'n_epochs': 5, 'gamma': 0.870886693668597, 'learning_rate': 0.003153745744057505, 'ent_coef': 0.0007182549183544349, 'gae_lambda': 0.9306639673665249}. Best is trial 10 with value: 0.9.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            " Value: 0.9\n",
            " Params: \n",
            "    n_steps: 19\n",
            "    n_epochs: 5\n",
            "    gamma: 0.9960282545103997\n",
            "    learning_rate: 0.00046974064922605227\n",
            "    ent_coef: 0.001757185895722159\n",
            "    gae_lambda: 0.8776126713871909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate model\n",
        "eval_env = Monitor(gym.make(\"FrozenLake-v1\"))\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14ZWiTcSUQmc",
        "outputId": "7e186749-fce5-431f-fb83-6a2cd41a8a54"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward=0.60 +/- 0.48989794855663565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the trained data"
      ],
      "metadata": {
        "id": "w9Fvr9IFTqyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the trained agent\n",
        "# using the vecenv\n",
        "obs = vec_env.reset()\n",
        "n_steps = 100\n",
        "for step in range(n_steps):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    print(f\"Step {step + 1}\")\n",
        "    print(\"Action: \", action)\n",
        "    obs, reward, done, info = vec_env.step(action)\n",
        "    print(\"obs=\", obs, \"reward=\", reward, \"done=\", done)\n",
        "    vec_env.render()\n",
        "    if done.all():\n",
        "        # Note that the VecEnv resets automatically\n",
        "        # when a done signal is encountered\n",
        "        print(\"Goal reached!\", \"reward=\", reward)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6ThHrVfT159",
        "outputId": "30323ba9-cd59-4193-91ad-334774e06b94"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1\n",
            "Action:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "obs= [4 4 4 0 4 0 0 4 0 0 4 4 4 0 4 0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 2\n",
            "Action:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "obs= [0 4 4 0 4 4 0 8 0 4 4 8 0 0 4 0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 3\n",
            "Action:  [0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 0]\n",
            "obs= [4 4 0 0 4 0 4 4 0 4 0 8 0 0 0 0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 4\n",
            "Action:  [0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "obs= [8 4 0 0 8 0 0 4 0 4 4 4 0 0 0 4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 5\n",
            "Action:  [3 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            "obs= [9 8 0 0 9 4 0 4 0 8 0 8 0 0 0 0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 6\n",
            "Action:  [1 3 0 0 1 0 0 0 0 3 0 3 0 0 0 0]\n",
            "obs= [ 8  9  0  0 13  0  0  0  0  4  0  4  0  0  4  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 7\n",
            "Action:  [3 1 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
            "obs= [9 8 4 4 9 0 4 0 0 8 0 4 0 4 0 4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 8\n",
            "Action:  [1 3 0 0 1 0 0 0 0 3 0 0 0 0 0 0]\n",
            "obs= [13  8  8  8  8  4  0  0  4  4  4  4  0  4  0  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 9\n",
            "Action:  [2 3 3 3 3 0 0 0 0 0 0 0 0 0 0 0]\n",
            "obs= [9 4 9 4 4 0 0 0 8 8 4 4 0 0 0 0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 10\n",
            "Action:  [1 0 1 0 0 0 0 0 3 3 0 0 0 0 0 0]\n",
            "obs= [10  4  8  8  4  0  4  0  9  4  4  8  0  4  4  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 11\n",
            "Action:  [0 0 3 3 0 0 0 0 1 0 0 3 0 0 0 0]\n",
            "obs= [14  4  9  8  0  0  4  0  8  0  8  8  0  8  8  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 12\n",
            "Action:  [1 0 1 3 0 0 0 0 3 0 3 3 0 3 3 0]\n",
            "obs= [14  0  8  8  4  4  8  0  8  4  9  9  4  4  4  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 13\n",
            "Action:  [1 0 3 3 0 0 3 0 3 0 1 1 0 0 0 3]\n",
            "obs= [13  4  8  9  0  4  4  0  8  0 13  8  4  4  4  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 14\n",
            "Action:  [2 0 3 1 0 0 0 0 3 0 2 3 0 0 0 3]\n",
            "obs= [13  8  9  8  0  0  0  0  4  0 13  9  8  8  0  9] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 15\n",
            "Action:  [2 3 1 3 0 0 0 0 0 0 2 1 3 3 0 1]\n",
            "obs= [ 9  8  8  8  4  0  0  0  4  0  9 10  4  9  0 13] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 16\n",
            "Action:  [1 3 3 3 0 0 0 0 0 0 1 0 0 1 0 2]\n",
            "obs= [ 8  8  8  8  0  4  0  4  8  0  8  9  8 13  0  9] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 17\n",
            "Action:  [3 3 3 3 0 0 0 0 3 0 3 1 3 2 0 1]\n",
            "obs= [ 8  4  9  4  4  0  0  4  9  0  9 10  4 13  0 13] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 18\n",
            "Action:  [3 0 1 0 0 0 0 0 1 0 1 0 0 2 0 2]\n",
            "obs= [ 4  0 10  0  4  0  0  8 10  0 13  9  0 14  4 13] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 19\n",
            "Action:  [0 0 0 0 0 0 0 3 0 0 2 1 0 1 0 2]\n",
            "obs= [ 8  4  6  0  0  0  0  9  9  0  9  8  4 14  0 14] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 20\n",
            "Action:  [3 0 0 0 0 0 0 1 1 0 1 3 0 1 0 1]\n",
            "obs= [ 4  8 10  0  0  4  0  8 13  0  8  9  0 14  4 13] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 21\n",
            "Action:  [0 3 0 0 0 0 0 3 2 0 3 1 0 1 0 2]\n",
            "obs= [ 4  8 14  0  0  0  4  9 13  0  4 10  0  0  0 14] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False  True False False]\n",
            "Step 22\n",
            "Action:  [0 3 1 0 0 0 0 1 2 0 0 0 0 0 0 1]\n",
            "obs= [ 0  8  0  0  4  0  0 10  9  0  0  6  0  0  0 14] reward= [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False  True False False False False False False False False False\n",
            " False False False False]\n",
            "Step 23\n",
            "Action:  [0 3 0 0 0 0 0 0 1 0 0 0 0 0 0 1]\n",
            "obs= [ 0  9  0  4  4  0  0 14  8  0  0 10  4  0  4 14] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 24\n",
            "Action:  [0 1 0 0 0 0 0 1 3 0 0 0 0 0 0 1]\n",
            "obs= [ 0 13  4  4  0  4  0  0  9  0  0  9  8  0  4  0] reward= [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.] done= [False False False False False False False  True False False False False\n",
            " False False False  True]\n",
            "Step 25\n",
            "Action:  [0 2 0 0 0 0 0 0 1 0 0 1 3 0 0 0]\n",
            "obs= [ 0 14  8  8  0  4  0  4  8  0  4 13  8  0  8  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 26\n",
            "Action:  [0 1 3 3 0 0 0 0 3 0 0 2 3 0 3 0]\n",
            "obs= [ 4 14  9  8  0  8  0  4  9  0  4 13  8  4  4  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 27\n",
            "Action:  [0 1 1 3 0 3 0 0 1 0 0 2 3 0 0 0]\n",
            "obs= [ 8 14 10  9  0  8  0  0 10  0  0 14  4  4  4  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 28\n",
            "Action:  [3 1 0 1 0 3 0 0 0 0 0 1 0 0 0 0]\n",
            "obs= [ 4 14 14  8  4  4  4  4 14  0  0 13  4  8  8  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 29\n",
            "Action:  [0 1 1 3 0 0 0 0 1 0 0 2 0 3 3 0]\n",
            "obs= [ 8  0 13  8  0  4  4  8  0  0  4 14  4  4  8  0] reward= [0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] done= [False  True False False False False False False  True False False False\n",
            " False False False False]\n",
            "Step 30\n",
            "Action:  [3 0 2 3 0 0 0 3 0 0 0 1 0 0 3 0]\n",
            "obs= [ 4  0  9  8  4  0  8  4  0  0  4 14  8  4  9  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 31\n",
            "Action:  [0 0 1 3 0 0 3 0 0 0 0 1 3 0 1 0]\n",
            "obs= [ 0  0  8  9  0  4  9  4  0  4  0 13  8  8 13  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 32\n",
            "Action:  [0 0 3 1 0 0 1 0 0 0 0 2 3 3 2 0]\n",
            "obs= [ 0  4  9  8  4  4 10  8  4  4  0  9  9  4 13  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 33\n",
            "Action:  [0 0 1 3 0 0 0 3 0 0 0 1 1 0 2 0]\n",
            "obs= [ 0  4 13  4  8  8 14  4  8  4  0  8 13  8 13  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 34\n",
            "Action:  [0 0 2 0 3 3 1 0 3 0 0 3 2 3 2 0]\n",
            "obs= [ 0  4 13  8  4  9  0  4  8  0  0  8 13  8 14  4] reward= [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False  True False False False False False\n",
            " False False False False]\n",
            "Step 35\n",
            "Action:  [0 0 2 3 0 1 0 0 3 0 0 3 2 3 1 0]\n",
            "obs= [ 4  8 14  9  0  8  0  4  9  0  4  9  9  4  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] done= [False False False False False False False False False False False False\n",
            " False False  True False]\n",
            "Step 36\n",
            "Action:  [0 3 1 1 0 3 0 0 1 0 0 1 1 0 0 0]\n",
            "obs= [ 4  8 13  8  0  9  0  4 10  0  4 10 13  0  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 37\n",
            "Action:  [0 3 2 3 0 1 0 0 0 0 0 0 2 0 0 0]\n",
            "obs= [ 8  8  9  8  4 10  0  4  9  0  0 14 14  0  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 38\n",
            "Action:  [3 3 1 3 0 0 0 0 1 0 0 1 1 0 0 0]\n",
            "obs= [ 9  8 13  8  8  6  0  8 10  0  0  0 13  0  4  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] done= [False False False False False False False False False False False  True\n",
            " False False False False]\n",
            "Step 39\n",
            "Action:  [1 3 2 3 3 0 0 3 0 0 0 0 2 0 0 0]\n",
            "obs= [8 9 9 4 9 2 0 4 9 0 0 4 9 0 4 4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 40\n",
            "Action:  [3 1 1 0 1 0 0 0 1 0 0 0 1 0 0 0]\n",
            "obs= [ 9  8 10  8 13  1  4  4 10  4  0  4  8  0  0  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 41\n",
            "Action:  [1 3 0 3 2 3 0 0 0 0 0 0 3 0 0 0]\n",
            "obs= [10  4  6  9 13  2  4  0 14  8  0  8  9  4  0  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 42\n",
            "Action:  [0 0 0 1 2 0 0 0 1 3 0 3 1 0 0 3]\n",
            "obs= [ 6  4  2 10 13  6  0  0 14  9  0  8 13  8  4  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 43\n",
            "Action:  [0 0 0 0 2 0 0 0 1 1 0 3 2 3 0 0]\n",
            "obs= [10  8  6 14  9  2  4  0 14 13  0  4 13  4  0  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 44\n",
            "Action:  [0 3 0 1 1 0 0 0 1 2 0 0 2 0 0 3]\n",
            "obs= [ 9  8  0 14 13  6  8  4 13 13  0  4  9  4  0  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False  True False False False False False False False False False\n",
            " False False False False]\n",
            "Step 45\n",
            "Action:  [1 3 0 1 2 0 3 0 2 2 0 0 1 0 0 3]\n",
            "obs= [13  8  0 14 14  0  9  4 14 14  4  0  8  0  0  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False  True False False False False False False\n",
            " False False False False]\n",
            "Step 46\n",
            "Action:  [2 3 0 1 1 0 1 0 1 1 0 0 3 0 0 0]\n",
            "obs= [13  9  0 14  0  0 10  4 14 14  0  0  8  0  0  4] reward= [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False  True False False False False False False False\n",
            " False False False False]\n",
            "Step 47\n",
            "Action:  [2 1 0 1 0 0 0 0 1 1 0 0 3 0 0 0]\n",
            "obs= [ 9  8  0 14  4  0  6  0 13 13  0  0  4  0  4  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 48\n",
            "Action:  [1 3 0 1 0 0 0 0 2 2 0 0 0 0 0 0]\n",
            "obs= [10  4  4 14  0  0 10  0  9  9  0  0  0  0  8  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 49\n",
            "Action:  [0 0 0 1 0 0 0 0 1 1 0 0 0 0 3 0]\n",
            "obs= [14  0  4  0  0  4  9  0 13  8  0  0  0  4  4  0] reward= [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False  True False False False False False False False False\n",
            " False False False False]\n",
            "Step 50\n",
            "Action:  [1 0 0 0 0 0 1 0 2 3 0 0 0 0 0 0]\n",
            "obs= [ 0  4  8  0  0  4 13  0 14  9  0  0  0  4  8  0] reward= [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [ True False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 51\n",
            "Action:  [0 0 3 0 0 0 2 0 1 1 0 0 0 0 3 0]\n",
            "obs= [ 0  8  9  4  0  0 13  0 13 13  4  4  0  4  9  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 52\n",
            "Action:  [0 3 1 0 0 0 2 0 2 2 0 0 0 0 1 0]\n",
            "obs= [ 0  9  8  4  4  0 13  0 14 14  0  4  0  4  8  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 53\n",
            "Action:  [0 1 3 0 0 0 2 0 1 1 0 0 0 0 3 0]\n",
            "obs= [ 4  8  8  8  4  0 14  0 13  0  0  0  0  0  8  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False  True False False\n",
            " False False False False]\n",
            "Step 54\n",
            "Action:  [0 3 3 3 0 0 1 0 2 0 0 0 0 0 3 0]\n",
            "obs= [ 4  9  9  4  4  4 14  0 14  4  4  0  4  0  4  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 55\n",
            "Action:  [0 1 1 0 0 0 1 0 1 0 0 0 0 0 0 3]\n",
            "obs= [ 0 10 13  8  0  4 13  0 14  4  4  0  8  4  8  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 56\n",
            "Action:  [0 0 2 3 0 0 2 0 1 0 0 0 3 0 3 0]\n",
            "obs= [ 0 14 14  9  4  4  9  0 14  4  0  0  8  0  4  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 57\n",
            "Action:  [0 1 1 1 0 0 1 0 1 0 0 0 3 0 0 0]\n",
            "obs= [ 0  0 14 10  4  0 10  0 13  8  0  0  9  0  0  0] reward= [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False  True False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 58\n",
            "Action:  [0 0 1 0 0 0 0 0 2 3 0 0 1 0 0 0]\n",
            "obs= [ 0  0  0  9  4  0 14  4 14  4  4  0 13  4  4  4] reward= [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False  True False False False False False False False False False\n",
            " False False False False]\n",
            "Step 59\n",
            "Action:  [0 0 0 1 0 0 1 0 1 0 0 0 2 0 0 0]\n",
            "obs= [ 0  0  0 13  4  0 13  0  0  4  4  0 14  0  8  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False  True False False False\n",
            " False False False False]\n",
            "Step 60\n",
            "Action:  [0 0 0 2 0 0 2 0 0 0 0 0 1 0 3 3]\n",
            "obs= [ 0  0  4  9  4  4 13  0  4  0  0  0  0  4  4  9] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            "  True False False False]\n",
            "Step 61\n",
            "Action:  [0 0 0 1 0 0 2 0 0 0 0 0 0 0 0 1]\n",
            "obs= [ 0  0  0  8  0  8  9  0  8  4  4  0  4  4  8 13] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 62\n",
            "Action:  [0 0 0 3 0 3 1 0 3 0 0 0 0 0 3 2]\n",
            "obs= [ 0  0  0  8  0  8  8  0  9  0  4  4  0  8  4 14] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 63\n",
            "Action:  [0 0 0 3 0 3 3 0 1 0 0 0 0 3 0 1]\n",
            "obs= [ 4  4  0  8  0  4  9  0 10  4  8  8  4  8  4 13] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 64\n",
            "Action:  [0 0 0 3 0 0 1 0 0 0 3 3 0 3 0 2]\n",
            "obs= [ 4  8  0  9  4  0 13  0 14  4  8  8  4  4  4  9] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 65\n",
            "Action:  [0 3 0 1 0 0 2 0 1 0 3 3 0 0 0 1]\n",
            "obs= [0 4 0 8 0 0 9 0 0 8 8 4 8 0 8 8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False  True False False False\n",
            " False False False False]\n",
            "Step 66\n",
            "Action:  [0 0 0 3 0 0 1 0 0 3 3 0 3 0 3 3]\n",
            "obs= [0 4 0 4 0 4 8 4 4 9 4 0 4 0 4 8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 67\n",
            "Action:  [0 0 0 0 0 0 3 0 0 1 0 0 0 0 0 3]\n",
            "obs= [0 0 0 4 4 8 4 4 4 8 4 4 4 0 0 8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 68\n",
            "Action:  [0 0 0 0 0 3 0 0 0 3 0 0 0 0 0 3]\n",
            "obs= [4 0 0 4 8 4 8 0 4 4 4 4 4 4 0 8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 69\n",
            "Action:  [0 0 0 0 3 0 3 0 0 0 0 0 0 0 0 3]\n",
            "obs= [4 0 4 0 4 4 9 0 0 4 0 8 0 4 0 8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 70\n",
            "Action:  [0 0 0 0 0 0 1 0 0 0 0 3 0 0 0 3]\n",
            "obs= [8 0 4 0 8 8 8 0 0 0 4 4 0 8 0 9] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 71\n",
            "Action:  [3 0 0 0 3 3 3 0 0 0 0 0 0 3 0 1]\n",
            "obs= [9 0 8 0 8 4 9 4 0 0 8 8 4 9 0 8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 72\n",
            "Action:  [1 0 3 0 3 0 1 0 0 0 3 3 0 1 0 3]\n",
            "obs= [13  4  8  0  8  0 10  0  0  4  8  8  0 10  0  9] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 73\n",
            "Action:  [2 0 3 0 3 0 0 0 0 0 3 3 0 0 0 1]\n",
            "obs= [14  0  4  0  8  0 14  0  4  8  4  8  0 14  4  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 74\n",
            "Action:  [1 0 0 0 3 0 1 0 0 3 0 3 0 1 0 3]\n",
            "obs= [13  0  4  0  9  0  0  0  4  4  0  8  4  0  8  8] reward= [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0.] done= [False False False False False False  True False False False False False\n",
            " False  True False False]\n",
            "Step 75\n",
            "Action:  [2 0 0 0 1 0 0 0 0 0 0 3 0 0 3 3]\n",
            "obs= [13  0  8  0 10  0  4  0  8  8  4  9  0  4  8  9] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 76\n",
            "Action:  [2 0 3 0 0 0 0 0 3 3 0 1 0 0 3 1]\n",
            "obs= [14  0  9  0  6  0  4  4  4  9  0  8  4  0  8 13] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 77\n",
            "Action:  [1 0 1 0 0 0 0 0 0 1 0 3 0 0 3 2]\n",
            "obs= [13  4  8  0  2  4  0  8  0  8  0  4  8  4  4 14] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 78\n",
            "Action:  [2 0 3 0 0 0 0 3 0 3 0 0 3 0 0 1]\n",
            "obs= [14  4  4  0  1  8  0  9  0  4  4  4  9  4  0 13] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 79\n",
            "Action:  [1 0 0 0 3 3 0 1 0 0 0 0 1 0 0 2]\n",
            "obs= [14  8  4  0  2  9  0 13  0  4  8  0  8  0  0 14] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 80\n",
            "Action:  [1 3 0 0 0 1 0 2 0 0 3 0 3 0 0 1]\n",
            "obs= [ 0  9  4  0  1 10  4 13  4  8  8  0  8  0  0 14] reward= [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [ True False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 81\n",
            "Action:  [0 1 0 0 3 0 0 2 0 3 3 0 3 0 0 1]\n",
            "obs= [ 0  8  8  4  1  6  8 13  4  4  9  4  8  4  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] done= [False False False False False False False False False False False False\n",
            " False False False  True]\n",
            "Step 82\n",
            "Action:  [0 3 3 0 3 0 3 2 0 0 1 0 3 0 0 0]\n",
            "obs= [ 0  4  4  4  2 10  9 14  4  8  8  4  4  4  0  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 83\n",
            "Action:  [0 0 0 0 0 0 1 1 0 3 3 0 0 0 0 0]\n",
            "obs= [ 0  8  4  8  6 14 13 13  4  9  8  0  8  4  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 84\n",
            "Action:  [0 3 0 3 0 1 2 2 0 1 3 0 3 0 0 0]\n",
            "obs= [ 4  9  4  8  0 14  9 13  4 10  4  4  8  8  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False  True False False False False False False False\n",
            " False False False False]\n",
            "Step 85\n",
            "Action:  [0 1 0 3 0 1 1 2 0 0 0 0 3 3 0 0]\n",
            "obs= [ 8 13  0  8  0 14  8 13  0  9  4  4  8  8  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 86\n",
            "Action:  [3 2 0 3 0 1 3 2 0 1 0 0 3 3 0 0]\n",
            "obs= [ 9 13  0  4  0 13  4 14  0 10  8  0  8  4  4  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 87\n",
            "Action:  [1 2 0 0 0 2 0 1 0 0 3 0 3 0 0 0]\n",
            "obs= [13 14  0  4  0  9  4  0  0  9  4  0  8  8  0  4] reward= [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False  True False False False False\n",
            " False False False False]\n",
            "Step 88\n",
            "Action:  [2 1 0 0 0 1 0 0 0 1 0 0 3 3 0 0]\n",
            "obs= [13  0  0  0  0 10  8  4  0 13  0  0  9  9  0  4] reward= [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False  True False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 89\n",
            "Action:  [2 0 0 0 0 0 3 0 0 2 0 0 1 1 0 0]\n",
            "obs= [14  0  0  4  0  6  8  4  0 13  4  0 10  8  0  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 90\n",
            "Action:  [1 0 0 0 0 0 3 0 0 2 0 0 0 3 0 0]\n",
            "obs= [ 0  0  0  4  4 10  9  4  0 13  4  4  6  8  0  0] reward= [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [ True False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 91\n",
            "Action:  [0 0 0 0 0 0 1 0 0 2 0 0 0 3 0 0]\n",
            "obs= [ 4  0  0  4  8  6  8  8  0 14  8  8  2  8  0  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 92\n",
            "Action:  [0 0 0 0 3 0 3 3 0 1 3 3 0 3 0 0]\n",
            "obs= [ 8  4  0  0  4  2  9  4  0 14  4  8  2  4  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 93\n",
            "Action:  [3 0 0 0 0 0 1 0 0 1 0 3 0 0 0 0]\n",
            "obs= [ 9  0  0  0  0  2 13  8  0 14  8  8  6  0  4  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 94\n",
            "Action:  [1 0 0 0 0 0 2 3 0 1 3 3 0 0 0 0]\n",
            "obs= [13  4  4  4  0  1  9  9  0 14  8  8 10  0  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 95\n",
            "Action:  [2 0 0 0 0 3 1 1 0 1 3 3 0 0 0 0]\n",
            "obs= [13  4  8  0  4  1  8 13  0  0  4  8  9  0  0  0] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False  True False False\n",
            " False False False False]\n",
            "Step 96\n",
            "Action:  [2 0 3 0 0 3 3 2 0 0 0 3 1 0 0 0]\n",
            "obs= [14  8  8  0  0  0  4  9  0  0  4  8  8  0  0  4] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 97\n",
            "Action:  [1 3 3 0 0 0 0 1 0 0 0 3 3 0 0 0]\n",
            "obs= [14  8  4  0  0  4  0  8  4  0  8  9  4  0  0  8] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 98\n",
            "Action:  [1 3 0 0 0 0 0 3 0 0 3 1 0 0 0 3]\n",
            "obs= [14  9  8  0  0  0  4  9  0  0  4 13  0  4  0  9] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 99\n",
            "Action:  [1 1 3 0 0 0 0 1 0 0 0 2 0 0 0 1]\n",
            "obs= [14 13  4  0  0  0  4 10  0  0  8 13  4  4  4 10] reward= [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [False False False False False False False False False False False False\n",
            " False False False False]\n",
            "Step 100\n",
            "Action:  [1 2 0 0 0 0 0 0 0 0 3 2 0 0 0 0]\n",
            "obs= [ 0 14  0  4  0  0  4 14  0  0  0 14  4  8  8  6] reward= [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] done= [ True False False False False False False False False False  True False\n",
            " False False False False]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzQZCDQmQbH3IKOEIsAHpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}